{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ef8a45-26b9-406f-868d-90f7b52051bf",
   "metadata": {},
   "source": [
    "<h1>FD004 Tuned CNN Model Training</h1>\n",
    "<ul>\n",
    "    <li>Loading training and validation data</li>\n",
    "    <li>Loading tuned model (best model from hyper tuning trials)</li>\n",
    "    <li>Tuned model training</li>\n",
    "    <li>Saving trained model</li>\n",
    "    <li>Displaying training model metrics</li>\n",
    "    <li>Creation of a .zip file for uploading to Google Drive</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7ad69b-4c21-42f8-b18e-ba65693abe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices: PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac4fcd5-c4e0-4ac3-b927-fc1cabc21091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading FD004.zip from Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1L5AQKlno4RuPmusVC8qz9gmFjT6gsYNq\n",
      "From (redirected): https://drive.google.com/uc?id=1L5AQKlno4RuPmusVC8qz9gmFjT6gsYNq&confirm=t&uuid=d150bb82-e034-4d63-9dfb-4955f142a6b6\n",
      "To: D:\\virtualenv\\src\\thesis\\cmapss\\tuning\\cnn\\input\\models\\FD004.zip\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 166M/166M [00:20<00:00, 8.16MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FD004.zip...\n",
      "Extraction complete: ./input\\models\n",
      "Downloading FD004.zip from Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1BGdAnxde8qRobh_nQUxTLPX2cDqBVSYD\n",
      "From (redirected): https://drive.google.com/uc?id=1BGdAnxde8qRobh_nQUxTLPX2cDqBVSYD&confirm=t&uuid=36c33eb2-fffc-45de-a127-2332e7bc1ea6\n",
      "To: D:\\virtualenv\\src\\thesis\\cmapss\\tuning\\cnn\\input\\CMAPSSData\\FD004.zip\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 72.0M/72.0M [00:08<00:00, 8.12MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FD004.zip...\n",
      "Extraction complete: ./input\\CMAPSSData\n",
      "\u001b[94m\u001b[1mInput directory\u001b[0m\n",
      "'./input'\n",
      "\u001b[94m\u001b[1mURL input dataset\u001b[0m\n",
      "'https://drive.google.com/file/d/1LU1DQuv7_CzBy2_Abgjg3HsvNDme361O/view?usp=drive_link'\n",
      "\u001b[94m\u001b[1mInput dataset directory\u001b[0m\n",
      "'./input\\\\CMAPSSData'\n",
      "\u001b[94m\u001b[1mOutput directory\u001b[0m\n",
      "'./working'\n",
      "\u001b[94m\u001b[1mOutput models directory\u001b[0m\n",
      "'./working\\\\models'\n",
      "\u001b[94m\u001b[1mOutput plots directory\u001b[0m\n",
      "'./working\\\\plots'\n"
     ]
    }
   ],
   "source": [
    "prepare_dirs(task='tuned-training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67bddd-0959-4478-8aa8-a8a1dd6dd7ab",
   "metadata": {},
   "source": [
    "<h2>Loading training and validation data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a91fd4-ebab-4d72-b978-07c5d3da631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mTraining features shape\u001b[0m\n",
      "(46210, 15, 16)\n",
      "\u001b[94m\u001b[1mTraining targets shape\u001b[0m\n",
      "(46210,)\n",
      "\u001b[94m\u001b[1mValidation features shape\u001b[0m\n",
      "(11553, 15, 16)\n",
      "\u001b[94m\u001b[1mValidation targets shape\u001b[0m\n",
      "(11553,)\n",
      "\u001b[94m\u001b[1mTesting features shape\u001b[0m\n",
      "(1240, 15, 16)\n",
      "\u001b[94m\u001b[1mTesting targets shape\u001b[0m\n",
      "(248,)\n"
     ]
    }
   ],
   "source": [
    "data_ftype = '.npy'\n",
    "\n",
    "ts_train_features_name = 'ts_train_features' + data_ftype\n",
    "ts_train_features_path = os.path.join(dataset_dir, ts_train_features_name)\n",
    "ts_train_targets_name = 'ts_train_targets' + data_ftype\n",
    "ts_train_targets_path = os.path.join(dataset_dir, ts_train_targets_name)\n",
    "\n",
    "ts_val_features_name = 'ts_val_features' + data_ftype\n",
    "ts_val_features_path = os.path.join(dataset_dir, ts_val_features_name)\n",
    "ts_val_targets_name = 'ts_val_targets' + data_ftype\n",
    "ts_val_targets_path = os.path.join(dataset_dir, ts_val_targets_name)\n",
    "\n",
    "ts_test_features_name = 'ts_test_features' + data_ftype\n",
    "ts_test_features_path = os.path.join(dataset_dir, ts_test_features_name)\n",
    "ts_test_targets_name = 'ts_test_targets' + data_ftype\n",
    "ts_test_targets_path = os.path.join(dataset_dir, ts_test_targets_name)\n",
    "\n",
    "ts_train_features = np.load(ts_train_features_path)\n",
    "ts_train_targets = np.load(ts_train_targets_path)\n",
    "\n",
    "ts_val_features = np.load(ts_val_features_path)\n",
    "ts_val_targets = np.load(ts_val_targets_path)\n",
    "\n",
    "ts_test_features = np.load(ts_test_features_path)\n",
    "ts_test_targets = np.load(ts_test_targets_path)\n",
    "\n",
    "\n",
    "nprint(\"Training features shape\", ts_train_features.shape)\n",
    "nprint(\"Training targets shape\", ts_train_targets.shape)\n",
    "nprint(\"Validation features shape\", ts_val_features.shape)\n",
    "nprint(\"Validation targets shape\", ts_val_targets.shape)\n",
    "nprint(\"Testing features shape\", ts_test_features.shape)\n",
    "nprint(\"Testing targets shape\", ts_test_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af86b5b-d211-48a1-a98d-08639bae3c1a",
   "metadata": {},
   "source": [
    "<h2>Loading tuned model (best model from hyper tuning trials)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d660cca-4110-49aa-ba97-d0663041f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./input\\models\\tuner0.json\n",
      "WARNING:tensorflow:From D:\\virtualenv\\myenv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\virtualenv\\myenv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,696</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">559,552</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">229,888</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">513</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m416\u001b[0m)             │          \u001b[38;5;34m33,696\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m448\u001b[0m)              │         \u001b[38;5;34m559,552\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m229,888\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m262,656\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m513\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,086,305</span> (4.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,086,305\u001b[0m (4.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,086,305</span> (4.14 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,086,305\u001b[0m (4.14 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_conv1d_layers_bounds = [1, 3]\n",
    "num_conv1d_filters_bounds = [64, 512, 32]\n",
    "num_dense_layers_bounds = [1, 2]\n",
    "num_dense_units_bounds = [64, 512, 32]\n",
    "initial_lr_bounds = [1e-4, 1e-2]\n",
    "batch_size_bounds = [32, 128, 32]\n",
    "\n",
    "rule_hp = RULEstimator_HyperModel(\n",
    "    window_length=window_length, \n",
    "    num_features=ts_train_features.shape[2], \n",
    "    num_targets=1 if len(ts_train_targets.shape)==1 else ts_train_targets.shape[1], \n",
    "    num_conv1d_layers_bounds=num_conv1d_layers_bounds, \n",
    "    num_conv1d_filters_bounds=num_conv1d_filters_bounds, \n",
    "    num_dense_layers_bounds=num_dense_layers_bounds, \n",
    "    num_dense_units_bounds=num_dense_units_bounds, \n",
    "    initial_lr_bounds=initial_lr_bounds,\n",
    "    batch_size_bounds=batch_size_bounds\n",
    ")\n",
    "rule_hp.build(kt.HyperParameters())\n",
    "\n",
    "\n",
    "with tensorflow.device('/GPU:0'):\n",
    "    tuner = kt.Hyperband(\n",
    "        hypermodel=rule_hp,\n",
    "        objective='val_loss',\n",
    "        max_epochs=max_epochs,\n",
    "        factor=factor,\n",
    "        directory=in_dir,\n",
    "        project_name=models_name,\n",
    "    )\n",
    "tuner.reload()\n",
    "tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a879c747-b499-409f-9f82-a9a6368f0cdf",
   "metadata": {},
   "source": [
    "<h2>Tuned model training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9030ea1b-32c1-4351-b326-344d07d592fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mbesthyperparameters.values\u001b[0m\n",
      "{'batch_size': 64,\n",
      " 'conv_filters_0': 416,\n",
      " 'conv_filters_1': 448,\n",
      " 'conv_filters_2': 416,\n",
      " 'conv_kernel_size_0': 5,\n",
      " 'conv_kernel_size_1': 3,\n",
      " 'conv_kernel_size_2': 7,\n",
      " 'dense_units_0': 512,\n",
      " 'dense_units_1': 512,\n",
      " 'initial_lr': 0.0038526189573804743,\n",
      " 'num_conv_layers': 2,\n",
      " 'num_dense_layers': 2,\n",
      " 'tuner/bracket': 0,\n",
      " 'tuner/epochs': 20,\n",
      " 'tuner/initial_epoch': 0,\n",
      " 'tuner/round': 0}\n",
      "\u001b[94m\u001b[1mTraining started: \u001b[0m\n",
      "'2024-12-06 13:43:54'\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.003852618858218193.\n",
      "Epoch 1/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 1779.9688 - val_loss: 1467.1074 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.003852618858218193.\n",
      "Epoch 2/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - loss: 964.9482 - val_loss: 770.8578 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.003852618858218193.\n",
      "Epoch 3/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 785.2736 - val_loss: 830.4354 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.003852618858218193.\n",
      "Epoch 4/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 767.2241 - val_loss: 968.7674 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.003852618858218193.\n",
      "Epoch 5/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 743.9863 - val_loss: 922.0004 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.003852618858218193.\n",
      "Epoch 6/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 710.3593 - val_loss: 659.2811 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.003852618858218193.\n",
      "Epoch 7/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 678.3841 - val_loss: 674.2032 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.003852618858218193.\n",
      "Epoch 8/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 653.2990 - val_loss: 582.1729 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.003852618858218193.\n",
      "Epoch 9/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 586.1995 - val_loss: 571.5369 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.003852618858218193.\n",
      "Epoch 10/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 565.1503 - val_loss: 532.0150 - learning_rate: 0.0039\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00038526188582181935.\n",
      "Epoch 11/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 429.1702 - val_loss: 429.5999 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 12/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 376.7824 - val_loss: 405.6365 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 13/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - loss: 358.7509 - val_loss: 384.2170 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 14/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 331.4413 - val_loss: 357.0091 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 15/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 304.7837 - val_loss: 337.9046 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 16/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 279.1800 - val_loss: 315.7040 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 17/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - loss: 257.9335 - val_loss: 290.6641 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 18/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 28ms/step - loss: 231.9606 - val_loss: 273.4818 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 19/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - loss: 212.5904 - val_loss: 265.7041 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 20/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 201.1321 - val_loss: 290.0592 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 21/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - loss: 205.4766 - val_loss: 220.3468 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 22/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - loss: 166.1467 - val_loss: 238.6387 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 23/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - loss: 167.8578 - val_loss: 208.1869 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 24/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 144.4013 - val_loss: 193.8607 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 25/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 133.2624 - val_loss: 187.0725 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 26/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 129.9828 - val_loss: 217.7545 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 27/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 125.8185 - val_loss: 162.7849 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 28/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 113.7901 - val_loss: 157.0376 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 29/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - loss: 102.6010 - val_loss: 148.0231 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 30/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 99.2133 - val_loss: 143.3531 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 31/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 94.6781 - val_loss: 162.9382 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 32/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - loss: 87.9578 - val_loss: 144.7750 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 33/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - loss: 84.3984 - val_loss: 150.6019 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 34/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 82.2695 - val_loss: 119.5904 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 35/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 75.3673 - val_loss: 119.4665 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 36/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - loss: 71.1945 - val_loss: 110.3260 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 37/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 68.6445 - val_loss: 123.4315 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 38/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 68.2911 - val_loss: 119.4244 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 39/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 33ms/step - loss: 67.3666 - val_loss: 100.6654 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.0003852618974633515.\n",
      "Epoch 40/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 59.5142 - val_loss: 103.0477 - learning_rate: 3.8526e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 3.852618974633515e-05.\n",
      "Epoch 41/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - loss: 48.6743 - val_loss: 86.2053 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 42/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 43.2960 - val_loss: 85.5171 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 43/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 41.2964 - val_loss: 84.0416 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 44/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 41.0194 - val_loss: 83.4983 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 45/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 31ms/step - loss: 40.6811 - val_loss: 83.3101 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 46/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 39.7920 - val_loss: 83.2888 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 47/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 39.7171 - val_loss: 81.5825 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 48/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 39.0001 - val_loss: 80.8453 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 49/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 39.5659 - val_loss: 80.2666 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 50/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 38.7495 - val_loss: 80.3771 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 51/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 37.8913 - val_loss: 79.7095 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 52/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 39.0371 - val_loss: 79.0280 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 53/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 36.9426 - val_loss: 78.7428 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 54/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - loss: 36.1626 - val_loss: 78.8299 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 55/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - loss: 36.2034 - val_loss: 79.8686 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 56/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 36.5618 - val_loss: 78.6259 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 57/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 35.0661 - val_loss: 78.5768 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 58/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 36.0817 - val_loss: 77.1821 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 59/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 35.0887 - val_loss: 76.7990 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 60/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 35.4017 - val_loss: 75.9750 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 61/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 35.1576 - val_loss: 75.9929 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 62/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 34.1071 - val_loss: 75.8569 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 63/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 34.0088 - val_loss: 75.3110 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 64/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 34.3631 - val_loss: 74.7175 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 65/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 34.4439 - val_loss: 74.7625 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 66/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 33.5164 - val_loss: 75.0447 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 67/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 33.5273 - val_loss: 73.4879 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 68/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 32.9845 - val_loss: 73.6565 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 69/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 32.1044 - val_loss: 73.2755 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 70/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 32.2489 - val_loss: 73.1850 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 71/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 32.8047 - val_loss: 72.9658 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 72/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 31.8966 - val_loss: 72.3967 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 73/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 32.1196 - val_loss: 72.4070 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 74/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 32.0479 - val_loss: 72.3115 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 75/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 30.6824 - val_loss: 71.7011 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 76/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 31.0097 - val_loss: 71.4209 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 77/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 30.7070 - val_loss: 70.9325 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 78/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 29.9775 - val_loss: 71.4986 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 79/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 30.0643 - val_loss: 71.0482 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 80/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 29.8405 - val_loss: 69.9318 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 81/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 29.2802 - val_loss: 69.6732 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 82/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 28.8882 - val_loss: 69.6593 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 83/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 29.1161 - val_loss: 70.4298 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 84/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 29.5117 - val_loss: 68.6726 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 85/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 29ms/step - loss: 28.1496 - val_loss: 69.3257 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 86/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - loss: 29.0296 - val_loss: 70.6053 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 87/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - loss: 28.5650 - val_loss: 68.6746 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 88/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 28.8103 - val_loss: 68.2406 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 89/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - loss: 27.7878 - val_loss: 69.5147 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 90/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 27.8995 - val_loss: 67.7236 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 91/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 27.9475 - val_loss: 69.6103 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 92/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - loss: 28.4338 - val_loss: 68.5660 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 93/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 27.1912 - val_loss: 67.2062 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 94/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - loss: 26.3773 - val_loss: 66.9932 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 95/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 26.8927 - val_loss: 66.0779 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 96/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 26.6806 - val_loss: 66.5351 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 97/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 27.5945 - val_loss: 66.0080 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 98/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 27.2922 - val_loss: 66.3598 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 99/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - loss: 26.1177 - val_loss: 65.8093 - learning_rate: 3.8526e-05\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 3.8526188291143626e-05.\n",
      "Epoch 100/100\n",
      "\u001b[1m723/723\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 30ms/step - loss: 26.5700 - val_loss: 65.3072 - learning_rate: 3.8526e-05\n",
      "\u001b[94m\u001b[1mTraining ended: \u001b[0m\n",
      "'2024-12-06 14:19:12'\n",
      "\u001b[94m\u001b[1mTraining duration\u001b[0m\n",
      "'2117.81 seconds'\n"
     ]
    }
   ],
   "source": [
    "besthyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "nprint('besthyperparameters.values', besthyperparameters.values)\n",
    "model = tuner.hypermodel.build(besthyperparameters)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "lr_scheduler = callbacks.LearningRateScheduler(scheduler_training, verbose=verbose)\n",
    "start_time = time.time()\n",
    "nprint('Training started: ', time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()))\n",
    "with tensorflow.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        ts_train_features, \n",
    "        ts_train_targets, \n",
    "        epochs=epochs, \n",
    "        validation_data=(\n",
    "            ts_val_features, \n",
    "            ts_val_targets\n",
    "        ), \n",
    "        verbose=verbose,\n",
    "        batch_size=besthyperparameters.values['batch_size'],\n",
    "        callbacks=[\n",
    "            early_stopping, \n",
    "            lr_scheduler\n",
    "        ]\n",
    "    )\n",
    "nprint('Training ended: ', time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()))\n",
    "end_time = time.time()\n",
    "training_duration = end_time - start_time\n",
    "nprint('Training duration', '{:.2f} seconds'.format(training_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d28c9-b2dc-40db-8ca1-55951e88af41",
   "metadata": {},
   "source": [
    "<h2>Saving trained model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71e801e-1d26-4629-9e6e-75ff346c042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype = 'CNN'\n",
    "\n",
    "cnn_model_name = '{}_{}'.format(dataset_name, modeltype)\n",
    "cnn_model_files_dir = os.path.join(out_models_dir, cnn_model_name)\n",
    "os.makedirs(cnn_model_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a0be72-309d-4ed7-8a63-e16cd9b2ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mCNN model path\u001b[0m\n",
      "'./working\\\\models\\\\FD004_CNN\\\\FD004_CNN.keras'\n"
     ]
    }
   ],
   "source": [
    "ftype = 'keras'\n",
    "cnn_model_file_name = '{}.{}'.format(cnn_model_name, ftype)\n",
    "cnn_model_path = os.path.join(cnn_model_files_dir, cnn_model_file_name)\n",
    "model.save(filepath=cnn_model_path)\n",
    "nprint('CNN model path', cnn_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27322f5f-eb9f-4a9c-8d2f-c11719756ae5",
   "metadata": {},
   "source": [
    "<h2>Displaying training model metrics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6acd028-1f57-4951-848c-f5919a3d9e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mCNN model history path\u001b[0m\n",
      "'./working\\\\models\\\\FD004_CNN\\\\FD004_CNN_history.json'\n",
      "     loss  val_loss  learning_rate  epoch\n",
      "27.243532 66.535080       0.000039     95\n",
      "27.320501 66.008041       0.000039     96\n",
      "26.832674 66.359756       0.000039     97\n",
      "26.654087 65.809326       0.000039     98\n",
      "26.596527 65.307228       0.000039     99\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ftype = 'json'\n",
    "cnn_model_history_name = '{}_{}_{}.{}'.format(dataset_name, modeltype, 'history', ftype) \n",
    "cnn_model_history_path = os.path.join(cnn_model_files_dir, cnn_model_history_name)\n",
    "with open(cnn_model_history_path, \"w\") as file: \n",
    "    json.dump({'history': history.history}, file, indent=4)\n",
    "nprint('CNN model history path', cnn_model_history_path)\n",
    "display_training_performance(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bde3bd-05e1-44a4-a7fa-fc2afc0603d1",
   "metadata": {},
   "source": [
    "<h2>Creation of a .zip file for uploading to Google Drive</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9877b05e-6ed3-441d-94f4-48fee7d60d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftype = 'zip'\n",
    "shutil.make_archive(cnn_model_files_dir, ftype, cnn_model_files_dir)\n",
    "shutil.rmtree(cnn_model_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee8384-469d-4c54-bd5b-f146f34e8b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
