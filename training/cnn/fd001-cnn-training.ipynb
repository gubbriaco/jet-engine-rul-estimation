{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc5ba2e-be87-46e9-9331-ef4fa32116a8",
   "metadata": {},
   "source": [
    "<h1>FD001 Tuned CNN Model Training</h1>\n",
    "<ul>\n",
    "    <li>Loading training and validation data</li>\n",
    "    <li>Loading tuned model (best model from hyper tuning trials)</li>\n",
    "    <li>Tuned model training</li>\n",
    "    <li>Saving trained model</li>\n",
    "    <li>Displaying training model metrics</li>\n",
    "    <li>Creation of a .zip file for uploading to Google Drive</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7ad69b-4c21-42f8-b18e-ba65693abe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices: PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac4fcd5-c4e0-4ac3-b927-fc1cabc21091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading FD001.zip from Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=107rKeqyMaDncCk6jpbyyCX86xzbMSiDU\n",
      "From (redirected): https://drive.google.com/uc?id=107rKeqyMaDncCk6jpbyyCX86xzbMSiDU&confirm=t&uuid=0d61b045-accb-4039-80fa-4ea7fd13420e\n",
      "To: D:\\virtualenv\\src\\thesis\\cmapss\\tuning\\cnn\\input\\models\\FD001.zip\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 150M/150M [00:18<00:00, 8.19MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FD001.zip...\n",
      "Extraction complete: ./input\\models\n",
      "Downloading FD001.zip from Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1TnV9sAX2My-R3iSGamX3rVAezoBsGY_M\n",
      "From (redirected): https://drive.google.com/uc?id=1TnV9sAX2My-R3iSGamX3rVAezoBsGY_M&confirm=t&uuid=c77cae46-8269-4eb2-917f-7d92dde7a942\n",
      "To: D:\\virtualenv\\src\\thesis\\cmapss\\tuning\\cnn\\input\\CMAPSSData\\FD001.zip\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 29.5M/29.5M [00:03<00:00, 8.21MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FD001.zip...\n",
      "Extraction complete: ./input\\CMAPSSData\n",
      "\u001b[94m\u001b[1mInput directory\u001b[0m\n",
      "'./input'\n",
      "\u001b[94m\u001b[1mURL input dataset\u001b[0m\n",
      "'https://drive.google.com/file/d/1LU1DQuv7_CzBy2_Abgjg3HsvNDme361O/view?usp=drive_link'\n",
      "\u001b[94m\u001b[1mInput dataset directory\u001b[0m\n",
      "'./input\\\\CMAPSSData'\n",
      "\u001b[94m\u001b[1mOutput directory\u001b[0m\n",
      "'./working'\n",
      "\u001b[94m\u001b[1mOutput models directory\u001b[0m\n",
      "'./working\\\\models'\n",
      "\u001b[94m\u001b[1mOutput plots directory\u001b[0m\n",
      "'./working\\\\plots'\n"
     ]
    }
   ],
   "source": [
    "prepare_dirs(task='tuned-training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7c2b5-bba4-4097-99d9-cdc57545c6ed",
   "metadata": {},
   "source": [
    "<h2>Loading training and validation data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a91fd4-ebab-4d72-b978-07c5d3da631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mTraining features shape\u001b[0m\n",
      "(14184, 30, 14)\n",
      "\u001b[94m\u001b[1mTraining targets shape\u001b[0m\n",
      "(14184,)\n",
      "\u001b[94m\u001b[1mValidation features shape\u001b[0m\n",
      "(3547, 30, 14)\n",
      "\u001b[94m\u001b[1mValidation targets shape\u001b[0m\n",
      "(3547,)\n",
      "\u001b[94m\u001b[1mTesting features shape\u001b[0m\n",
      "(497, 30, 14)\n",
      "\u001b[94m\u001b[1mTesting targets shape\u001b[0m\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "data_ftype = '.npy'\n",
    "\n",
    "ts_train_features_name = 'ts_train_features' + data_ftype\n",
    "ts_train_features_path = os.path.join(dataset_dir, ts_train_features_name)\n",
    "ts_train_targets_name = 'ts_train_targets' + data_ftype\n",
    "ts_train_targets_path = os.path.join(dataset_dir, ts_train_targets_name)\n",
    "\n",
    "ts_val_features_name = 'ts_val_features' + data_ftype\n",
    "ts_val_features_path = os.path.join(dataset_dir, ts_val_features_name)\n",
    "ts_val_targets_name = 'ts_val_targets' + data_ftype\n",
    "ts_val_targets_path = os.path.join(dataset_dir, ts_val_targets_name)\n",
    "\n",
    "ts_test_features_name = 'ts_test_features' + data_ftype\n",
    "ts_test_features_path = os.path.join(dataset_dir, ts_test_features_name)\n",
    "ts_test_targets_name = 'ts_test_targets' + data_ftype\n",
    "ts_test_targets_path = os.path.join(dataset_dir, ts_test_targets_name)\n",
    "\n",
    "ts_train_features = np.load(ts_train_features_path)\n",
    "ts_train_targets = np.load(ts_train_targets_path)\n",
    "\n",
    "ts_val_features = np.load(ts_val_features_path)\n",
    "ts_val_targets = np.load(ts_val_targets_path)\n",
    "\n",
    "ts_test_features = np.load(ts_test_features_path)\n",
    "ts_test_targets = np.load(ts_test_targets_path)\n",
    "\n",
    "\n",
    "nprint(\"Training features shape\", ts_train_features.shape)\n",
    "nprint(\"Training targets shape\", ts_train_targets.shape)\n",
    "nprint(\"Validation features shape\", ts_val_features.shape)\n",
    "nprint(\"Validation targets shape\", ts_val_targets.shape)\n",
    "nprint(\"Testing features shape\", ts_test_features.shape)\n",
    "nprint(\"Testing targets shape\", ts_test_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522eb23-7fbf-402c-b290-96a96a0170cc",
   "metadata": {},
   "source": [
    "<h2>Loading tuned model (best model from hyper tuning trials)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d660cca-4110-49aa-ba97-d0663041f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./input\\models\\tuner0.json\n",
      "WARNING:tensorflow:From D:\\virtualenv\\myenv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\virtualenv\\myenv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">6,816</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">123,136</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">123,360</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">481</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m14\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m96\u001b[0m)              │           \u001b[38;5;34m6,816\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m123,136\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m196,864\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)                 │         \u001b[38;5;34m123,360\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m481\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450,657</span> (1.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m450,657\u001b[0m (1.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">450,657</span> (1.72 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m450,657\u001b[0m (1.72 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_conv1d_layers_bounds = [1, 3]\n",
    "num_conv1d_filters_bounds = [64, 512, 32]\n",
    "num_dense_layers_bounds = [1, 2]\n",
    "num_dense_units_bounds = [64, 512, 32]\n",
    "initial_lr_bounds = [1e-4, 1e-2]\n",
    "batch_size_bounds = [32, 128, 32]\n",
    "\n",
    "rule_hp = RULEstimator_HyperModel(\n",
    "    window_length=window_length, \n",
    "    num_features=ts_train_features.shape[2], \n",
    "    num_targets=1 if len(ts_train_targets.shape)==1 else ts_train_targets.shape[1], \n",
    "    num_conv1d_layers_bounds=num_conv1d_layers_bounds, \n",
    "    num_conv1d_filters_bounds=num_conv1d_filters_bounds, \n",
    "    num_dense_layers_bounds=num_dense_layers_bounds, \n",
    "    num_dense_units_bounds=num_dense_units_bounds, \n",
    "    initial_lr_bounds=initial_lr_bounds,\n",
    "    batch_size_bounds=batch_size_bounds\n",
    ")\n",
    "rule_hp.build(kt.HyperParameters())\n",
    "\n",
    "\n",
    "with tensorflow.device('/GPU:0'):\n",
    "    tuner = kt.Hyperband(\n",
    "        hypermodel=rule_hp,\n",
    "        objective='val_loss',\n",
    "        max_epochs=max_epochs,\n",
    "        factor=factor,\n",
    "        directory=in_dir,\n",
    "        project_name=models_name,\n",
    "    )\n",
    "tuner.reload()\n",
    "tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87046fac-d134-4213-a8f9-dde79e76b04f",
   "metadata": {},
   "source": [
    "<h2>Tuned model training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9030ea1b-32c1-4351-b326-344d07d592fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mbesthyperparameters.values\u001b[0m\n",
      "{'batch_size': 32,\n",
      " 'conv_filters_0': 96,\n",
      " 'conv_filters_1': 256,\n",
      " 'conv_filters_2': 256,\n",
      " 'conv_kernel_size_0': 5,\n",
      " 'conv_kernel_size_1': 5,\n",
      " 'conv_kernel_size_2': 3,\n",
      " 'dense_units_0': 480,\n",
      " 'dense_units_1': 128,\n",
      " 'initial_lr': 0.0013117452857213854,\n",
      " 'num_conv_layers': 3,\n",
      " 'num_dense_layers': 1,\n",
      " 'tuner/bracket': 2,\n",
      " 'tuner/epochs': 20,\n",
      " 'tuner/initial_epoch': 7,\n",
      " 'tuner/round': 2,\n",
      " 'tuner/trial_id': '0013'}\n",
      "\u001b[94m\u001b[1mTraining started: \u001b[0m\n",
      "'2024-12-04 19:35:00'\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001311745261773467.\n",
      "Epoch 1/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 1198.6359 - val_loss: 459.1524 - learning_rate: 0.0013\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001311745261773467.\n",
      "Epoch 2/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 380.7833 - val_loss: 251.2752 - learning_rate: 0.0013\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001311745261773467.\n",
      "Epoch 3/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 271.7015 - val_loss: 273.2177 - learning_rate: 0.0013\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001311745261773467.\n",
      "Epoch 4/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 232.1541 - val_loss: 346.9471 - learning_rate: 0.0013\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001311745261773467.\n",
      "Epoch 5/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 220.0656 - val_loss: 242.1601 - learning_rate: 0.0013\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.001311745261773467.\n",
      "Epoch 6/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 190.9281 - val_loss: 241.1451 - learning_rate: 0.0013\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.001311745261773467.\n",
      "Epoch 7/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 167.7780 - val_loss: 130.3774 - learning_rate: 0.0013\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.001311745261773467.\n",
      "Epoch 8/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 130.4499 - val_loss: 116.8819 - learning_rate: 0.0013\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.001311745261773467.\n",
      "Epoch 9/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 111.1788 - val_loss: 84.0912 - learning_rate: 0.0013\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.001311745261773467.\n",
      "Epoch 10/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 76.2175 - val_loss: 144.7502 - learning_rate: 0.0013\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00013117452617734672.\n",
      "Epoch 11/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 53.6011 - val_loss: 46.0865 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 12/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 44.2568 - val_loss: 42.8004 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 13/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 40.0330 - val_loss: 39.8164 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 14/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 36.7634 - val_loss: 36.9343 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 15/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 34.0012 - val_loss: 39.8158 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 16/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 34.0038 - val_loss: 32.9583 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 17/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 29.1792 - val_loss: 33.1911 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 18/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 27.8236 - val_loss: 29.3291 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 19/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 26.4706 - val_loss: 27.3079 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 20/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 24.3167 - val_loss: 25.0830 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 21/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 23.6563 - val_loss: 23.9189 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 22/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 21.5922 - val_loss: 23.7040 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 23/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 20.6786 - val_loss: 23.6618 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 24/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 19.3359 - val_loss: 20.4139 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 25/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 19.0016 - val_loss: 19.6084 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 26/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 17.0974 - val_loss: 19.2796 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 27/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 17.0226 - val_loss: 18.5498 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 28/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - loss: 15.9369 - val_loss: 17.4828 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 29/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 15.7513 - val_loss: 16.4360 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 30/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 14.5860 - val_loss: 15.7076 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 31/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - loss: 14.4923 - val_loss: 14.9423 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 32/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 13.1053 - val_loss: 17.2790 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 33/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - loss: 13.9286 - val_loss: 16.3536 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 34/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 12.8492 - val_loss: 15.7384 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 35/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 12.0351 - val_loss: 13.5245 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 36/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 11.9068 - val_loss: 12.5786 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 37/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 10.9977 - val_loss: 13.0858 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 38/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 10.9382 - val_loss: 19.1912 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 39/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 10.7945 - val_loss: 18.2834 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.00013117452908772975.\n",
      "Epoch 40/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 11.1700 - val_loss: 11.9959 - learning_rate: 1.3117e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 41/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 8.7328 - val_loss: 10.7317 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 42/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 8.3587 - val_loss: 11.0927 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 43/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 8.3093 - val_loss: 10.5288 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 44/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 8.1031 - val_loss: 10.4677 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 45/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 8.1373 - val_loss: 10.6263 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 46/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 8.1165 - val_loss: 10.4467 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 47/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 8.0778 - val_loss: 10.4136 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 48/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 8.1970 - val_loss: 10.4257 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 49/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 7.8190 - val_loss: 10.2746 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 50/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 7.6131 - val_loss: 10.3721 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 51/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 8.0500 - val_loss: 10.1185 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 52/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 8.0255 - val_loss: 10.1775 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 53/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 7.9675 - val_loss: 10.2285 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 54/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.9491 - val_loss: 10.1168 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 55/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 7.8340 - val_loss: 10.0539 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 56/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 7.6938 - val_loss: 10.0339 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 57/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 7.9744 - val_loss: 9.9230 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 58/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 7.6835 - val_loss: 9.9877 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 59/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.6368 - val_loss: 9.7911 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 60/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 7.6851 - val_loss: 9.8278 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 61/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.5619 - val_loss: 9.8114 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 62/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.6663 - val_loss: 9.9018 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 63/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 7.5718 - val_loss: 9.8142 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 64/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.4752 - val_loss: 9.7686 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 65/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.5130 - val_loss: 9.6481 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 66/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.3010 - val_loss: 9.7441 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 67/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.3869 - val_loss: 9.6647 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 68/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.3014 - val_loss: 9.6154 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 69/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.2460 - val_loss: 9.9118 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 70/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.2972 - val_loss: 9.5540 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 71/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.4221 - val_loss: 9.7726 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 72/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.4928 - val_loss: 9.5670 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 73/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.1706 - val_loss: 9.4292 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 74/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.0293 - val_loss: 9.3917 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 75/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.1037 - val_loss: 9.5415 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 76/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.0930 - val_loss: 9.3018 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 77/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.1287 - val_loss: 9.2732 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 78/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.0103 - val_loss: 9.6455 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 79/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.0377 - val_loss: 9.7545 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 80/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 7.1177 - val_loss: 9.4672 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 81/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 6.7757 - val_loss: 9.2870 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 82/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 6.7468 - val_loss: 9.2112 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 83/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - loss: 6.8571 - val_loss: 9.2144 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 84/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 6.6555 - val_loss: 9.4397 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 85/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 6.9757 - val_loss: 9.0722 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 86/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 6.8017 - val_loss: 9.4081 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 87/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 6.8461 - val_loss: 8.8924 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 88/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 6.9027 - val_loss: 9.0367 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 89/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 6.8226 - val_loss: 8.9964 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 90/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 6.8743 - val_loss: 8.9405 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 91/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 18ms/step - loss: 6.7554 - val_loss: 8.9542 - learning_rate: 1.3117e-05\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 1.3117452908772975e-05.\n",
      "Epoch 92/100\n",
      "\u001b[1m444/444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - loss: 6.7834 - val_loss: 9.0804 - learning_rate: 1.3117e-05\n",
      "\u001b[94m\u001b[1mTraining ended: \u001b[0m\n",
      "'2024-12-04 19:46:59'\n",
      "\u001b[94m\u001b[1mTraining duration\u001b[0m\n",
      "'718.53 seconds'\n"
     ]
    }
   ],
   "source": [
    "besthyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "nprint('besthyperparameters.values', besthyperparameters.values)\n",
    "model = tuner.hypermodel.build(besthyperparameters)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "lr_scheduler = callbacks.LearningRateScheduler(scheduler_training, verbose=verbose)\n",
    "start_time = time.time()\n",
    "nprint('Training started: ', time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()))\n",
    "with tensorflow.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        ts_train_features, \n",
    "        ts_train_targets, \n",
    "        epochs=epochs, \n",
    "        validation_data=(\n",
    "            ts_val_features, \n",
    "            ts_val_targets\n",
    "        ), \n",
    "        verbose=verbose,\n",
    "        batch_size=besthyperparameters.values['batch_size'],\n",
    "        callbacks=[\n",
    "            early_stopping, \n",
    "            lr_scheduler\n",
    "        ]\n",
    "    )\n",
    "nprint('Training ended: ', time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()))\n",
    "end_time = time.time()\n",
    "training_duration = end_time - start_time\n",
    "nprint('Training duration', '{:.2f} seconds'.format(training_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3c90a-c9b5-4264-aaef-6769b757445d",
   "metadata": {},
   "source": [
    "<h2>Saving trained model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71e801e-1d26-4629-9e6e-75ff346c042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype = 'CNN'\n",
    "\n",
    "cnn_model_name = '{}_{}'.format(dataset_name, modeltype)\n",
    "cnn_model_files_dir = os.path.join(out_models_dir, cnn_model_name)\n",
    "os.makedirs(cnn_model_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a0be72-309d-4ed7-8a63-e16cd9b2ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mCNN model path\u001b[0m\n",
      "'./working\\\\models\\\\FD001_CNN\\\\FD001_CNN.keras'\n"
     ]
    }
   ],
   "source": [
    "ftype = 'keras'\n",
    "cnn_model_file_name = '{}.{}'.format(cnn_model_name, ftype)\n",
    "cnn_model_path = os.path.join(cnn_model_files_dir, cnn_model_file_name)\n",
    "model.save(filepath=cnn_model_path)\n",
    "nprint('CNN model path', cnn_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2247acc7-df51-4541-9632-bfeaedb0c2a3",
   "metadata": {},
   "source": [
    "<h2>Displaying training model metrics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6acd028-1f57-4951-848c-f5919a3d9e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mCNN model history path\u001b[0m\n",
      "'./working\\\\models\\\\FD001_CNN\\\\FD001_CNN_history.json'\n",
      "    loss  val_loss  learning_rate  epoch\n",
      "6.814451  9.036690       0.000013     87\n",
      "6.710324  8.996374       0.000013     88\n",
      "6.706924  8.940519       0.000013     89\n",
      "6.694739  8.954231       0.000013     90\n",
      "6.662977  9.080371       0.000013     91\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ftype = 'json'\n",
    "cnn_model_history_name = '{}_{}_{}.{}'.format(dataset_name, modeltype, 'history', ftype) \n",
    "cnn_model_history_path = os.path.join(cnn_model_files_dir, cnn_model_history_name)\n",
    "with open(cnn_model_history_path, \"w\") as file: \n",
    "    json.dump({'history': history.history}, file, indent=4)\n",
    "nprint('CNN model history path', cnn_model_history_path)\n",
    "display_training_performance(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bde3bd-05e1-44a4-a7fa-fc2afc0603d1",
   "metadata": {},
   "source": [
    "<h2>Creation of a .zip file for uploading to Google Drive</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9877b05e-6ed3-441d-94f4-48fee7d60d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftype = 'zip'\n",
    "shutil.make_archive(cnn_model_files_dir, ftype, cnn_model_files_dir)\n",
    "shutil.rmtree(cnn_model_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee8384-469d-4c54-bd5b-f146f34e8b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
