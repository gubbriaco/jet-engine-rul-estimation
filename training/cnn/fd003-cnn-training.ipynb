{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bda7969-134e-47b8-89c0-57901bf2f74a",
   "metadata": {},
   "source": [
    "<h1>FD003 Tuned CNN Model Training</h1>\n",
    "<ul>\n",
    "    <li>Loading training and validation data</li>\n",
    "    <li>Loading tuned model (best model from hyper tuning trials)</li>\n",
    "    <li>Tuned model training</li>\n",
    "    <li>Saving trained model</li>\n",
    "    <li>Displaying training model metrics</li>\n",
    "    <li>Creation of a .zip file for uploading to Google Drive</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7ad69b-4c21-42f8-b18e-ba65693abe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices: PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac4fcd5-c4e0-4ac3-b927-fc1cabc21091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading FD003.zip from Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=10H7ofhmbeHkrTjZ8v-lGDd62xZkQ-Vjz\n",
      "From (redirected): https://drive.google.com/uc?id=10H7ofhmbeHkrTjZ8v-lGDd62xZkQ-Vjz&confirm=t&uuid=da6f154e-c283-49dc-be86-11b50647f4e9\n",
      "To: D:\\virtualenv\\src\\thesis\\cmapss\\tuning\\cnn\\input\\models\\FD003.zip\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 148M/148M [00:18<00:00, 7.88MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FD003.zip...\n",
      "Extraction complete: ./input\\models\n",
      "Downloading FD003.zip from Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1zCT4nZMr0wnaGJZixayS_UJ1fh8ScxqP\n",
      "From (redirected): https://drive.google.com/uc?id=1zCT4nZMr0wnaGJZixayS_UJ1fh8ScxqP&confirm=t&uuid=39e7ec7c-eeff-46ad-b403-af1b2381ed27\n",
      "To: D:\\virtualenv\\src\\thesis\\cmapss\\tuning\\cnn\\input\\CMAPSSData\\FD003.zip\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 40.3M/40.3M [00:05<00:00, 7.79MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FD003.zip...\n",
      "Extraction complete: ./input\\CMAPSSData\n",
      "\u001b[94m\u001b[1mInput directory\u001b[0m\n",
      "'./input'\n",
      "\u001b[94m\u001b[1mURL input dataset\u001b[0m\n",
      "'https://drive.google.com/file/d/1LU1DQuv7_CzBy2_Abgjg3HsvNDme361O/view?usp=drive_link'\n",
      "\u001b[94m\u001b[1mInput dataset directory\u001b[0m\n",
      "'./input\\\\CMAPSSData'\n",
      "\u001b[94m\u001b[1mOutput directory\u001b[0m\n",
      "'./working'\n",
      "\u001b[94m\u001b[1mOutput models directory\u001b[0m\n",
      "'./working\\\\models'\n",
      "\u001b[94m\u001b[1mOutput plots directory\u001b[0m\n",
      "'./working\\\\plots'\n"
     ]
    }
   ],
   "source": [
    "prepare_dirs(task='tuned-training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9918770-1fd5-404b-bf63-065922b98e5d",
   "metadata": {},
   "source": [
    "<h2>Loading training and validation data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a91fd4-ebab-4d72-b978-07c5d3da631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mTraining features shape\u001b[0m\n",
      "(17456, 30, 15)\n",
      "\u001b[94m\u001b[1mTraining targets shape\u001b[0m\n",
      "(17456,)\n",
      "\u001b[94m\u001b[1mValidation features shape\u001b[0m\n",
      "(4364, 30, 15)\n",
      "\u001b[94m\u001b[1mValidation targets shape\u001b[0m\n",
      "(4364,)\n",
      "\u001b[94m\u001b[1mTesting features shape\u001b[0m\n",
      "(500, 30, 15)\n",
      "\u001b[94m\u001b[1mTesting targets shape\u001b[0m\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "data_ftype = '.npy'\n",
    "\n",
    "ts_train_features_name = 'ts_train_features' + data_ftype\n",
    "ts_train_features_path = os.path.join(dataset_dir, ts_train_features_name)\n",
    "ts_train_targets_name = 'ts_train_targets' + data_ftype\n",
    "ts_train_targets_path = os.path.join(dataset_dir, ts_train_targets_name)\n",
    "\n",
    "ts_val_features_name = 'ts_val_features' + data_ftype\n",
    "ts_val_features_path = os.path.join(dataset_dir, ts_val_features_name)\n",
    "ts_val_targets_name = 'ts_val_targets' + data_ftype\n",
    "ts_val_targets_path = os.path.join(dataset_dir, ts_val_targets_name)\n",
    "\n",
    "ts_test_features_name = 'ts_test_features' + data_ftype\n",
    "ts_test_features_path = os.path.join(dataset_dir, ts_test_features_name)\n",
    "ts_test_targets_name = 'ts_test_targets' + data_ftype\n",
    "ts_test_targets_path = os.path.join(dataset_dir, ts_test_targets_name)\n",
    "\n",
    "ts_train_features = np.load(ts_train_features_path)\n",
    "ts_train_targets = np.load(ts_train_targets_path)\n",
    "\n",
    "ts_val_features = np.load(ts_val_features_path)\n",
    "ts_val_targets = np.load(ts_val_targets_path)\n",
    "\n",
    "ts_test_features = np.load(ts_test_features_path)\n",
    "ts_test_targets = np.load(ts_test_targets_path)\n",
    "\n",
    "\n",
    "nprint(\"Training features shape\", ts_train_features.shape)\n",
    "nprint(\"Training targets shape\", ts_train_targets.shape)\n",
    "nprint(\"Validation features shape\", ts_val_features.shape)\n",
    "nprint(\"Validation targets shape\", ts_val_targets.shape)\n",
    "nprint(\"Testing features shape\", ts_test_features.shape)\n",
    "nprint(\"Testing targets shape\", ts_test_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384563dd-12df-46f2-8011-44a1d1e7c53a",
   "metadata": {},
   "source": [
    "<h2>Loading tuned model (best model from hyper tuning trials)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d660cca-4110-49aa-ba97-d0663041f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./input\\models\\tuner0.json\n",
      "WARNING:tensorflow:From D:\\virtualenv\\myenv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\virtualenv\\myenv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,003,968</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">717,120</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">143,808</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">449</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m15\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m320\u001b[0m)             │          \u001b[38;5;34m24,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m448\u001b[0m)             │       \u001b[38;5;34m1,003,968\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m320\u001b[0m)             │         \u001b[38;5;34m717,120\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)                 │         \u001b[38;5;34m143,808\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m449\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,889,665</span> (7.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,889,665\u001b[0m (7.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,889,665</span> (7.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,889,665\u001b[0m (7.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_conv1d_layers_bounds = [1, 3]\n",
    "num_conv1d_filters_bounds = [64, 512, 32]\n",
    "num_dense_layers_bounds = [1, 2]\n",
    "num_dense_units_bounds = [64, 512, 32]\n",
    "initial_lr_bounds = [1e-4, 1e-2]\n",
    "batch_size_bounds = [32, 128, 32]\n",
    "\n",
    "rule_hp = RULEstimator_HyperModel(\n",
    "    window_length=window_length, \n",
    "    num_features=ts_train_features.shape[2], \n",
    "    num_targets=1 if len(ts_train_targets.shape)==1 else ts_train_targets.shape[1], \n",
    "    num_conv1d_layers_bounds=num_conv1d_layers_bounds, \n",
    "    num_conv1d_filters_bounds=num_conv1d_filters_bounds, \n",
    "    num_dense_layers_bounds=num_dense_layers_bounds, \n",
    "    num_dense_units_bounds=num_dense_units_bounds, \n",
    "    initial_lr_bounds=initial_lr_bounds,\n",
    "    batch_size_bounds=batch_size_bounds\n",
    ")\n",
    "rule_hp.build(kt.HyperParameters())\n",
    "\n",
    "\n",
    "with tensorflow.device('/GPU:0'):\n",
    "    tuner = kt.Hyperband(\n",
    "        hypermodel=rule_hp,\n",
    "        objective='val_loss',\n",
    "        max_epochs=max_epochs,\n",
    "        factor=factor,\n",
    "        directory=in_dir,\n",
    "        project_name=models_name,\n",
    "    )\n",
    "tuner.reload()\n",
    "tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70e3a6-1068-418b-a9d6-cecd65123208",
   "metadata": {},
   "source": [
    "<h2>Tuned model training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9030ea1b-32c1-4351-b326-344d07d592fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mbesthyperparameters.values\u001b[0m\n",
      "{'batch_size': 32,\n",
      " 'conv_filters_0': 320,\n",
      " 'conv_filters_1': 448,\n",
      " 'conv_filters_2': 320,\n",
      " 'conv_kernel_size_0': 5,\n",
      " 'conv_kernel_size_1': 7,\n",
      " 'conv_kernel_size_2': 5,\n",
      " 'dense_units_0': 448,\n",
      " 'dense_units_1': 320,\n",
      " 'initial_lr': 0.0015593155550660902,\n",
      " 'num_conv_layers': 3,\n",
      " 'num_dense_layers': 1,\n",
      " 'tuner/bracket': 2,\n",
      " 'tuner/epochs': 20,\n",
      " 'tuner/initial_epoch': 7,\n",
      " 'tuner/round': 2,\n",
      " 'tuner/trial_id': '0012'}\n",
      "\u001b[94m\u001b[1mTraining started: \u001b[0m\n",
      "'2024-12-06 10:25:32'\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0015593155985698104.\n",
      "Epoch 1/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 58ms/step - loss: 855.8981 - val_loss: 405.3871 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0015593155985698104.\n",
      "Epoch 2/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 61ms/step - loss: 386.4197 - val_loss: 441.5628 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0015593155985698104.\n",
      "Epoch 3/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 63ms/step - loss: 293.7137 - val_loss: 202.2148 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0015593155985698104.\n",
      "Epoch 4/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 60ms/step - loss: 243.3304 - val_loss: 175.5073 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0015593155985698104.\n",
      "Epoch 5/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 61ms/step - loss: 193.8655 - val_loss: 190.7788 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0015593155985698104.\n",
      "Epoch 6/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 60ms/step - loss: 194.4209 - val_loss: 188.7523 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0015593155985698104.\n",
      "Epoch 7/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 60ms/step - loss: 171.8296 - val_loss: 218.8375 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0015593155985698104.\n",
      "Epoch 8/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 61ms/step - loss: 183.8522 - val_loss: 168.1336 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0015593155985698104.\n",
      "Epoch 9/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 61ms/step - loss: 160.9411 - val_loss: 152.2402 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0015593155985698104.\n",
      "Epoch 10/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 60ms/step - loss: 148.3179 - val_loss: 151.8771 - learning_rate: 0.0016\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00015593155985698106.\n",
      "Epoch 11/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 61ms/step - loss: 124.8777 - val_loss: 119.8781 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 12/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 60ms/step - loss: 116.7695 - val_loss: 126.9443 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 13/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 61ms/step - loss: 112.5996 - val_loss: 113.7155 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 14/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 61ms/step - loss: 110.3546 - val_loss: 108.8264 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 15/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 62ms/step - loss: 105.7646 - val_loss: 106.7719 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 16/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 61ms/step - loss: 105.5703 - val_loss: 101.1321 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 17/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 60ms/step - loss: 98.0906 - val_loss: 97.4291 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 18/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 61ms/step - loss: 98.0353 - val_loss: 96.7064 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 19/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 61ms/step - loss: 90.4156 - val_loss: 88.2205 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 20/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 85.9655 - val_loss: 82.5730 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 21/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 61ms/step - loss: 81.9058 - val_loss: 80.2321 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 22/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 62ms/step - loss: 76.2492 - val_loss: 76.3450 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 23/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 64ms/step - loss: 70.3766 - val_loss: 67.3109 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 24/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 62ms/step - loss: 65.0956 - val_loss: 62.5892 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 25/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 59.2867 - val_loss: 57.6985 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 26/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 62ms/step - loss: 52.5989 - val_loss: 52.3460 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 27/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 62ms/step - loss: 49.4748 - val_loss: 48.1915 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 28/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 62ms/step - loss: 44.0367 - val_loss: 44.4212 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 29/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 63ms/step - loss: 39.6071 - val_loss: 55.5636 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 30/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 37.3578 - val_loss: 38.9116 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 31/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 62ms/step - loss: 34.3796 - val_loss: 35.1562 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 32/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 64ms/step - loss: 31.3919 - val_loss: 30.7132 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 33/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 63ms/step - loss: 28.2368 - val_loss: 28.7755 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 34/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 26.1392 - val_loss: 27.0170 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 35/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 24.9007 - val_loss: 24.6798 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 36/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 23.0033 - val_loss: 20.0839 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 37/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 20.7673 - val_loss: 26.7057 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 38/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 18.6154 - val_loss: 19.1693 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 39/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 17.1341 - val_loss: 16.9205 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.000155931556946598.\n",
      "Epoch 40/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 16.3024 - val_loss: 16.7604 - learning_rate: 1.5593e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 41/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 11.2305 - val_loss: 13.1112 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 42/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 10.5557 - val_loss: 13.3680 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 43/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 10.3986 - val_loss: 12.7326 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 44/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 62ms/step - loss: 10.2142 - val_loss: 12.1459 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 45/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 62ms/step - loss: 9.8238 - val_loss: 12.1330 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 46/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 65ms/step - loss: 9.8035 - val_loss: 11.8799 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 47/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 9.6599 - val_loss: 11.9015 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 48/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 63ms/step - loss: 9.4097 - val_loss: 11.5299 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 49/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 65ms/step - loss: 9.4664 - val_loss: 11.3185 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 50/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 9.3072 - val_loss: 12.8338 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 51/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 66ms/step - loss: 8.9795 - val_loss: 10.9579 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 52/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 9.0194 - val_loss: 11.1916 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 53/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 64ms/step - loss: 8.8041 - val_loss: 14.2532 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 54/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 64ms/step - loss: 8.7503 - val_loss: 10.3767 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 55/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 8.3852 - val_loss: 10.9821 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 56/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 8.5747 - val_loss: 10.1828 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 57/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 8.2871 - val_loss: 10.2051 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 58/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 8.2721 - val_loss: 10.3197 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 59/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 7.9692 - val_loss: 9.6912 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 60/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 65ms/step - loss: 7.9604 - val_loss: 9.5756 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 61/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 64ms/step - loss: 7.9785 - val_loss: 9.4670 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 62/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 65ms/step - loss: 7.5266 - val_loss: 9.7073 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 63/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 7.6727 - val_loss: 9.4992 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 64/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 65ms/step - loss: 7.5023 - val_loss: 9.1637 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 65/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 63ms/step - loss: 7.2822 - val_loss: 9.0651 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 66/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 64ms/step - loss: 7.3193 - val_loss: 9.0097 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 67/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 65ms/step - loss: 7.2433 - val_loss: 9.1113 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 68/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 7.1213 - val_loss: 8.6671 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 69/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 64ms/step - loss: 7.0429 - val_loss: 8.8453 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 70/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 6.9211 - val_loss: 8.8643 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 71/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 6.7939 - val_loss: 8.5508 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 72/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 6.6670 - val_loss: 8.3568 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 73/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 6.5575 - val_loss: 8.3090 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 74/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 6.3607 - val_loss: 8.1061 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 75/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 6.2250 - val_loss: 7.9908 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 76/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 6.4029 - val_loss: 8.1041 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 77/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 6.2581 - val_loss: 8.4601 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 78/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 6.1408 - val_loss: 8.0886 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 79/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 6.0968 - val_loss: 7.9995 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 80/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 6.2170 - val_loss: 7.6498 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 81/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 63ms/step - loss: 5.9598 - val_loss: 7.4546 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 82/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 64ms/step - loss: 5.9559 - val_loss: 8.6267 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 83/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 5.9464 - val_loss: 7.4390 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 84/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 5.7809 - val_loss: 7.4926 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 85/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 63ms/step - loss: 5.6659 - val_loss: 7.2852 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 86/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 5.7275 - val_loss: 7.2944 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 87/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 5.5086 - val_loss: 7.1308 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 88/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 64ms/step - loss: 5.4979 - val_loss: 6.8956 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 89/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 66ms/step - loss: 5.5426 - val_loss: 7.0183 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 90/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 64ms/step - loss: 5.3230 - val_loss: 6.7943 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 91/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 64ms/step - loss: 5.3791 - val_loss: 6.7157 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 92/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 5.2709 - val_loss: 7.1708 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 93/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 5.4491 - val_loss: 6.5467 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 94/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 4.9818 - val_loss: 7.2768 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 95/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 5.3728 - val_loss: 6.5549 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 96/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 5.0125 - val_loss: 6.7706 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 97/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 63ms/step - loss: 5.0194 - val_loss: 6.5197 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 98/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 63ms/step - loss: 5.0817 - val_loss: 6.2344 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 99/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 63ms/step - loss: 5.0098 - val_loss: 6.6205 - learning_rate: 1.5593e-05\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 1.55931556946598e-05.\n",
      "Epoch 100/100\n",
      "\u001b[1m546/546\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 63ms/step - loss: 4.9274 - val_loss: 6.3018 - learning_rate: 1.5593e-05\n",
      "\u001b[94m\u001b[1mTraining ended: \u001b[0m\n",
      "'2024-12-06 11:22:49'\n",
      "\u001b[94m\u001b[1mTraining duration\u001b[0m\n",
      "'3437.04 seconds'\n"
     ]
    }
   ],
   "source": [
    "besthyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "nprint('besthyperparameters.values', besthyperparameters.values)\n",
    "model = tuner.hypermodel.build(besthyperparameters)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "lr_scheduler = callbacks.LearningRateScheduler(scheduler_training, verbose=verbose)\n",
    "start_time = time.time()\n",
    "nprint('Training started: ', time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()))\n",
    "with tensorflow.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        ts_train_features, \n",
    "        ts_train_targets, \n",
    "        epochs=epochs, \n",
    "        validation_data=(\n",
    "            ts_val_features, \n",
    "            ts_val_targets\n",
    "        ), \n",
    "        verbose=verbose,\n",
    "        batch_size=besthyperparameters.values['batch_size'],\n",
    "        callbacks=[\n",
    "            early_stopping, \n",
    "            lr_scheduler\n",
    "        ]\n",
    "    )\n",
    "nprint('Training ended: ', time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()))\n",
    "end_time = time.time()\n",
    "training_duration = end_time - start_time\n",
    "nprint('Training duration', '{:.2f} seconds'.format(training_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dcd7ee-5392-4258-950c-1565665ea3be",
   "metadata": {},
   "source": [
    "<h2>Saving trained model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71e801e-1d26-4629-9e6e-75ff346c042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype = 'CNN'\n",
    "\n",
    "cnn_model_name = '{}_{}'.format(dataset_name, modeltype)\n",
    "cnn_model_files_dir = os.path.join(out_models_dir, cnn_model_name)\n",
    "os.makedirs(cnn_model_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a0be72-309d-4ed7-8a63-e16cd9b2ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mCNN model path\u001b[0m\n",
      "'./working\\\\models\\\\FD003_CNN\\\\FD003_CNN.keras'\n"
     ]
    }
   ],
   "source": [
    "ftype = 'keras'\n",
    "cnn_model_file_name = '{}.{}'.format(cnn_model_name, ftype)\n",
    "cnn_model_path = os.path.join(cnn_model_files_dir, cnn_model_file_name)\n",
    "model.save(filepath=cnn_model_path)\n",
    "nprint('CNN model path', cnn_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010d3f5-88aa-4a2f-a050-4de929a443d5",
   "metadata": {},
   "source": [
    "<h2>Displaying training model metrics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6acd028-1f57-4951-848c-f5919a3d9e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mCNN model history path\u001b[0m\n",
      "'./working\\\\models\\\\FD003_CNN\\\\FD003_CNN_history.json'\n",
      "    loss  val_loss  learning_rate  epoch\n",
      "5.053385  6.770556       0.000016     95\n",
      "5.027052  6.519745       0.000016     96\n",
      "4.968455  6.234449       0.000016     97\n",
      "4.995384  6.620540       0.000016     98\n",
      "4.922241  6.301758       0.000016     99\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAGwCAYAAABPSaTdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABbiklEQVR4nO3deXhU1f3H8fedNXtCgCREEkBlC4IiKAYsWkERqYpQrYqKS7FioCLFBXdrFatWaati9adgFaSi4oIrIKCyi7JjBEXDliBbNpJJZub+/phkIAKaQGZuMvm8nuc+M3PvmZnv3Frz8Zxz7zFM0zQRERERiVA2qwsQERERCSWFHREREYloCjsiIiIS0RR2REREJKIp7IiIiEhEU9gRERGRiKawIyIiIhHNYXUBDYHf72f79u3Ex8djGIbV5YiIiEgtmKZJcXEx6enp2GxH7r9R2AG2b99ORkaG1WWIiIjIUdiyZQutW7c+4nGFHSA+Ph4InKyEhASLqxEREZHaKCoqIiMjI/h3/EgUdiA4dJWQkKCwIyIi0sj82hQUTVAWERGRiKawIyIiIhFNYUdEREQimubsiIhIWPn9fioqKqwuQxoBp9OJ3W4/5s9R2BERkbCpqKhg8+bN+P1+q0uRRiIpKYm0tLRjug+ewo6IiISFaZrs2LEDu91ORkbGL94ETsQ0Tfbv38/OnTsBaNWq1VF/lsKOiIiEhdfrZf/+/aSnpxMTE2N1OdIIREdHA7Bz505SUlKOekjL0lj9wAMPYBhGja1Tp07B4+Xl5eTk5NC8eXPi4uIYOnQoBQUFNT4jLy+PQYMGERMTQ0pKCrfddhterzfcP0VERH6Fz+cDwOVyWVyJNCbVwbiysvKoP8Pynp0uXbowZ86c4GuH40BJt956K++//z4zZswgMTGRUaNGMWTIEBYuXAgE/o8zaNAg0tLSWLRoETt27OCaa67B6XTyyCOPhP23iIjIr9MahFIX9fHPi+Vhx+FwkJaWdsj+wsJCXnzxRaZNm8Y555wDwOTJk+ncuTNLlizhjDPO4JNPPmH9+vXMmTOH1NRUTjnlFB566CHuuOMOHnjgAf3Xg4iIiFh/n52NGzeSnp7O8ccfz7Bhw8jLywNgxYoVVFZW0r9//2DbTp06kZmZyeLFiwFYvHgxXbt2JTU1NdhmwIABFBUVsW7duiN+p8fjoaioqMYmIiIikcnSsNOrVy+mTJnCRx99xKRJk9i8eTO/+c1vKC4uJj8/H5fLRVJSUo33pKamkp+fD0B+fn6NoFN9vPrYkUyYMIHExMTgphXPRUTkSM4++2zGjBljdRlyDCwdxho4cGDwebdu3ejVqxdt2rTh9ddfD87ADoXx48czduzY4OvqVVPr2+4SD8XlXtISo4hyHvtNkURERKTuLB/GOlhSUhIdOnRg06ZNpKWlUVFRwb59+2q0KSgoCM7xSUtLO+TqrOrXh5sHVM3tdgdXOA/lSucXP7OQs5+Yz/odGiYTERGxSoMKOyUlJXz33Xe0atWKHj164HQ6mTt3bvB4bm4ueXl5ZGdnA5Cdnc2aNWuCNxwCmD17NgkJCWRlZYW9/p+Lcwc6zkrKdSm8iMjPmabJ/gqvJZtpmkdV8969e7nmmmto1qwZMTExDBw4kI0bNwaP//jjj1x44YU0a9aM2NhYunTpwgcffBB877Bhw2jZsiXR0dG0b9+eyZMn18u5lF9m6TDWuHHjuPDCC2nTpg3bt2/n/vvvx263c8UVV5CYmMgNN9zA2LFjSU5OJiEhgdGjR5Odnc0ZZ5wBwHnnnUdWVhZXX301jz32GPn5+dxzzz3k5OTgdrut/GkAxEdVhR2Pwo6IyM+VVfrIuu9jS757/V8HEOOq+5/Aa6+9lo0bN/Luu++SkJDAHXfcwQUXXMD69etxOp3k5ORQUVHBZ599RmxsLOvXrycuLg6Ae++9l/Xr1/Phhx/SokULNm3aRFlZWX3/NDkMS8PO1q1bueKKK9i9ezctW7bkzDPPZMmSJbRs2RKAp556CpvNxtChQ/F4PAwYMIBnn302+H673c6sWbMYOXIk2dnZxMbGMnz4cP76179a9ZNqCPbsKOyIiDR61SFn4cKF9O7dG4CpU6eSkZHB22+/zaWXXkpeXh5Dhw6la9euABx//PHB9+fl5dG9e3d69uwJQNu2bcP+G5oqS8PO9OnTf/F4VFQUzzzzDM8888wR27Rp0ybYRdjQxGoYS0TkiKKddtb/dYBl311XGzZswOFw0KtXr+C+5s2b07FjRzZs2ADAn//8Z0aOHMknn3xC//79GTp0KN26dQNg5MiRDB06lK+++orzzjuPwYMHB0OThFaDmrMTaTSMJSJyZIZhEONyWLKF6i7Of/zjH/n++++5+uqrWbNmDT179uTf//43ELgC+ccff+TWW29l+/bt9OvXj3HjxoWkDqlJYSeENIwlIhI5OnfujNfrZenSpcF9u3fvJjc3t8ZFMRkZGdx000289dZb/OUvf+GFF14IHmvZsiXDhw/n1VdfZeLEiTz//PNh/Q1NleXLRUSyOLcTgGINY4mINHrt27fn4osvZsSIEfznP/8hPj6eO++8k+OOO46LL74YgDFjxjBw4EA6dOjA3r17mTdvHp07dwbgvvvuo0ePHnTp0gWPx8OsWbOCxyS01LMTQnFVw1il6tkREYkIkydPpkePHvzud78jOzsb0zT54IMPcDoD/3Hr8/nIycmhc+fOnH/++XTo0CF4YY3L5WL8+PF069aNvn37Yrfbf3XuqtQPwzzamw1EkKKiIhITEyksLKzXGwy+vnwLt7+5mnM6pfDStafV2+eKiDRG5eXlbN68mXbt2hEVFWV1OdJI/NI/N7X9+62enRDS1VgiIiLWU9gJoephrGINY4mIiFhGYSeEDlyNVWlxJSIiIk2Xwk4IxQcnKPssrkRERKTpUtgJIS0EKiIiYj2FnRCqnqBc4fPj8ap3R0RExAoKOyFU3bMD6t0RERGxisJOCNltBjGuwGJzWjJCRETEGgo7Iab1sURERKylsBNi1ffa0TCWiEjT1LZtWyZOnFirtoZh8Pbbb4e0nqZIYSfE4tWzIyIiYimFnRCLVdgRERGxlMJOiFXP2SnWMJaISE2mCRWl1my1XAP7+eefJz09Hb/fX2P/xRdfzPXXX893333HxRdfTGpqKnFxcZx22mnMmTOn3k7RmjVrOOecc4iOjqZ58+bceOONlJSUBI/Pnz+f008/ndjYWJKSkujTpw8//vgjAKtWreK3v/0t8fHxJCQk0KNHD7788st6q60xcfx6EzkWccG7KCvsiIjUULkfHkm35rvv2g6u2F9tdumllzJ69GjmzZtHv379ANizZw8fffQRH3zwASUlJVxwwQU8/PDDuN1u/vvf/3LhhReSm5tLZmbmMZVYWlrKgAEDyM7OZvny5ezcuZM//vGPjBo1iilTpuD1ehk8eDAjRozgtddeo6KigmXLlmEYBgDDhg2je/fuTJo0CbvdzsqVK3E6ncdUU2OlsBNimrMjItJ4NWvWjIEDBzJt2rRg2HnjjTdo0aIFv/3tb7HZbJx88snB9g899BAzZ87k3XffZdSoUcf03dOmTaO8vJz//ve/xMYGgtnTTz/NhRdeyN///necTieFhYX87ne/44QTTgCgc+fOwffn5eVx22230alTJwDat29/TPU0Zgo7IRZc+VzDWCIiNTljAj0sVn13LQ0bNowRI0bw7LPP4na7mTp1Kpdffjk2m42SkhIeeOAB3n//fXbs2IHX66WsrIy8vLxjLnHDhg2cfPLJwaAD0KdPH/x+P7m5ufTt25drr72WAQMGcO6559K/f38uu+wyWrVqBcDYsWP54x//yCuvvEL//v259NJLg6GoqdGcnRDTBGURkSMwjMBQkhVb1VBPbVx44YWYpsn777/Pli1b+Pzzzxk2bBgA48aNY+bMmTzyyCN8/vnnrFy5kq5du1JRURGqs1bD5MmTWbx4Mb179+Z///sfHTp0YMmSJQA88MADrFu3jkGDBvHpp5+SlZXFzJkzw1JXQ6OwE2LxWgxURKRRi4qKYsiQIUydOpXXXnuNjh07cuqppwKwcOFCrr32Wi655BK6du1KWloaP/zwQ718b+fOnVm1ahWlpaXBfQsXLsRms9GxY8fgvu7duzN+/HgWLVrESSedxLRp04LHOnTowK233sonn3zCkCFDmDx5cr3U1tgo7IRY8KaC6tkREWm0hg0bxvvvv89LL70U7NWBwDyYt956i5UrV7Jq1SquvPLKQ67cOpbvjIqKYvjw4axdu5Z58+YxevRorr76alJTU9m8eTPjx49n8eLF/Pjjj3zyySds3LiRzp07U1ZWxqhRo5g/fz4//vgjCxcuZPny5TXm9DQlmrMTYnHuwMx3hR0RkcbrnHPOITk5mdzcXK688srg/ieffJLrr7+e3r1706JFC+644w6Kiorq5TtjYmL4+OOPueWWWzjttNOIiYlh6NChPPnkk8Hj33zzDS+//DK7d++mVatW5OTk8Kc//Qmv18vu3bu55pprKCgooEWLFgwZMoQHH3ywXmprbAzTrOXNBiJYUVERiYmJFBYWkpCQUK+fvfi73VzxwhJOTIljztiz6vWzRUQak/LycjZv3ky7du2IioqyuhxpJH7pn5va/v3WMFaIxWnOjoiIiKUUdkJMc3ZERARg6tSpxMXFHXbr0qWL1eVFNM3ZCbG4gy499/tNbLbaX+4oIiKR46KLLqJXr16HPdZU72wcLgo7IRYfdeAU76/0BcOPiIg0LfHx8cTHx1tdRpOkYawQcztsOKp6czRvR0REJPwUdkLMMIzgvJ39Rbvg5QthxRRrixIREWlCFHbCINYVCDv2bz+CzZ/Bly9ZXJGIiEjTobATBtXzduw/rQvs8HosrEZERKRpUdgJg+pJydG71wd2KOyIiIiEjcJOGATm7JjE7fsmsMMXntVwRUTk2J199tmMGTPG6jJ44IEHOOWUU6wuo1FS2AmDOLeDNPbgrtwX2KGeHRERqaNx48Yxd+5cq8uolWuvvZbBgwdbXUaQwk4YxLkddLblHdihnh0REalSUVG7vwlxcXE0b948xNX8ssrKSku//2gp7IRBnNtBlvHjgR3q2RERwTRN9lfut2Q72jWwPR4P48aN47jjjiM2NpZevXoxf/784PHdu3dzxRVXcNxxxxETE0PXrl157bXXanzG2WefzahRoxgzZgwtWrRgwIABzJ8/H8MwmDt3Lj179iQmJobevXuTm5sbfN/Ph7Gqe0+eeOIJWrVqRfPmzcnJyakRSHbs2MGgQYOIjo6mXbt2TJs2jbZt2zJx4sRa/V7DMJg0aRIXXXQRsbGxPPzww/h8Pm644QbatWtHdHQ0HTt25J///GeNOl9++WXeeecdDMPAMIzgOdqyZQuXXXYZSUlJJCcnc/HFF/PDDz/U+vwfLd3ONwziohycaDso7Pg8YJpgaOkIEWm6yrxl9Jp2+OUTQm3plUuJccbU+X2jRo1i/fr1TJ8+nfT0dGbOnMn555/PmjVraN++PeXl5fTo0YM77riDhIQE3n//fa6++mpOOOEETj/99ODnvPzyy4wcOZKFCxcCgVACcPfdd/OPf/yDli1bctNNN3H99dcH2xzOvHnzaNWqFfPmzWPTpk384Q9/4JRTTmHEiBEAXHPNNezatYv58+fjdDoZO3YsO3furNNvfuCBB3j00UeZOHEiDocDv99P69atmTFjBs2bN2fRokXceOONtGrVissuu4xx48axYcMGioqKmDx5MgDJyclUVlYyYMAAsrOz+fzzz3E4HPztb3/j/PPPZ/Xq1bhcrjrVVRcKO2FwSM8OBIayHG5rChIRkTrLy8tj8uTJ5OXlkZ6eDgTm0Xz00UdMnjyZRx55hOOOO45x48YF3zN69Gg+/vhjXn/99Rphp3379jz22GPB19Vh5+GHH+ass84C4M4772TQoEGUl5cTFRV12JqaNWvG008/jd1up1OnTgwaNIi5c+cyYsQIvvnmG+bMmcPy5cvp2bMnAP/3f/9H+/bt6/S7r7zySq677roa+x588MHg83bt2rF48WJef/11LrvsMuLi4oiOjsbj8ZCWlhZs9+qrr+L3+/m///s/jKr/2J88eTJJSUnMnz+f8847r0511YXCThg0c1TQ1iioudPrUdgRkSYt2hHN0iuXWvbddbVmzRp8Ph8dOnSosd/j8QTn0vh8Ph555BFef/11tm3bRkVFBR6Ph5iYmr1IPXr0OOx3dOvWLfi8VatWAOzcuZPMzMzDtu/SpQt2u73Ge9asWQNAbm4uDoeDU089NXj8xBNPpFmzZrX9yQDBoHSwZ555hpdeeom8vDzKysqoqKj41SvFVq1axaZNmw5ZH6y8vJzvvvuuTjXVlcJOGKSVf4/NMNlra0Yz/97ATk1SFpEmzjCMoxpKskpJSQl2u50VK1bUCBgQmDwM8Pjjj/PPf/6TiRMn0rVrV2JjYxkzZswhk5BjY2MP+x0Hr35e3fvh9/uPWNPPV0s3DOMX2x+Nn9c6ffp0xo0bxz/+8Q+ys7OJj4/n8ccfZ+nSXw6uJSUl9OjRg6lTpx5yrGXLlvVa888p7IRBy9JvAfjOdjw9jTWBoKNJyiIijUr37t3x+Xzs3LmT3/zmN4dts3DhQi6++GKuuuoqIBBUvv32W7KyssJZKgAdO3bE6/Xy9ddfB3uSNm3axN69e4/pcxcuXEjv3r25+eabg/t+3jPjcrnw+Xw19p166qn873//IyUlhYSEhGOqoa50NVYYNCsOzKb/xmgL9qqhK2+5dQWJiEiddejQgWHDhnHNNdfw1ltvsXnzZpYtW8aECRN4//33gcBcnNmzZ7No0SI2bNjAn/70JwoKCn7lk0OjU6dO9O/fnxtvvJFly5bx9ddfc+ONNxIdHR3sNToa7du358svv+Tjjz/m22+/5d5772X58uU12rRt25bVq1eTm5vLrl27qKysZNiwYbRo0YKLL76Yzz//nM2bNzN//nz+/Oc/s3Xr1mP9ub9IYScMqu+cvM6bAY6q2eYaxhIRaXQmT57MNddcw1/+8hc6duzI4MGDWb58eXBOzT333MOpp57KgAEDOPvss0lLS7P05nr//e9/SU1NpW/fvlxyySWMGDGC+Pj4I054ro0//elPDBkyhD/84Q/06tWL3bt31+jlARgxYgQdO3akZ8+etGzZkoULFxITE8Nnn31GZmYmQ4YMoXPnztxwww2Ul5eHvKfHMI/2ZgMRpKioiMTERAoLC+v/hPt9+B85Dpu3jPO9/+CjZv+A4u1w4wJIP6V+v0tEpAErLy9n8+bNtGvX7pj+2MrR27p1KxkZGcyZM4d+/fpZXU6t/NI/N7X9+605O6G2ZzM2bxllpotvvamYdhcGqGdHRERC7tNPP6WkpISuXbuyY8cObr/9dtq2bUvfvn2tLi2sNIwVavmrAcg1M/Bjwxecs6MJyiIiElqVlZXcdddddOnShUsuuYSWLVsGbzA4depU4uLiDrt16dLF6tLrlXp2Qq1gLQC5tAXAb6u6TNCnsCMiIqE1YMAABgwYcNhjF110Eb16Hf4O1j+/pL2xU9gJtfzAzZ1+cBwPFeA1XLhAPTsiImKp+Pj4Q27wF6k0jBVq+YGena3uEwDwGlVpWWFHRJooXRcjdVEfN0lUz04ole4OXHkF7Iw+AfZWUlkddjRBWUSaGKfTiWEY/PTTT7Rs2fKY7vUikc80TSoqKvjpp5+w2WzHtFCowk4oFQSGsEg+Hnt0ArCbCtSzIyJNk91up3Xr1mzdupUffvjB6nKkkYiJiSEzMxOb7egHoxR2Qqlqvg6pJxHrCZzqYNhRz46INEFxcXG0b9+eyspKq0uRRsBut+NwOI65F1BhJ5Sq5uuQ1o34/KqwY1adcvXsiEgTZbfbD1lIUySUNEE5lKp7dtJOIi4qEHLKg2FHa2OJiIiEQ4MJO48++iiGYTBmzJjgvvLycnJycmjevDlxcXEMHTr0kAXV8vLyGDRoEDExMaSkpHDbbbfh9XrDXP1hmCakdIbk4yH1JOLcPws7GsYSEREJiwYxjLV8+XL+85//0K1btxr7b731Vt5//31mzJhBYmIio0aNYsiQISxcuBAAn8/HoEGDSEtLY9GiRezYsYNrrrkGp9PJI488YsVPOcAw4PcvBl/GRW0CoMyvYSwREZFwsrxnp6SkhGHDhvHCCy/QrFmz4P7CwkJefPFFnnzySc455xx69OjB5MmTWbRoEUuWLAHgk08+Yf369bz66quccsopDBw4kIceeohnnnmGiooj95x4PB6KiopqbKFW3bOz31c1Tq2eHRERkbCwPOzk5OQwaNAg+vfvX2P/ihUrqKysrLG/U6dOZGZmsnjxYgAWL15M165dSU1NDbYZMGAARUVFrFu37ojfOWHCBBITE4NbRkZGPf+qQwXDjnp2REREwsrSsDN9+nS++uorJkyYcMix/Px8XC4XSUlJNfanpqaSn58fbHNw0Kk+Xn3sSMaPH09hYWFw27JlyzH+kl9XHXZKgz07CjsiIiLhYNmcnS1btnDLLbcwe/ZsoqKiwvrdbrcbt9sd1u+svhqrxFsVdtSzIyIiEhaW9eysWLGCnTt3cuqpp+JwOHA4HCxYsIB//etfOBwOUlNTqaioYN++fTXeV1BQQFpaGgBpaWmHXJ1V/bq6TUMR7w7cTLDEV3XKFXZERETCwrKw069fP9asWcPKlSuDW8+ePRk2bFjwudPpZO7cucH35ObmkpeXR3Z2NgDZ2dmsWbOGnTt3BtvMnj2bhIQEsrKywv6bfkl1z05xpSYoi4iIhJNlw1jx8fGcdNJJNfbFxsbSvHnz4P4bbriBsWPHkpycTEJCAqNHjyY7O5szzjgDgPPOO4+srCyuvvpqHnvsMfLz87nnnnvIyckJ+zDVr4l1B0JOsdcGTtSzIyIiEiYN4j47R/LUU09hs9kYOnQoHo+HAQMG8OyzzwaP2+12Zs2axciRI8nOziY2Npbhw4fz17/+1cKqD696GKvc1NpYIiIi4WSYpmlaXYTVioqKSExMpLCwkISEhJB8h2manHj3h5zNl7zo+gcc1wNGfBqS7xIREWkKavv32/L77DQVhmEQ53YcWPXcq54dERGRcFDYCaM4t4OK4DCW5uyIiIiEg8JOGAV6dnQHZRERkXBS2AmjuCgHHjRBWUREJJwUdsIozn1Q2FHPjoiISFgo7IRRXJSGsURERMJNYSeM4jVBWUREJOwUdsKoxgRlvxf8fmsLEhERaQIUdsIo9uD77IB6d0RERMJAYSeM4g++Ggs0b0dERCQMFHbCKM7twIsdP0Zghy4/FxERCTmFnTCKi3IABt7g5eflltYjIiLSFCjshFGcOzA5ucLQ+lgiIiLhorATRgnRgZBTYVZdkaUJyiIiIiGnsBNGiVVhx6MbC4qIiISNwk4YVYedMr/WxxIREQkXhZ0wqg47FZqgLCIiEjYKO2HktNuIcdkPWh9LPTsiIiKhprATZonRzgM9O5qgLCIiEnIKO2GWGO08cDWWJiiLiIiEnMJOmCXU6NnRMJaIiEioKeyEWWK088D6WOrZERERCTmFnTALzNnRMJaIiEi4KOyEmSYoi4iIhJfCTpglRjvxmLr0XEREJFwUdsJMPTsiIiLhpbATZjXCjubsiIiIhJzCTpjVuBpLl56LiIiEnMJOmCXUuKmg1sYSEREJNYWdMKs5jKWeHRERkVBT2Amzg++zY2rOjoiISMgp7ITZwT073goNY4mIiISawk6YuRw2/HY3oLAjIiISDgo7FnA4owDwVZZZXImIiEjkU9ixgNNdHXY0Z0dERCTUFHYs4HQFwo6psCMiIhJyCjsWcEVFA2BquQgREZGQU9ixgNsdCDuG7rMjIiIScgo7FnBHV4UdLRchIiIScgo7FoiOjgHA5tcwloiISKgp7FigOuzY/erZERERCTWFHQvExlSFHbPS4kpEREQin8KOBarDjkNhR0REJOQUdiwQFxsLgB0/+LwWVyMiIhLZFHYsEB8bd+CF7rUjIiISUgo7FkiIiw0+92sxUBERkZBS2LFAQmwUXjNw6kvLSi2uRkREJLIp7FggymmnAicAxSX7La5GREQksinsWKTSCISdkv3q2REREQklhR2LeKvCzv796tkREREJJYUdi3gNF6CwIyIiEmoKOxbx2wJhp0wTlEVEREJKYccipr067JRZXImIiEhkU9ixSHXY8ZQr7IiIiISSwo5VHG5AYUdERCTUFHasUhV2KjwKOyIiIqGksGMRmyMKgEqFHRERkZCyNOxMmjSJbt26kZCQQEJCAtnZ2Xz44YfB4+Xl5eTk5NC8eXPi4uIYOnQoBQUFNT4jLy+PQYMGERMTQ0pKCrfddhteb8NfSdzuDPTseLU2loiISEhZGnZat27No48+yooVK/jyyy8555xzuPjii1m3bh0At956K++99x4zZsxgwYIFbN++nSFDhgTf7/P5GDRoEBUVFSxatIiXX36ZKVOmcN9991n1k2rN7gr07PgqFXZERERCyTBN07S6iIMlJyfz+OOP8/vf/56WLVsybdo0fv/73wPwzTff0LlzZxYvXswZZ5zBhx9+yO9+9zu2b99OamoqAM899xx33HEHP/30Ey6X67Df4fF48Hg8wddFRUVkZGRQWFhIQkJC6H8kUPjaCBJzX+efxjBuuf/ZsHyniIhIJCkqKiIxMfFX/343mDk7Pp+P6dOnU1paSnZ2NitWrKCyspL+/fsH23Tq1InMzEwWL14MwOLFi+natWsw6AAMGDCAoqKiYO/Q4UyYMIHExMTglpGREbofdgROd6Bnx1/poYHlTRERkYhiedhZs2YNcXFxuN1ubrrpJmbOnElWVhb5+fm4XC6SkpJqtE9NTSU/Px+A/Pz8GkGn+nj1sSMZP348hYWFwW3Lli31+6NqweWOBsBJJSWehj/HSEREpLFyWF1Ax44dWblyJYWFhbzxxhsMHz6cBQsWhPQ73W43brc7pN/xaxxVc3bcVFJYVkl8lNPSekRERCKV5T07LpeLE088kR49ejBhwgROPvlk/vnPf5KWlkZFRQX79u2r0b6goIC0tDQA0tLSDrk6q/p1dZsGyx4IW66qsCMiIiKhYXnY+Tm/34/H46FHjx44nU7mzp0bPJabm0teXh7Z2dkAZGdns2bNGnbu3BlsM3v2bBISEsjKygp77XXiCEyeduFV2BEREQkhS4exxo8fz8CBA8nMzKS4uJhp06Yxf/58Pv74YxITE7nhhhsYO3YsycnJJCQkMHr0aLKzsznjjDMAOO+888jKyuLqq6/mscceIz8/n3vuuYecnBzLh6l+VXXPjlFJkcKOiIhIyFgadnbu3Mk111zDjh07SExMpFu3bnz88cece+65ADz11FPYbDaGDh2Kx+NhwIABPPvsgcu07XY7s2bNYuTIkWRnZxMbG8vw4cP561//atVPqr2q5SLc6tkREREJqQZ3nx0r1PY6/Xq1Ygq8dwuf+Hrww7kvcGPfE8LzvSIiIhGi0d1np8mxV/fsaIKyiIhIKCnsWEUTlEVERMJCYccqB01QLizTTQVFRERCRWHHKo4D99nR1VgiIiKho7BjFbuGsURERMJBYccqjgPLRahnR0REJHQUdqxSPUHZ0NVYIiIioXRUYeerr75izZo1wdfvvPMOgwcP5q677qKioqLeiotowbWxAsNYut2RiIhIaBxV2PnTn/7Et99+C8D333/P5ZdfTkxMDDNmzOD222+v1wIj1kETlL1+k/0VPosLEhERiUxHFXa+/fZbTjnlFABmzJhB3759mTZtGlOmTOHNN9+sz/oiV9UEZTeBy841lCUiIhIaRxV2TNPE7/cDMGfOHC644AIAMjIy2LVrV/1VF8mq18YyKgFTYUdERCREjirs9OzZk7/97W+88sorLFiwgEGDBgGwefNmUlNT67XAiOU4sCq7Lj8XEREJnaMKOxMnTuSrr75i1KhR3H333Zx44okAvPHGG/Tu3bteC4xY9oPDjq7IEhERCRXH0bypW7duNa7Gqvb4449jt9uPuagmoWrODgR6drbs2W9hMSIiIpHrqHp2li9fztKlSw/Zv2rVKlatWnXMRTUJNhvYnECgZ2f99iKLCxIREYlMRxV2cnJy2LJlyyH7t23bRk5OzjEX1WRUX35ueFm/Q2FHREQkFI4q7Kxfv55TTz31kP3du3dn/fr1x1xUk3HQvXY27SyhvFL32hEREalvRxV23G43BQUFh+zfsWMHDsdRTQNqmqomKbeMMvH6TTbtLLG4IBERkchzVGHnvPPOY/z48RQWFgb37du3j7vuuotzzz233oqLeFXrY3VoEXhct73wl1qLiIjIUTiqbpgnnniCvn370qZNG7p37w7AypUrSU1N5ZVXXqnXAiNaVc/Oicku2IImKYuIiITAUYWd4447jtWrVzN16lRWrVpFdHQ01113HVdccQVOp7O+a4xcVT07xycH/mfQJGUREZH6d9QTbGJjY7nxxhvrs5amp6pnp01iICBu2FGM329isxlWViUiIhJRah123n33XQYOHIjT6eTdd9/9xbYXXXTRMRfWJDiiAGgVAy6HjRKPl7w9+2nbItbiwkRERCJHrcPO4MGDyc/PJyUlhcGDBx+xnWEY+Hy6hLpWqoax7GYlndLiWb21kPU7ihR2RERE6lGtr8by+/2kpKQEnx9pU9Cpg+r1sbweslolAJqkLCIiUt/qfOl5ZWUl/fr1Y+PGjaGop2mp6tnBV0FWelXY0SRlERGRelXnsON0Olm9enUoaml6DurZ6ZKunh0REZFQOKqbCl511VW8+OKL9V1L0xPs2fHQMS0Bw4D8onJ2l3isrUtERCSCHNWl516vl5deeok5c+bQo0cPYmNrTqh98skn66W4iFd1NRZeD3FuB22bx7J5VynrdxTxm/Ytra1NREQkQhxV2Fm7dm1wIdBvv/22XgtqUg4axgLIapUQCDvbFXZERETqy1GFnXnz5tV3HU3TQROUAbLSE3h/zQ5NUhYREalHRzVn5/rrr6e4uPiQ/aWlpVx//fXHXFST8fOeHU1SFhERqXdHFXZefvllysrKDtlfVlbGf//732Muqsk4aIIyQJeqe+1891MJZRW6X5GIiEh9qNMwVlFREaZpYpomxcXFREVFBY/5fD4++OCD4I0HpRaCPTuBYayW8W5axLnYVVJBbkExp2QkWVebiIhIhKhT2ElKSsIwDAzDoEOHDoccNwyDBx98sN6Ki3iO6rBTDgTOX+dWCXy+cRfrtxcp7IiIiNSDOoWdefPmYZom55xzDm+++SbJycnBYy6XizZt2pCenl7vRUas6rBTNUEZAvN2Pt+4i/U7Ci0qSkREJLLUKeycddZZAGzevJnMzEwMwwhJUU3GzyYoA3RJTwRgnSYpi4iI1IujmqDcpk0bvvjiC6666ip69+7Ntm3bAHjllVf44osv6rXAiPazS8+B4IKg3+woxuc3rahKREQkohxV2HnzzTcZMGAA0dHRfPXVV3g8gZ6JwsJCHnnkkXotMKIdpmenXYtYop12yip9bN5ValFhIiIikeOows7f/vY3nnvuOV544QWcTmdwf58+ffjqq6/qrbiI97NLzwHsNoNOreIBWLdd83ZERESO1VGFndzcXPr27XvI/sTERPbt23esNTUdB62NdTCtgC4iIlJ/jirspKWlsWnTpkP2f/HFFxx//PHHXFSTcZhhLNAkZRERkfp0VGFnxIgR3HLLLSxduhTDMNi+fTtTp05l3LhxjBw5sr5rjFyHmaAMB3p21m0vxDQ1SVlERORYHNVCoHfeeSd+v59+/fqxf/9++vbti9vtZty4cYwePbq+a4xcR+jZ6ZAaj91msHd/JTsKy0lPiragOBERkchwVGHHMAzuvvtubrvtNjZt2kRJSQlZWVnExcXVd32R7Qg9O1FOO+1T4vgmv5h124sUdkRERI5BncJObVc0f+mll46qmCYnOEG5/JBDWekJfJNfzPrtRZyblRrmwkRERCJHncLOlClTaNOmDd27d9dckvpQPYzl94LfD7YDU6iyWiXwFttqf/l5yU/wxZNwxs2QlBGCYkVERBqnOoWdkSNH8tprr7F582auu+46rrrqqhrrY0kdVQ9jQeBeO7YDw1V1viLr8ydg6XPgq4RBT9RnlSIiIo1ana7GeuaZZ9ixYwe333477733HhkZGVx22WV8/PHH6uk5GtU9O3DIJOWsqiuytu0rY9/+mnN6DitvSeBxz3f1VZ2IiEhEqPOl5263myuuuILZs2ezfv16unTpws0330zbtm0pKSkJRY2Ry37g7tM/n6ScGO0kIznQ0/OrNxes2A8FawPP9/5QjwWKiIg0fkd1n53gm202DMPANE18Pl991dR0GMYRLz8H6NKqlkNZ278OzPsB2JcHfv1vISIiUq3OYcfj8fDaa69x7rnn0qFDB9asWcPTTz9NXl6eLj0/GkdYMgJq3lzwF21ZeuC53wtF2+qrOhERkUavThOUb775ZqZPn05GRgbXX389r732Gi1atAhVbU2DwwUeaiwGWq3LcdVh51d6drYur/l67w+QlFk/9YmIiDRydQo7zz33HJmZmRx//PEsWLCABQsWHLbdW2+9VS/FNQm/NIxVdUXWdz+VUF7pI8ppP/T9pglblgWeRydD2Z5A2Gl36EKtIiIiTVGdws4111yDYRihqqVpOsJdlAFS4t20iHOxq6SCb/KLOSUj6dD3790M+3eBzQmdLoCvX9UkZRERkYPU+aaCUs9+oWfHMAw6t0rg8427WLe98PBhZ0vVEFark6Flp8DzvT+GplYREZFG6JiuxpJ68As9O1CLmwturRrCyjgdmrUNPFfPjoiISJClYWfChAmcdtppxMfHk5KSwuDBg8nNza3Rpry8nJycHJo3b05cXBxDhw6loKCgRpu8vDwGDRpETEwMKSkp3HbbbXi93nD+lKP3C+tjwcFXZB0h7FTP12l9msKOiIjIYVgadhYsWEBOTg5Llixh9uzZVFZWct5551FaWhpsc+utt/Lee+8xY8YMFixYwPbt2xkyZEjwuM/nY9CgQVRUVLBo0SJefvllpkyZwn333WfFT6q76rDjKT7s4eqw882OIrw+f82DFaVQsC7wPON0SGoTeL5/1xE/T0REpKmp05yd+vbRRx/VeD1lyhRSUlJYsWIFffv2pbCwkBdffJFp06ZxzjnnADB58mQ6d+7MkiVLOOOMM/jkk09Yv349c+bMITU1lVNOOYWHHnqIO+64gwceeACXy3XI93o8HjyeA3Nkiopquf5UKKR2gc0LApePn3LlIYfbNo8l1mWntMLH97tK6ZAaf+Dgtq/A9EF8OiS2DuwLXpH1I6SdFKYfISIi0nA1qDk7hYWBm+dVLy66YsUKKisr6d+/f7BNp06dyMzMZPHixQAsXryYrl27kpqaGmwzYMAAioqKWLdu3WG/Z8KECSQmJga3jAwLVwlv+5vA4+bPD3vYZgtMUgaYvmwLFd6DencOnq9TTUNZIiIiNTSYsOP3+xkzZgx9+vThpJMCPRL5+fm4XC6SkpJqtE1NTSU/Pz/Y5uCgU328+tjhjB8/nsLCwuC2ZcuWev41ddAmGzBg90YoPny952YFfs9LCzczYOJnzN1QEFh4tfpKLIUdERGRI7J0GOtgOTk5rF27li+++CLk3+V2u3G73b/eMByim0FaV8hfDT98AV1/f0iTEb85nuRYF3//KJfNu0q54eUv+c2JzZmyayl2gNYKOyIiIkfSIHp2Ro0axaxZs5g3bx6tW7cO7k9LS6OiooJ9+/bVaF9QUEBaWlqwzc+vzqp+Xd2mwau+2/EPRx7KurRnBvPGncVNZ52Ay24j77t12Mv3YNpd0KrbgcbVYWef7rUjIiICFocd0zQZNWoUM2fO5NNPP6Vdu3Y1jvfo0QOn08ncuXOD+3Jzc8nLyyM7OxuA7Oxs1qxZw86dO4NtZs+eTUJCAllZWeH5Iceq7ZmBxx9+uVcrPsrJnQM7MXtsX86O2QxAUVIXcBzUS6WeHRERkRosHcbKyclh2rRpvPPOO8THxwfn2CQmJhIdHU1iYiI33HADY8eOJTk5mYSEBEaPHk12djZnnHEGAOeddx5ZWVlcffXVPPbYY+Tn53PPPfeQk5PTcIaqfk1m9bydTVC0AxJa1Ty+axOsmAzp3eHE/rRpnsSgZlthF6w2OvCbg9s2q7r8fO+P4PeDrUF03omIiFjG0rAzadIkAM4+++wa+ydPnsy1114LwFNPPYXNZmPo0KF4PB4GDBjAs88+G2xrt9uZNWsWI0eOJDs7m9jYWIYPH85f//rXcP2MYxedFBiK2rEq0LvT7dKax98dDXmLAs9tDsjM5uTSjQDM2tOa3n4Tu61qzbKE1mDYA6uol+RDQnr4foeIiEgDZGnYMU3zV9tERUXxzDPP8MwzzxyxTZs2bfjggw/qs7Twa/ubqrDzec2ws/3rQNCxOSD5BNiVCz98TnWf1fz97fg6by892wYu18fugKSMwDDW3h8UdkREpMnTGEdDUX2/nZ9PUl4S6P2iyxAYtQz+/DUMmAAn9GNu8uUUkMzs9TUnaGvejoiIyAEKOw1Fm2wwbLDneyjcFthXtAPWvhl4nn1z4DH5+MDzq9+i/OwHAPh4XX7NXjKFHRERkSCFnYYiKhFanRx4/uPCwOPy/wO/NzCBOb37IW85q2NLXHYbP+zez6adJQcOKOyIiIgEKew0JNWXoG/+DCrL4MuXAq/PuPmwzePcDvqc2ByATw4eyko66IosERGRJk5hpyEJztv5Alb/L7CgZ1ImdBp0xLec1yVw48RP1h201IR6dkRERIIUdhqSzKp5O3s3w4LHAvt63QQ2+xHf0q9zCoYBq7YWsqOwLLCzOuyU5PO3mV/i8//6VW8iIiKRSmGnIYlKgFanBJ4XbQNXHHS/6hffkhIfxamZzQCYUzWUVWZPYL8tFoD5y1aw6LtdIStZRESkoVPYaWiq5+0AdL86MHH5V1Sviv7J+gL2lFZw5YtL+d7bEoBMYydvrtgaklJFREQaA4WdhqZ6UVAM6HVjrd5yXlXYWfzdbn4/aRFf5+1jhy2wL9PYyUfr8inxeENRrYiISIOnsNPQtDsLul0O/R8I3FOnFo5vGceJKXF4/Sbf7yolPTGKHqcELlXvGrOX8ko/H67ZEcKiRUREGi6FnYbG4YIh/4Ezx9TpbYO6BhYP7Zgaz5s39yb5uPYAdE8oBOCtr7bVa5kiIiKNhaVrY0n9GXn2CXRulUCfE5sTH+UMXpGVwU4AFn+/m61799O6WYyFVYqIiISfenYiRJTTzvknpQWCDkCzdgA4i/LIbhdYJPTtr9W7IyIiTY/CTqRKzAjcs6dyP1d1NoDAUFZtVpoXERGJJAo7kcrhgszeAJzrmU2U08b3u0pZuWWftXWJiIiEmcJOJDv9jwC4Vr7MoM6BoSxNVBYRkaZGYSeSdfodxKdD6U+MaLEWgHdXbcfj9VlcmIiISPgo7EQyuxN6Xg9Ax7zppCa4KSyrZN43Oy0uTEREJHwUdiJdj+Fgc2JsXcZNHYoBmLTgey0OKiIiTYbCTqSLS4EulwDwB/Mj4t0OVm3Zx/OffW9xYSIiIuGhsNMUnB5YYyvmm5k8NCAdgKdmf0tufrGVVYmIiISFwk5T0LontDoFfB4u9s+lX6cUKnx+/jJjJZU+v9XViYiIhJTCTlNgGMHeHWP5i0wYnEVitJO124p4dt53FhcnIiISWgo7TcVJQyA6GQrzSFn2KJO7b+I823KWz5tJbu4Gq6sTEREJGcPU+gEUFRWRmJhIYWEhCQkJVpcTOrPvh4UTD9ntxY7/5uW4Uk4If00iIiJHqbZ/v7XqeVNy5q3gLYfiHeAppnJ/IeU7NhDPfnK//ICOF4y2ukIREZF6p7DTlEQnwcC/B186gfn/vplzd0+l4sfllpUlIiISSpqz08Q5WvcAIHHPGosrERERCQ2FnSYuNasPAOmVP2B6SiyuRkREpP4p7DRxJ57QgQKzGQ787MhdZnU5IiIi9U5hp4lzOWz8GNUJgF25iy2uRkREpP4p7AglLboFnmz7ytpCREREQkBhR4hpdzoALYvWWlyJiIhI/VPYETJPOhOAVv58yvb9ZHE1IiIi9UthR2iVmsqPBFZDz1v7hcXViIiI1C+FHcEwDHbEZQFQ/N0Si6sRERGpXwo7AkBl2ikAuHeutLQOERGR+qawIwAknZgNwHGlG0Brw4qISARR2BEAju96BpWmnWQK2bl1k9XliIiI1BuFHQEgNjaOzY52AGxbp0nKIiISORR2JGhP4kkAeH6+AnpFKWxfGf6CRERE6oHCjgTZqlZAj9+9+sDO/XvghX7w/Fmw/h2LKhMRETl6CjsSlNq5NwBtPRvxVlZCeSG8cgn8tCHQ4NOHwe+zsEIREZG6U9iRoIz2p7DfdBNrlJO3bhFM+wPsWAkxzSEqCXblwtq3rC5TRESkThR2JMjmcPCjuyMA6R8Mh7zF4E6Eq2dC79GBRgseBZ/XwipFRETqRmFHaqheAT2qYi+mMxauegNanQy9/gTRybB7E6yZYXGVIiIitaewIzXEtw/M2/GYTv6WcC+bo7sEDrjjoc8tgecL/q7eHRERaTQUdqSGTmddzvITRnOt/x5e3JbJgImf8ez8TVT6/HD6CIhpAXs3w+rpVpcqIiJSK4Zpam2AoqIiEhMTKSwsJCEhwepyGoS83fu5++01fL5xFwCd0uIZ07895xXOwDb7XkjKhNFfgd1pcaUiItJU1fbvt3p25LAym8fw3+tP5x+XnkxSjJNv8ou56dWvuGBRR8pczWFfHqycanWZIiIiv0phR47IMAyG9mjN3LFnkfPbE0iIcvDNbi+PlV4AQMUH4yldpsAjIiINm4ax0DBWbZV4vPxv+RZe/TyXh/c/SG/7egBWJg+k5R/+xXGpKRZXKCIiTUlt/34r7KCwU1eVPj8frN5K4cePMqxsGnbDZLOZxpvtHuTigYNonxpvdYkiItIEKOzUgcLO0TFNk1ULP6L1vNG08P1EpWnnc39XdqWfwxkDryKz7QlWlygiIhFMYacOFHaOUdleCv83ksQfPqyxOy+6E3FnXEdy3z+BYVhUnIiIRCqFnTpQ2KknOzeQv/wtSle/xwmeDcHdXzc7n+Oufp6U5EQLixMRkUjTKC49/+yzz7jwwgtJT0/HMAzefvvtGsdN0+S+++6jVatWREdH079/fzZu3FijzZ49exg2bBgJCQkkJSVxww03UFJSEsZfIUEpnUkbdDcnjF/C2iuW83ridXhNG933fkTeP89l4ruL2VtaYXWVIiLSxFgadkpLSzn55JN55plnDnv8scce41//+hfPPfccS5cuJTY2lgEDBlBeXh5sM2zYMNatW8fs2bOZNWsWn332GTfeeGO4foIcwUkdO3DZrRPZeO5kSo0Yehq5DPnyaq597BWmLNyM39/kOxRFRCRMGswwlmEYzJw5k8GDBwOBXp309HT+8pe/MG7cOAAKCwtJTU1lypQpXH755WzYsIGsrCyWL19Oz549Afjoo4+44IIL2Lp1K+np6bX6bg1jhZa58xvKX/490aVbKDKjech7NdsyB/P3S7uTkRxjdXkiItJINYphrF+yefNm8vPz6d+/f3BfYmIivXr1YvHixQAsXryYpKSkYNAB6N+/PzabjaVLlx7xsz0eD0VFRTU2CR0jpRPRNy/AzMwmwSjjcefz3LvtJv468d9MW5pHA8nbIiISoRps2MnPzwcgNTW1xv7U1NTgsfz8fFJSat7IzuFwkJycHGxzOBMmTCAxMTG4ZWRk1HP1cojY5hjXvAvnPoTPnUhnWx4v2B6h9awreeSZ51n/zQatpC4iIiHRYMNOKI0fP57CwsLgtmXLFqtLahocLujzZ+y3rMTf62Z8hoO+9jXcvet2sqafgf+hllQ81gH+71zYNMfqakVEJEI02LCTlpYGQEFBQY39BQUFwWNpaWns3LmzxnGv18uePXuCbQ7H7XaTkJBQY5MwiknGNnAC9tHLKek4hD3OVCpNOzb8uPYXwNZl+KcPg/y1VlcqIiIRoMGGnXbt2pGWlsbcuXOD+4qKili6dCnZ2dkAZGdns2/fPlasWBFs8+mnn+L3++nVq1fYa5Y6Sj6euCsmk3z3t2wb9SMPdpjJ4Mq/8bnvJGzeckr+ezmU7bW6ShERaeQcVn55SUkJmzZtCr7evHkzK1euJDk5mczMTMaMGcPf/vY32rdvT7t27bj33ntJT08PXrHVuXNnzj//fEaMGMFzzz1HZWUlo0aN4vLLL6/1lVjSMLRtGc/9V57DD7t68fe3OtFu20203r+F9c9cTtvR7xHjdlldooiINFKWXno+f/58fvvb3x6yf/jw4UyZMgXTNLn//vt5/vnn2bdvH2eeeSbPPvssHTp0CLbds2cPo0aN4r333sNmszF06FD+9a9/ERcXV+s6dOl5w+L3m7w+axaDV1xHlFHJK67LOeOGJ7TAqIiI1KDlIupAYadh2jT7/zhx4V8AGOm7nX6Dh/P7Hq0trkpERBqKRn+fHZETz/0jZafcAMDfbf/m9Temc/sbqyir8FlcmYiINCYKO9KgRf/uUcw2fUgwynjV9Qj+r6cy+JmFbNqp9c9ERKR2FHakYXO4MK56E7pcgsvw8YTzP1yy+3kufvoz3lm5zerqRESkEVDYkYbPGQ1DX4K+twNwk+M9njKfYPz0JTzw7joqfX6LCxQRkYZMYUcaB5sNzrkbhryAaXdxnn0FS9w5dFl2J48+/Sw792lYS0REDk9XY6GrsRqdLcvgzRtgX15w124S8WYNIXXgnRB/5Ltni4hI5NCl53WgsNMI+f2Qt5ii5a9hrn+bRLMYgApbDLazb8PROwccbouLFBGRUNKl5xLZbDZo24eES5/GcdtGnk2fwNf+E3H59+P49EE8/zoNvnkflOVFRJo8hR1p9GJjohk5YiRbh7zDvcZoCswk3EU/wvQr8b3xRwUeEZEmTmFHIoJhGFx4SmvG/OVeHu8wjae9F1Nh2rGve4O9cydaXZ6IiFhIYUciSvM4N08M60PHKx/nSfv1AMR98RCrl861uDIREbGKwo5EpHOzUrn2zw+xyNUHJz6SPriJ6Z+ttrosERGxgMKORKy0pGhOHf0qu5ytyDR2Ej/7L9z11mrdhFBEpIlR2JGIFhWfTPPhU/EZDgbZl2Fb8RI3vPwlpR6v1aWJiEiYKOxIxDNa98B+3l8BuNfxKsamOVzxwhJ2lXgsrkxERMJBYUeahjNuhg4DcRuVvOz6O5fk/4srn51H3u79VlcmIiIhprAjTYNhwKWT4fQbAbjO8TFPl4zlzmdfZe22QouLExGRUFLYkabDGQ0XPA7D3sAX05IOtm1M8d7Jh/+5iznrdlhdnYiIhIjCjjQ97c/FnrOEyvYDcRk+brO9iut/l/Lq7GVoqTgRkcijsCNNU2wLnFe+hnfQRCoMN31taxjwxVBeevn/qPDq0nQRkUiisCNNl2HgOO06nCMXsCeuPS2NIm74YRwfP/VH9hWXWF2diIjUE4UdafKMlM4k3/I5W0+8EoALS99k68T+FGz/0eLKRESkPijsiAA4o2l91SS2DniBYmI4ybcB2/Nns3XNgqP7vKId8Orv4etX67dOERGpM4UdkYO0zr6M0ms+4QdbBi3ZQ+qbQ9g6Z1LdP+ijO2DTbPj4LqjQvXxERKyksCPyM2nHdyV+1AIWuXrjxEvrL+4k/5URUF5Uuw/YNBfWvxN4Xl4I62aGrlgREflVCjsih9E8uTndxr7L/xKuxW8apH33OsX/6M7+lW/AL12e7vXAB7cFnsenBx5XTA59wSIickQKOyJHEBflZPCfn+T5tk+y2Z9KfOUuYt6+gYLnLsTcs/nwb1r0b9jzHcSlwvD3wOaArcshf214ixcRkSCFHZFf4HbYuem669l+5Txedv4Bj+kgteBzKv7di70fPAQVpQca78uDz54IPD/vb9DiROg0KPBavTsiIpZR2BGphT6djuPyOybxes/pLPZ3wW16aLbsCfY/2R1z5TTw++Gj8eAtgzZ9oOulgTf2uC7wuOp/4NG9e0RErKCwI1JLboedqy88l+P+PJuJze5ii78lMeUFGG+PxPf0afDNLDDscMETgYVHAdqdBc3aQUUxrH3T2h8gItJEKeyI1FFmi1hGj76dj85+l8d8V1BkRmPfsylw8IyRkJp1oLHNBj2uDTzXUJaIiCUUdkSOgt1mMOKcLAb+6e8Mj/sPL3oH8o6vN3ft+R0/FXtqNu5+FdicsP1r2L7SknpFRJoyhR2RY9C1dSJTbxnE5p53M8Y7immr9nDOP+YzZeFmvL6qBUVjW0DWRYHn6t0REQk7hR2RYxTjcvC3wV15a2Rvuh6XSHG5lwfeW8+FTy9k7oaCQOipnqi8egaU/GRtwSIiTYxhmr90h7SmoaioiMTERAoLC0lISLC6HGnEfH6T15bl8fjHuRSWVQKQEu9m6KnHceu3V+HauwmiEqHvbXD6jeBwW1yxiEjjVdu/3wo7KOxI/dtTWsGz8zbx5ldb2bs/EHqyjB94NvYF2nqrbkjYrC30fxCyLj5w9ZaIiNSawk4dKOxIqFR4/czdUMCMFVuZn7sTTD9D7Z9xu+N1Whr7ADDbnIlx8b8h+XhrixURaWQUdupAYUfCIb+wnJlfb2PGii3k/7SbPzlmcaN9FtFGBV57FP5z7sOVPTJwubqIiPwqhZ06UNiRcDJNk6/y9vHGiq2sXPU19/knkW1fD8CW+JOJGvocLdtm/cqniIiIwk4dKOyIVUo9Xt74Mo/dC57jRs/LxBnleEwn3yX2olXPC2nWbRAkZVhdpohIg6SwUwcKO2I1n9/kiy9X0GzOOLpVfF3jWGXzjjg7nAvHnw2Z2eCOs6ZIEZEGRmGnDhR2pMEwTdZ+tZC182dwQuEiTjU2YjcO/F/UbzgpT+2Oq8M5OLpcBKldav/ZFfuhbC8kHheCwkVEwk9hpw4UdqQhWvTdLl74eAVxWz+jj20tZ9rX0trYVaPN/qQORHe/DKPr7yG53ZE/bPd38PJFULwD/vAKdBoU4upFREJPYacOFHakoTJNk+U/7OXLH/ewqaCYkoLvaLV7KX38KzjLtgq34Q229bY5E8eF/4QWJ9b8kF2b4OULoXh74LUjCoa/Bxmnh/GXiIjUP4WdOlDYkcbENE3W7yjijYXr8Kx5h4HmF/S2rcNumHhwMzcjB1+PG+jRtjnplVsCQackH1p2gsQM2DQbopvBDbOhRXurf46IyFFT2KkDhR1prArLKnlzxVZmL1rOzcX/5Df2tQB87juJ//guZKJrEi3Yx9649hRc8j/aH5eK/ZWLYduXkJQZCDzxaRb/ChGRo6OwUwcKO9LYmabJtr2l7Jk/iU5rHsdleoLHNvgzubLiLvaSQHyUg4HtHNy781biS3+EtK5w7QcQpX/uRaTxUdipA4UdiSi7NsHbN8HW5ZQ0y2Jax3/x+TY/X+fto8QTmOOTYRTwlut+WhpFlDqaUdzufJqffjnO488Eu8PiHyAiUjsKO3WgsCMRx+eFLUshvTu4YgK7/Cart+5jfu5PLPj2J3zbvuIF5z9IM/YG31ZkS+Kn1D6445oREx1NXEw0Lnd04P4+x5+tBUtFpEFR2KkDhR1pivaWVvB57na2r5xN6pYPOdu/lGZGyRHbe9v0xTHgr4EAJSLSACjs1IHCjjR1fr/Juq27+X7ZB/i3fcX+snI85fvxeytoZhTzO9uSA5e5n/R7+O1dEJMMlWUHNmc0xKWAK65x9gBt/xqWPAemD84eD81PsLoiEfkVCjt1oLAjcnglHi8r8/YxccZshpW9wiX2hb/+JmdMIPTEpUJsy8AWlxJ4rBGEjMBzhxsc0YGw5IwBuxMwwTQDj9Wf6Y4HdwK4Yg8fpnyVkL8atiwLDOHt2xK4l9CJ/aBNn8Dn/5xpwqY5sPCf8MPnB/bbnJB9M/xmnCZvizRgCjt1oLAj8ssK91dy51uryVu3hDscr9HXvgYAv2HHa4/GtEdh95Xh8JaGvhjDBs5YcEYFbpDocIPdBXu+B2/54d/jiAoEnuR2UFkO3jLwemDXRtiVG2hjc0CXIbB/N3w3N7AvNgXOuQeSj4eSAij9CUp2gt8buGdRYuvAQq0JxwW+AwgGNdMfaHfw5o6HqKTG2fMl0gAp7NSBwo7IrzNNk6lL83ho1noMbxle7HipeeVWNOW0NAppyT5aGoW0qNqaU0QLo5AYApfEG5gYhoHdMIkyKomiIri5jEqqe32MqtZuPET7S7Hj/8Uayx2J5Cd246fEk9kf3Yr0whUct2shMeUFR3yP3xlLYdYwCk/+I2ZCaxwGxObNJfGz+7Hv/f7YTtrh2F2BXq+4FIhpEejJsjkCm90JNvuB1zYHGPZAiKssC4S0ynLArOoRizrw6IoN9Jy54wOPzqhDP8dmC4RFwx54hMCwnd8L/qpHRxREJwVCWXQSuOLBV3Fg83oC7zm45w2j6vtjA71wCnMSJgo7daCwI1J7GwuKeevrbezbX0mJx0upx0txeSXllX4qvH4qfIFHj9dPZdXzSp8fr/9Y/1VjEkUF8ZQRa5ThpvLAZlSy3WzO92Yr4Od/aE1ONLbR17aGRKOUctOFByfluCg2o1ngP5kiYg/5Nidehts/5ir7HLzY2U0ie4wkCm1JYNhINXeRxi5SzZ9IpugXK/dix48NF5XHeA4ag6rg46jueXOB3R14rA5Z1ZvNURXW3AdCW43g5wi083sDw5TVPWQVpVBRAp5i8JQEwqA7LjDM6Y4PbA53VcBzHAiQrrhAu2AojA2Ez+rvxoDdG6FgHezcADvXB0JmShakZgUW3k3JCrzP9AcColkVwA8Ono6owwe+6u+yOawPhJVlgXpsdmvrOEYKO3WgsCMSen6/GQhCPj+VB4Uir9/E5zep9PmDjx7vgcDk8frx+f14fYF23qo25ZV+yip9lFf6KKvw4fX7g8f9B7Wr9JmBEFb1nYHP9OGpDDw3TROfGXiPaUJl1XfVJZy5qcCOn0BfR+CPmIlBJQ78GFQHMDcVtKAw2OvVzCjGiQ8HXhz4g492fDiMwKMdPxU4KTNdlBPYTAxcB4W9KKOCWMoDm1FOLGVEGxXY8OPAV/Xox4aJDX/VZmJg4q36Fi82/BhEU0GiUUoipUQbFYf81goc+Kj+A2lgVv06Nx5sNPk/J7VnrwqBzqiqOWtVYam6h81XGXhuEDjucAfmnQXDUlVwtNkDbcv3QdleKNsHnqJAmKvuQYxNCbyvOB+KtkPRtkB7ww7xrSAhHRJaBXoaq3vvvOWBR8NWNZ/u4C0msFX35Jm+QPAsLwp8d0VJVW9j3IEeR1csdP5dYKmaelTbv9+6e5iIhIXNZhBlsxPlbBz/JWmaBwJThTcQrjxeXzCI/ZzH68dT6aOsaqvw+jEMMA7qafL6zWBP18G9YIFQFghfpX4TvxkIhz7zQBD0+qpqqXpefczrN/H6DgS9wOOBcOir+pxAgKtbkHNRSQzlVOKgAieV2Dm05yx4xoiigjjKiTXKAkOSeAOhzKjERWVV2DKrYpWJA3/weCC4VVSFPh92w1cVq0wqsePDRqUZiG5luCkxoykhihKiqTCdxBrlxFFGnFFGPPtxVfWn2Y1AYHTiDYbBOAJtow0PLry4q2q1Gz62mCnk+jPINTPI9bemDDcdjS10sm2hk5HHCbbtuPDix6iKjQY2zGD4dFGJy/D9+smtHhasKK7V/xZ1tn93YNu5/shtTB8UbQ1sYVDYsgeJGfUbdmorYsLOM888w+OPP05+fj4nn3wy//73vzn9dK3qLCJHxzAMnHYDp91GjMvqauqXeVBQqg5DPt+BHq7qIOX3E3zuOyhI+c3ATSr91e2rQ5c/0JNWHaxqBDBfVc+XGfh+IBDqzECPWvX3VIdMn9+kwjTx+TnwPVWPlX4Tu89PjM/EWRUUfX4o8fsprAqHplk1o8gEk8B3/Fx1+KwOnRVePz7TDJ4fX1Xw3GyeyAdmVQitPPSD/FXHqlWHueD5xgj2srnw4sQbCFlGBVFUzVkzKnBTiRcbXtNBJXa82LFhBo9FEXi048NuBKKWHT9e7BSasRSacewjlmIzhnhjf3D+XAujkGgqyKcZ+WYyO8zmFJhJxOAhzdhLqrGHVsYemhkleEwHHpx4CAz32qpCbDQeoo0KovAQU/U8mnJi8GBiUEwMxWY0xcSw33TjMgLhMqYqYMbg4QR/DIn1+49yrUVE2Pnf//7H2LFjee655+jVqxcTJ05kwIAB5ObmkpKSYnV5IiINimEYOOwGjsbRydYoHDx06vWZmD8b0vOb1Ohxq/T5awQkIDikemDI1l8j7PmrQqG/KpD5q49VBUaTA8HLZoCtapK/YRiYpskJPj/llYHeyfJKXzAAVvdA+k0Th98kqiqcVlYFWkzwAyWmSVHVxYbVNfgOSpEGRnAqUnWA9Vd9hs8Pdya3Ctn5/zURMWenV69enHbaaTz99NMA+P1+MjIyGD16NHfeeeevvj9Uc3YKSgvwmbXozhQREYlwLWNa4rQ56/Uzm8ycnYqKClasWMH48eOD+2w2G/3792fx4sWHfY/H48HjObAqdFHRL19JcbT++Mkf+aHoh5B8toiISGPy3uD3aJvY1pLvbvRhZ9euXfh8PlJTU2vsT01N5ZtvvjnseyZMmMCDDz4Y8trcdjdR9qhfb9jA/Lz7VURE5FgZFl5u3+jDztEYP348Y8eODb4uKioiIyOj3r/njYveqPfPFBERkbpp9GGnRYsW2O12Cgpq3iG1oKCAtLS0w77H7XbjdrvDUZ6IiIhYzGZ1AcfK5XLRo0cP5s6dG9zn9/uZO3cu2dnZFlYmIiIiDUGj79kBGDt2LMOHD6dnz56cfvrpTJw4kdLSUq677jqrSxMRERGLRUTY+cMf/sBPP/3EfffdR35+PqeccgofffTRIZOWRUREpOmJiPvsHCutjSUiItL41Pbvd6OfsyMiIiLySxR2REREJKIp7IiIiEhEU9gRERGRiKawIyIiIhFNYUdEREQimsKOiIiIRDSFHREREYloCjsiIiIS0SJiuYhjVX0T6aKiIosrERERkdqq/rv9a4tBKOwAxcXFAGRkZFhciYiIiNRVcXExiYmJRzyutbEAv9/P9u3biY+PxzCMevvcoqIiMjIy2LJli9bcCjGd6/DRuQ4fnevw0vkOn/o616ZpUlxcTHp6OjbbkWfmqGcHsNlstG7dOmSfn5CQoP/jhInOdfjoXIePznV46XyHT32c61/q0ammCcoiIiIS0RR2REREJKIp7ISQ2+3m/vvvx+12W11KxNO5Dh+d6/DRuQ4vne/wCfe51gRlERERiWjq2REREZGIprAjIiIiEU1hR0RERCKawo6IiIhENIWdEHrmmWdo27YtUVFR9OrVi2XLllldUqM3YcIETjvtNOLj40lJSWHw4MHk5ubWaFNeXk5OTg7NmzcnLi6OoUOHUlBQYFHFkeHRRx/FMAzGjBkT3KfzXL+2bdvGVVddRfPmzYmOjqZr1658+eWXweOmaXLffffRqlUroqOj6d+/Pxs3brSw4sbJ5/Nx77330q5dO6KjoznhhBN46KGHaqytpHN9dD777DMuvPBC0tPTMQyDt99+u8bx2pzXPXv2MGzYMBISEkhKSuKGG26gpKTk2IszJSSmT59uulwu86WXXjLXrVtnjhgxwkxKSjILCgqsLq1RGzBggDl58mRz7dq15sqVK80LLrjAzMzMNEtKSoJtbrrpJjMjI8OcO3eu+eWXX5pnnHGG2bt3bwurbtyWLVtmtm3b1uzWrZt5yy23BPfrPNefPXv2mG3atDGvvfZac+nSpeb3339vfvzxx+amTZuCbR599FEzMTHRfPvtt81Vq1aZF110kdmuXTuzrKzMwsobn4cffths3ry5OWvWLHPz5s3mjBkzzLi4OPOf//xnsI3O9dH54IMPzLvvvtt86623TMCcOXNmjeO1Oa/nn3++efLJJ5tLliwxP//8c/PEE080r7jiimOuTWEnRE4//XQzJycn+Nrn85np6enmhAkTLKwq8uzcudMEzAULFpimaZr79u0znU6nOWPGjGCbDRs2mIC5ePFiq8pstIqLi8327dubs2fPNs8666xg2NF5rl933HGHeeaZZx7xuN/vN9PS0szHH388uG/fvn2m2+02X3vttXCUGDEGDRpkXn/99TX2DRkyxBw2bJhpmjrX9eXnYac253X9+vUmYC5fvjzY5sMPPzQNwzC3bdt2TPVoGCsEKioqWLFiBf379w/us9ls9O/fn8WLF1tYWeQpLCwEIDk5GYAVK1ZQWVlZ49x36tSJzMxMnfujkJOTw6BBg2qcT9B5rm/vvvsuPXv25NJLLyUlJYXu3bvzwgsvBI9v3ryZ/Pz8Guc7MTGRXr166XzXUe/evZk7dy7ffvstAKtWreKLL75g4MCBgM51qNTmvC5evJikpCR69uwZbNO/f39sNhtLly49pu/XQqAhsGvXLnw+H6mpqTX2p6am8s0331hUVeTx+/2MGTOGPn36cNJJJwGQn5+Py+UiKSmpRtvU1FTy8/MtqLLxmj59Ol999RXLly8/5JjOc/36/vvvmTRpEmPHjuWuu+5i+fLl/PnPf8blcjF8+PDgOT3cv1N0vuvmzjvvpKioiE6dOmG32/H5fDz88MMMGzYMQOc6RGpzXvPz80lJSalx3OFwkJycfMznXmFHGq2cnBzWrl3LF198YXUpEWfLli3ccsstzJ49m6ioKKvLiXh+v5+ePXvyyCOPANC9e3fWrl3Lc889x/Dhwy2uLrK8/vrrTJ06lWnTptGlSxdWrlzJmDFjSE9P17mOYBrGCoEWLVpgt9sPuTKloKCAtLQ0i6qKLKNGjWLWrFnMmzeP1q1bB/enpaVRUVHBvn37arTXua+bFStWsHPnTk499VQcDgcOh4MFCxbwr3/9C4fDQWpqqs5zPWrVqhVZWVk19nXu3Jm8vDyA4DnVv1OO3W233cadd97J5ZdfTteuXbn66qu59dZbmTBhAqBzHSq1Oa9paWns3LmzxnGv18uePXuO+dwr7ISAy+WiR48ezJ07N7jP7/czd+5csrOzLays8TNNk1GjRjFz5kw+/fRT2rVrV+N4jx49cDqdNc59bm4ueXl5Ovd10K9fP9asWcPKlSuDW8+ePRk2bFjwuc5z/enTp88ht1D49ttvadOmDQDt2rUjLS2txvkuKipi6dKlOt91tH//fmy2mn/67HY7fr8f0LkOldqc1+zsbPbt28eKFSuCbT799FP8fj+9evU6tgKOaXqzHNH06dNNt9ttTpkyxVy/fr154403mklJSWZ+fr7VpTVqI0eONBMTE8358+ebO3bsCG779+8PtrnpppvMzMxM89NPPzW//PJLMzs728zOzraw6shw8NVYpqnzXJ+WLVtmOhwO8+GHHzY3btxoTp061YyJiTFfffXVYJtHH33UTEpKMt955x1z9erV5sUXX6zLoY/C8OHDzeOOOy546flbb71ltmjRwrz99tuDbXSuj05xcbH59ddfm19//bUJmE8++aT59ddfmz/++KNpmrU7r+eff77ZvXt3c+nSpeYXX3xhtm/fXpeeN3T//ve/zczMTNPlcpmnn366uWTJEqtLavSAw26TJ08OtikrKzNvvvlms1mzZmZMTIx5ySWXmDt27LCu6Ajx87Cj81y/3nvvPfOkk04y3W632alTJ/P555+vcdzv95v33nuvmZqaarrdbrNfv35mbm6uRdU2XkVFReYtt9xiZmZmmlFRUebxxx9v3n333abH4wm20bk+OvPmzTvsv5+HDx9ummbtzuvu3bvNK664woyLizMTEhLM6667ziwuLj7m2gzTPOi2kSIiIiIRRnN2REREJKIp7IiIiEhEU9gRERGRiKawIyIiIhFNYUdEREQimsKOiIiIRDSFHREREYloCjsiIiIS0RR2REQAwzB4++23rS5DREJAYUdELHfttddiGMYh2/nnn291aSISARxWFyAiAnD++eczefLkGvvcbrdF1YhIJFHPjog0CG63m7S0tBpbs2bNgMAQ06RJkxg4cCDR0dEcf/zxvPHGGzXev2bNGs455xyio6Np3rw5N954IyUlJTXavPTSS3Tp0gW3202rVq0YNWpUjeO7du3ikksuISYmhvbt2/Puu+8Gj+3du5dhw4bRsmVLoqOjad++/SHhTEQaJoUdEWkU7r33XoYOHcqqVasYNmwYl19+ORs2bACgtLSUAQMG0KxZM5YvX86MGTOYM2dOjTAzadIkcnJyuPHGG1mzZg3vvvsuJ554Yo3vePDBB7nssstYvXo1F1xwAcOGDWPPnj3B71+/fj0ffvghGzZsYNKkSbRo0SJ8J0BEjt4xr5suInKMhg8fbtrtdjM2NrbG9vDDD5umaZqAedNNN9V4T69evcyRI0eapmmazz//vNmsWTOzpKQkePz99983bTabmZ+fb5qmaaanp5t33333EWsAzHvuuSf4uqSkxATMDz/80DRN07zwwgvN6667rn5+sIiElebsiEiD8Nvf/pZJkybV2JecnBx8np2dXeNYdnY2K1euBGDDhg2cfPLJxMbGBo/36dMHv99Pbm4uhmGwfft2+vXr94s1dOvWLfg8NjaWhIQEdu7cCcDIkSMZOnQoX331Feeddx6DBw+md+/eR/VbRSS8FHZEpEGIjY09ZFipvkRHR9eqndPprPHaMAz8fj8AAwcO5Mcff+SDDz5g9uzZ9OvXj5ycHJ544ol6r1dE6pfm7IhIo7BkyZJDXnfu3BmAzp07s2rVKkpLS4PHFy5ciM1mo2PHjsTHx9O2bVvmzp17TDW0bNmS4cOH8+qrrzJx4kSef/75Y/o8EQkP9eyISIPg8XjIz8+vsc/hcAQnAc+YMYOePXty5plnMnXqVJYtW8aLL74IwLBhw7j//vsZPnw4DzzwAD/99BOjR4/m6quvJjU1FYAHHniAm266iZSUFAYOHEhxcTELFy5k9OjRtarvvvvuo0ePHnTp0gWPx8OsWbOCYUtEGjaFHRFpED766CNatWpVY1/Hjh355ptvgMCVUtOnT+fmm2+mVatWvPbaa2RlZQEQExPDxx9/zC233MJpp51GTEwMQ4cO5cknnwx+1vDhwykvL+epp55i3LhxtGjRgt///ve1rs/lcjF+/Hh++OEHoqOj+c1vfsP06dPr4ZeLSKgZpmmaVhchIvJLDMNg5syZDB482OpSRKQR0pwdERERiWgKOyIiIhLRNGdHRBo8jbaLyLFQz46IiIhENIUdERERiWgKOyIiIhLRFHZEREQkoinsiIiISERT2BEREZGIprAjIiIiEU1hR0RERCLa/wM7MLmhYa7m+QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ftype = 'json'\n",
    "cnn_model_history_name = '{}_{}_{}.{}'.format(dataset_name, modeltype, 'history', ftype) \n",
    "cnn_model_history_path = os.path.join(cnn_model_files_dir, cnn_model_history_name)\n",
    "with open(cnn_model_history_path, \"w\") as file: \n",
    "    json.dump({'history': history.history}, file, indent=4)\n",
    "nprint('CNN model history path', cnn_model_history_path)\n",
    "display_training_performance(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bde3bd-05e1-44a4-a7fa-fc2afc0603d1",
   "metadata": {},
   "source": [
    "<h2>Creation of a .zip file for uploading to Google Drive</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9877b05e-6ed3-441d-94f4-48fee7d60d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftype = 'zip'\n",
    "shutil.make_archive(cnn_model_files_dir, ftype, cnn_model_files_dir)\n",
    "shutil.rmtree(cnn_model_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee8384-469d-4c54-bd5b-f146f34e8b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
