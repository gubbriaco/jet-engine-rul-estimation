{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f747b8ca-6bb2-4dc3-aca6-694d5f908b4f",
   "metadata": {},
   "source": [
    "<h1>FD002 Tuned CNN Model Training</h1>\n",
    "<ul>\n",
    "    <li>Loading training and validation data</li>\n",
    "    <li>Loading tuned model (best model from hyper tuning trials)</li>\n",
    "    <li>Tuned model training</li>\n",
    "    <li>Saving trained model</li>\n",
    "    <li>Displaying training model metrics</li>\n",
    "    <li>Creation of a .zip file for uploading to Google Drive</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be7ad69b-4c21-42f8-b18e-ba65693abe2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devices: PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n"
     ]
    }
   ],
   "source": [
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac4fcd5-c4e0-4ac3-b927-fc1cabc21091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading FD002.zip from Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1YpCySV1adGQKdIZbifyiolXsucTv9ZZt\n",
      "From (redirected): https://drive.google.com/uc?id=1YpCySV1adGQKdIZbifyiolXsucTv9ZZt&confirm=t&uuid=902ffdf7-256e-4a7c-9d23-b07862cf9e19\n",
      "To: D:\\virtualenv\\src\\thesis\\cmapss\\tuning\\cnn\\input\\models\\FD002.zip\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 143M/143M [00:17<00:00, 8.00MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FD002.zip...\n",
      "Extraction complete: ./input\\models\n",
      "Downloading FD002.zip from Google Drive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1pzFs93wfKkd4MZTATkQB-_oypFafq7iL\n",
      "From (redirected): https://drive.google.com/uc?id=1pzFs93wfKkd4MZTATkQB-_oypFafq7iL&confirm=t&uuid=348e21ea-69f2-49c3-9d22-3e3358b8c151\n",
      "To: D:\\virtualenv\\src\\thesis\\cmapss\\tuning\\cnn\\input\\CMAPSSData\\FD002.zip\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 76.5M/76.5M [00:09<00:00, 8.07MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting FD002.zip...\n",
      "Extraction complete: ./input\\CMAPSSData\n",
      "\u001b[94m\u001b[1mInput directory\u001b[0m\n",
      "'./input'\n",
      "\u001b[94m\u001b[1mURL input dataset\u001b[0m\n",
      "'https://drive.google.com/file/d/1LU1DQuv7_CzBy2_Abgjg3HsvNDme361O/view?usp=drive_link'\n",
      "\u001b[94m\u001b[1mInput dataset directory\u001b[0m\n",
      "'./input\\\\CMAPSSData'\n",
      "\u001b[94m\u001b[1mOutput directory\u001b[0m\n",
      "'./working'\n",
      "\u001b[94m\u001b[1mOutput models directory\u001b[0m\n",
      "'./working\\\\models'\n",
      "\u001b[94m\u001b[1mOutput plots directory\u001b[0m\n",
      "'./working\\\\plots'\n"
     ]
    }
   ],
   "source": [
    "prepare_dirs(task='tuned-training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0180e90-d142-4c8a-8dd9-92569a95ba35",
   "metadata": {},
   "source": [
    "<h2>Loading training and validation data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3a91fd4-ebab-4d72-b978-07c5d3da631b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mTraining features shape\u001b[0m\n",
      "(39055, 20, 15)\n",
      "\u001b[94m\u001b[1mTraining targets shape\u001b[0m\n",
      "(39055,)\n",
      "\u001b[94m\u001b[1mValidation features shape\u001b[0m\n",
      "(9764, 20, 15)\n",
      "\u001b[94m\u001b[1mValidation targets shape\u001b[0m\n",
      "(9764,)\n",
      "\u001b[94m\u001b[1mTesting features shape\u001b[0m\n",
      "(1289, 20, 15)\n",
      "\u001b[94m\u001b[1mTesting targets shape\u001b[0m\n",
      "(259,)\n"
     ]
    }
   ],
   "source": [
    "data_ftype = '.npy'\n",
    "\n",
    "ts_train_features_name = 'ts_train_features' + data_ftype\n",
    "ts_train_features_path = os.path.join(dataset_dir, ts_train_features_name)\n",
    "ts_train_targets_name = 'ts_train_targets' + data_ftype\n",
    "ts_train_targets_path = os.path.join(dataset_dir, ts_train_targets_name)\n",
    "\n",
    "ts_val_features_name = 'ts_val_features' + data_ftype\n",
    "ts_val_features_path = os.path.join(dataset_dir, ts_val_features_name)\n",
    "ts_val_targets_name = 'ts_val_targets' + data_ftype\n",
    "ts_val_targets_path = os.path.join(dataset_dir, ts_val_targets_name)\n",
    "\n",
    "ts_test_features_name = 'ts_test_features' + data_ftype\n",
    "ts_test_features_path = os.path.join(dataset_dir, ts_test_features_name)\n",
    "ts_test_targets_name = 'ts_test_targets' + data_ftype\n",
    "ts_test_targets_path = os.path.join(dataset_dir, ts_test_targets_name)\n",
    "\n",
    "ts_train_features = np.load(ts_train_features_path)\n",
    "ts_train_targets = np.load(ts_train_targets_path)\n",
    "\n",
    "ts_val_features = np.load(ts_val_features_path)\n",
    "ts_val_targets = np.load(ts_val_targets_path)\n",
    "\n",
    "ts_test_features = np.load(ts_test_features_path)\n",
    "ts_test_targets = np.load(ts_test_targets_path)\n",
    "\n",
    "\n",
    "nprint(\"Training features shape\", ts_train_features.shape)\n",
    "nprint(\"Training targets shape\", ts_train_targets.shape)\n",
    "nprint(\"Validation features shape\", ts_val_features.shape)\n",
    "nprint(\"Validation targets shape\", ts_val_targets.shape)\n",
    "nprint(\"Testing features shape\", ts_test_features.shape)\n",
    "nprint(\"Testing targets shape\", ts_test_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d4f2d-4b41-4b40-96b8-6db9edb8d95c",
   "metadata": {},
   "source": [
    "<h2>Loading tuned model (best model from hyper tuning trials)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d660cca-4110-49aa-ba97-d0663041f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./input\\models\\tuner0.json\n",
      "WARNING:tensorflow:From D:\\virtualenv\\myenv\\Lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\virtualenv\\myenv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">50,880</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">599,456</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">133,440</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">321</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m15\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m480\u001b[0m)             │          \u001b[38;5;34m50,880\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m416\u001b[0m)             │         \u001b[38;5;34m599,456\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling1d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m416\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)                 │         \u001b[38;5;34m133,440\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m321\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">784,097</span> (2.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m784,097\u001b[0m (2.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">784,097</span> (2.99 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m784,097\u001b[0m (2.99 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_conv1d_layers_bounds = [1, 3]\n",
    "num_conv1d_filters_bounds = [64, 512, 32]\n",
    "num_dense_layers_bounds = [1, 2]\n",
    "num_dense_units_bounds = [64, 512, 32]\n",
    "initial_lr_bounds = [1e-4, 1e-2]\n",
    "batch_size_bounds = [32, 128, 32]\n",
    "\n",
    "rule_hp = RULEstimator_HyperModel(\n",
    "    window_length=window_length, \n",
    "    num_features=ts_train_features.shape[2], \n",
    "    num_targets=1 if len(ts_train_targets.shape)==1 else ts_train_targets.shape[1], \n",
    "    num_conv1d_layers_bounds=num_conv1d_layers_bounds, \n",
    "    num_conv1d_filters_bounds=num_conv1d_filters_bounds, \n",
    "    num_dense_layers_bounds=num_dense_layers_bounds, \n",
    "    num_dense_units_bounds=num_dense_units_bounds, \n",
    "    initial_lr_bounds=initial_lr_bounds,\n",
    "    batch_size_bounds=batch_size_bounds\n",
    ")\n",
    "rule_hp.build(kt.HyperParameters())\n",
    "\n",
    "\n",
    "with tensorflow.device('/GPU:0'):\n",
    "    tuner = kt.Hyperband(\n",
    "        hypermodel=rule_hp,\n",
    "        objective='val_loss',\n",
    "        max_epochs=max_epochs,\n",
    "        factor=factor,\n",
    "        directory=in_dir,\n",
    "        project_name=models_name,\n",
    "    )\n",
    "tuner.reload()\n",
    "tuner.get_best_models()[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be72ea4f-9264-4c40-bded-8546ad625c1f",
   "metadata": {},
   "source": [
    "<h2>Tuned model training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9030ea1b-32c1-4351-b326-344d07d592fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mbesthyperparameters.values\u001b[0m\n",
      "{'batch_size': 32,\n",
      " 'conv_filters_0': 480,\n",
      " 'conv_filters_1': 416,\n",
      " 'conv_filters_2': 448,\n",
      " 'conv_kernel_size_0': 7,\n",
      " 'conv_kernel_size_1': 3,\n",
      " 'conv_kernel_size_2': 7,\n",
      " 'dense_units_0': 320,\n",
      " 'dense_units_1': 512,\n",
      " 'initial_lr': 0.0029985904666745577,\n",
      " 'num_conv_layers': 2,\n",
      " 'num_dense_layers': 1,\n",
      " 'tuner/bracket': 2,\n",
      " 'tuner/epochs': 20,\n",
      " 'tuner/initial_epoch': 7,\n",
      " 'tuner/round': 2,\n",
      " 'tuner/trial_id': '0014'}\n",
      "\u001b[94m\u001b[1mTraining started: \u001b[0m\n",
      "'2024-12-05 21:32:29'\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.0029985904693603516.\n",
      "Epoch 1/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - loss: 1467.8573 - val_loss: 902.0212 - learning_rate: 0.0030\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.0029985904693603516.\n",
      "Epoch 2/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - loss: 839.6891 - val_loss: 903.8722 - learning_rate: 0.0030\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.0029985904693603516.\n",
      "Epoch 3/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 761.1299 - val_loss: 676.1597 - learning_rate: 0.0030\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.0029985904693603516.\n",
      "Epoch 4/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 710.6811 - val_loss: 629.5457 - learning_rate: 0.0030\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.0029985904693603516.\n",
      "Epoch 5/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - loss: 640.7135 - val_loss: 834.8134 - learning_rate: 0.0030\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0029985904693603516.\n",
      "Epoch 6/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 563.7084 - val_loss: 504.0479 - learning_rate: 0.0030\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0029985904693603516.\n",
      "Epoch 7/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 422.8159 - val_loss: 330.7334 - learning_rate: 0.0030\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0029985904693603516.\n",
      "Epoch 8/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 303.0909 - val_loss: 407.9964 - learning_rate: 0.0030\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0029985904693603516.\n",
      "Epoch 9/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 260.6368 - val_loss: 201.7558 - learning_rate: 0.0030\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0029985904693603516.\n",
      "Epoch 10/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 169.7988 - val_loss: 149.7049 - learning_rate: 0.0030\n",
      "\n",
      "Epoch 11: LearningRateScheduler setting learning rate to 0.00029985904693603517.\n",
      "Epoch 11/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 85.1010 - val_loss: 86.6340 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 12: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 12/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 60.7877 - val_loss: 78.1346 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 13: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 13/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 53.0088 - val_loss: 72.4820 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 14: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 14/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 48.3395 - val_loss: 70.2670 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 15: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 15/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 44.4503 - val_loss: 61.1657 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 16: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 16/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 39.0758 - val_loss: 56.0622 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 17: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 17/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 35.9709 - val_loss: 52.6671 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 18: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 18/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 33.9736 - val_loss: 51.5371 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 19: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 19/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 32.1219 - val_loss: 47.4395 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 20: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 20/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 29.7970 - val_loss: 44.0535 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 21: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 21/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 28.0735 - val_loss: 41.5575 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 22: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 22/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 26.0426 - val_loss: 40.8605 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 23: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 23/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 25.5626 - val_loss: 40.3082 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 24: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 24/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 24.3057 - val_loss: 38.4816 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 25: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 25/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - loss: 23.2321 - val_loss: 38.5980 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 26: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 26/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 21.2730 - val_loss: 34.6398 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 27: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 27/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 20.1446 - val_loss: 37.2834 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 28: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 28/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 19.3017 - val_loss: 32.7015 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 29: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 29/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 18.5975 - val_loss: 31.0022 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 30: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 30/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 17.7157 - val_loss: 30.6391 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 31: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 31/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - loss: 17.2902 - val_loss: 29.6933 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 32: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 32/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 16.5882 - val_loss: 28.5983 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 33: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 33/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 16.2633 - val_loss: 28.1511 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 34: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 34/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 15.2750 - val_loss: 26.5297 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 35: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 35/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 14.8733 - val_loss: 26.7622 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 36: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 36/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 14.3104 - val_loss: 27.4379 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 37: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 37/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 14.6588 - val_loss: 25.7794 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 38: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 38/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 13.7991 - val_loss: 25.7493 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 39: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 39/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 13.3971 - val_loss: 24.3087 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 40: LearningRateScheduler setting learning rate to 0.000299859035294503.\n",
      "Epoch 40/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 13.0541 - val_loss: 24.0057 - learning_rate: 2.9986e-04\n",
      "\n",
      "Epoch 41: LearningRateScheduler setting learning rate to 2.99859035294503e-05.\n",
      "Epoch 41/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 10.6585 - val_loss: 21.5106 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 42: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 42/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 9.4432 - val_loss: 21.1544 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 43: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 43/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 8.8344 - val_loss: 20.9534 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 44: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 44/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 9.0172 - val_loss: 21.1364 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 45: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 45/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 8.8724 - val_loss: 20.9145 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 46: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 46/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 8.8304 - val_loss: 21.0430 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 47: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 47/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 8.6502 - val_loss: 20.8465 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 48: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 48/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 8.8306 - val_loss: 20.5893 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 49: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 49/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 23ms/step - loss: 8.8268 - val_loss: 20.8497 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 50: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 50/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 8.7073 - val_loss: 20.7465 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 51: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 51/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 8.6989 - val_loss: 20.4741 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 52: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 52/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - loss: 8.0745 - val_loss: 20.3346 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 53: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 53/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - loss: 8.3181 - val_loss: 20.4032 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 54: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 54/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - loss: 8.4225 - val_loss: 20.5944 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 55: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 55/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 8.2588 - val_loss: 20.2788 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 56: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 56/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 8.2342 - val_loss: 20.2381 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 57: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 57/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - loss: 8.3351 - val_loss: 20.1665 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 58: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 58/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 8.1236 - val_loss: 19.9747 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 59: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 59/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 8.2913 - val_loss: 20.0227 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 60: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 60/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - loss: 8.0977 - val_loss: 19.9814 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 61: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 61/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - loss: 8.0084 - val_loss: 19.8127 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 62: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 62/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 8.1945 - val_loss: 19.9806 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 63: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 63/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - loss: 8.2674 - val_loss: 20.2641 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 64: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 64/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - loss: 8.1936 - val_loss: 19.9551 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 65: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 65/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 8.0264 - val_loss: 20.2987 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 66: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 66/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 7.9127 - val_loss: 19.6319 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 67: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 67/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.6507 - val_loss: 19.8923 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 68: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 68/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.6879 - val_loss: 19.7869 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 69: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 69/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - loss: 7.6885 - val_loss: 19.5332 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 70: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 70/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.6642 - val_loss: 19.7763 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 71: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 71/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.7118 - val_loss: 19.3983 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 72: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 72/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.5156 - val_loss: 19.3280 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 73: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 73/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.4399 - val_loss: 19.3054 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 74: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 74/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.5769 - val_loss: 19.2173 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 75: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 75/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.6016 - val_loss: 19.4001 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 76: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 76/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 7.6447 - val_loss: 19.1365 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 77: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 77/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.7923 - val_loss: 19.1242 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 78: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 78/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.2904 - val_loss: 19.1198 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 79: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 79/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.5334 - val_loss: 18.9716 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 80: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 80/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.3230 - val_loss: 19.1582 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 81: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 81/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - loss: 7.0643 - val_loss: 18.9946 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 82: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 82/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.3158 - val_loss: 18.9538 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 83: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 83/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - loss: 7.2971 - val_loss: 18.8816 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 84: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 84/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 7.2824 - val_loss: 18.7115 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 85: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 85/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 26ms/step - loss: 6.7204 - val_loss: 19.1374 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 86: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 86/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 7.0074 - val_loss: 18.6779 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 87: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 87/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - loss: 7.0860 - val_loss: 18.8352 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 88: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 88/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.0067 - val_loss: 18.6732 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 89: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 89/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 25ms/step - loss: 7.1647 - val_loss: 18.5593 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 90: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 90/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.1763 - val_loss: 18.6012 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 91: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 91/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.1138 - val_loss: 18.5758 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 92: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 92/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 6.9719 - val_loss: 18.4827 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 93: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 93/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 7.0934 - val_loss: 18.4318 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 94: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 94/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 6.8135 - val_loss: 18.4184 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 95: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 95/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 28ms/step - loss: 6.7439 - val_loss: 18.2500 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 96: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 96/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - loss: 6.8556 - val_loss: 18.2512 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 97: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 97/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 6.8969 - val_loss: 18.2053 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 98: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 98/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 24ms/step - loss: 6.6783 - val_loss: 18.2093 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 99: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 99/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 27ms/step - loss: 6.7305 - val_loss: 18.1470 - learning_rate: 2.9986e-05\n",
      "\n",
      "Epoch 100: LearningRateScheduler setting learning rate to 2.9985903893248178e-05.\n",
      "Epoch 100/100\n",
      "\u001b[1m1221/1221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 27ms/step - loss: 6.8666 - val_loss: 18.0549 - learning_rate: 2.9986e-05\n",
      "\u001b[94m\u001b[1mTraining ended: \u001b[0m\n",
      "'2024-12-05 22:21:10'\n",
      "\u001b[94m\u001b[1mTraining duration\u001b[0m\n",
      "'2921.09 seconds'\n"
     ]
    }
   ],
   "source": [
    "besthyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "nprint('besthyperparameters.values', besthyperparameters.values)\n",
    "model = tuner.hypermodel.build(besthyperparameters)\n",
    "early_stopping = callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "lr_scheduler = callbacks.LearningRateScheduler(scheduler_training, verbose=verbose)\n",
    "start_time = time.time()\n",
    "nprint('Training started: ', time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()))\n",
    "with tensorflow.device('/GPU:0'):\n",
    "    history = model.fit(\n",
    "        ts_train_features, \n",
    "        ts_train_targets, \n",
    "        epochs=epochs, \n",
    "        validation_data=(\n",
    "            ts_val_features, \n",
    "            ts_val_targets\n",
    "        ), \n",
    "        verbose=verbose,\n",
    "        batch_size=besthyperparameters.values['batch_size'],\n",
    "        callbacks=[\n",
    "            early_stopping, \n",
    "            lr_scheduler\n",
    "        ]\n",
    "    )\n",
    "nprint('Training ended: ', time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()))\n",
    "end_time = time.time()\n",
    "training_duration = end_time - start_time\n",
    "nprint('Training duration', '{:.2f} seconds'.format(training_duration))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d7c81-b6a9-40f5-b54b-2f6d46453a70",
   "metadata": {},
   "source": [
    "<h2>Saving trained model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71e801e-1d26-4629-9e6e-75ff346c042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype = 'CNN'\n",
    "\n",
    "cnn_model_name = '{}_{}'.format(dataset_name, modeltype)\n",
    "cnn_model_files_dir = os.path.join(out_models_dir, cnn_model_name)\n",
    "os.makedirs(cnn_model_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a0be72-309d-4ed7-8a63-e16cd9b2ab02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mCNN model path\u001b[0m\n",
      "'./working\\\\models\\\\FD002_CNN\\\\FD002_CNN.keras'\n"
     ]
    }
   ],
   "source": [
    "ftype = 'keras'\n",
    "cnn_model_file_name = '{}.{}'.format(cnn_model_name, ftype)\n",
    "cnn_model_path = os.path.join(cnn_model_files_dir, cnn_model_file_name)\n",
    "model.save(filepath=cnn_model_path)\n",
    "nprint('CNN model path', cnn_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b625af-dc86-4fc7-8504-a75cade64fa5",
   "metadata": {},
   "source": [
    "<h2>Displaying training model metrics</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6acd028-1f57-4951-848c-f5919a3d9e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mCNN model history path\u001b[0m\n",
      "'./working\\\\models\\\\FD002_CNN\\\\FD002_CNN_history.json'\n",
      "    loss  val_loss  learning_rate  epoch\n",
      "6.969507 18.251211        0.00003     95\n",
      "6.940071 18.205286        0.00003     96\n",
      "6.922813 18.209322        0.00003     97\n",
      "6.887563 18.146996        0.00003     98\n",
      "6.882256 18.054905        0.00003     99\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGwCAYAAABIC3rIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABZdUlEQVR4nO3deXxU1f3/8dedJZN9JxskgMouKoLSgKVWqIhoRfnVUqPiUqgKVrRqtSpVq1KXWupSrP1W1ApqbdUqKoqIoIiAIIiCLBUBgRC2ZLIvM/f3x52ZZELAJCSZCfN+Ph7TSe49M/dz70zNm3PPudcwTdNEREREJILZQl2AiIiISKgpEImIiEjEUyASERGRiKdAJCIiIhFPgUhEREQingKRiIiIRDwFIhEREYl4jlAX0Bl4vV527dpFQkIChmGEuhwRERFpBtM0KS0tJScnB5vtyH1ACkTNsGvXLnJzc0NdhoiIiLTCjh076Nat2xHbKBA1Q0JCAmAd0MTExBBXIyIiIs3hdrvJzc0N/B0/EgWiZvCfJktMTFQgEhER6WSaM9xFg6pFREQk4ikQiYiISMRTIBIREZGIpzFEIiISdjweD7W1taEuQzqBqKio751S3xwKRCIiEjZM06SwsJDi4uJQlyKdhM1mo2fPnkRFRR3V+ygQiYhI2PCHoYyMDGJjY3UxXDki/4WTd+/eTV5e3lF9XxSIREQkLHg8nkAYSktLC3U50kl06dKFXbt2UVdXh9PpbPX7aFC1iIiEBf+YodjY2BBXIp2J/1SZx+M5qvdRIBIRkbCi02TSEm31fVEgEhERkYinQCQiIiIRT4FIRETkKJ155plMmzYt1GXIUVAgCiGP16TIXcU3e8tCXYqIiEhEUyAKoV3FlZz+wELOfeyjUJciIiIS0RSIQigxxrpeQlWtl+q6o5suKCJyLDJNk4qaupA8TNNsVc0HDx7k8ssvJyUlhdjYWMaMGcPmzZsD67dt28b5559PSkoKcXFxDBgwgLfffjvw2oKCArp06UJMTAy9evVi9uzZbXIs5ch0YcYQSnA5MAwwTSitqsMVbw91SSIiYaWy1kP/6e+GZNvr7x1NbFTL/0xeccUVbN68mTfeeIPExER++9vfcu6557J+/XqcTidTpkyhpqaGJUuWEBcXx/r164mPjwfgrrvuYv369bzzzjukp6ezZcsWKisr23rXpAkKRCFksxnEuxyUVtXhrqwlPd4V6pJEROQo+IPQ0qVLGTZsGABz5swhNzeX119/nZ/97Gds376d8ePHM3DgQACOO+64wOu3b9/OoEGDGDJkCAA9evTo8H2IVApEIZYY7bQCUVVdqEsREQk7MU476+8dHbJtt9SGDRtwOBwMHTo0sCwtLY0+ffqwYcMGAH79619z7bXX8t577zFq1CjGjx/PSSedBMC1117L+PHjWb16NWeffTbjxo0LBCtpXxpDFGIJ0VYmLa2qDXElIiLhxzAMYqMcIXm01xWzf/nLX/LNN99w2WWXsW7dOoYMGcLjjz8OwJgxY9i2bRs33ngju3btYuTIkdx8883tUocEUyAKMf/AaneleohERDq7fv36UVdXx/LlywPL9u/fz8aNG+nfv39gWW5uLtdccw2vvvoqv/nNb/j73/8eWNelSxcmTpzICy+8wMyZM3n66ac7dB8ilU6ZhVhitC8QqYdIRKTT69WrFxdccAGTJk3ib3/7GwkJCdx222107dqVCy64AIBp06YxZswYevfuzcGDB1m0aBH9+vUDYPr06QwePJgBAwZQXV3NvHnzAuukfamHKMQSY6xM6q5UIBIRORbMnj2bwYMHc95555Gfn49pmrz99ts4ndY/gD0eD1OmTKFfv36cc8459O7dm7/+9a+Adef222+/nZNOOokRI0Zgt9t56aWXQrk7EUM9RCGmHiIRkc7vww8/DPyckpLC888/f9i2/vFCTbnzzju5884727I0aSb1EIVYYrS/h0hjiEREREJFgSjE/IOqNctMREQkdBSIQqz+lJl6iEREREIlpIFoyZIlnH/++eTk5GAYBq+//nrQetM0mT59OtnZ2cTExDBq1Kig+8EAHDhwgIKCAhITE0lOTubqq6+mrCz47vFffPEFP/zhD4mOjiY3N5eHHnqovXet2TSoWkREJPRCGojKy8s5+eSTefLJJ5tc/9BDD/HYY4/x1FNPsXz5cuLi4hg9ejRVVVWBNgUFBXz11VcsWLCAefPmsWTJEiZPnhxY73a7Ofvss+nevTurVq3i4Ycf5u677w6b6zpoULWIiEjohXSW2ZgxYxgzZkyT60zTZObMmdx5552Bazc8//zzZGZm8vrrrzNhwgQ2bNjA/PnzWblyZeC+L48//jjnnnsujzzyCDk5OcyZM4eamhqeeeYZoqKiGDBgAGvWrOHRRx8NCk6hkhCtCzOKiIiEWtiOIdq6dSuFhYWMGjUqsCwpKYmhQ4eybNkyAJYtW0ZycnIgDAGMGjUKm80WuErosmXLGDFiBFFRUYE2o0ePZuPGjRw8eLDJbVdXV+N2u4Me7cV/ykyDqkVEREInbANRYWEhAJmZmUHLMzMzA+sKCwvJyMgIWu9wOEhNTQ1q09R7NNxGYzNmzCApKSnwyM3NPfodOgz/KbPyGg91Hm+7bUdEREQOL2wDUSjdfvvtlJSUBB47duxot235b+4KUKqZZiIiIiERtoEoKysLgD179gQt37NnT2BdVlYWRUVFQevr6uo4cOBAUJum3qPhNhpzuVwkJiYGPdqLw24jLsoOaGC1iEik6tGjBzNnzmxW26ZmZcvRC9tA1LNnT7Kysli4cGFgmdvtZvny5eTn5wOQn59PcXExq1atCrT54IMP8Hq9DB06NNBmyZIl1NbWh40FCxbQp08fUlJSOmhvjkwDq0VEREIrpIGorKyMNWvWsGbNGsAaSL1mzRq2b9+OYRhMmzaN++67jzfeeIN169Zx+eWXk5OTw7hx4wACN8abNGkSK1asYOnSpUydOpUJEyaQk5MDwCWXXEJUVBRXX301X331FS+//DJ/+ctfuOmmm0K014cKXItIPUQiIiIhEdJA9NlnnzFo0CAGDRoEwE033cSgQYOYPn06ALfeeivXX389kydP5rTTTqOsrIz58+cTHR0deI85c+bQt29fRo4cybnnnssZZ5wRdI2hpKQk3nvvPbZu3crgwYP5zW9+w/Tp08Niyr2ff2C1ZpqJiDRimlBTHpqHaTarxKeffpqcnBy83uCJMRdccAFXXXUV//vf/7jgggvIzMwkPj6e0047jffff7/NDtG6des466yziImJIS0tjcmTJwddoPjDDz/k9NNPJy4ujuTkZIYPH862bdsAWLt2LT/+8Y9JSEggMTGRwYMH89lnn7VZbZ1JSK9DdOaZZ2Ie4QtnGAb33nsv995772HbpKamMnfu3CNu56STTuKjjz5qdZ3tzX8/M50yExFppLYCHsgJzbZ/twui4r632c9+9jOuv/56Fi1axMiRIwHrLgrz58/n7bffpqysjHPPPZf7778fl8vF888/z/nnn8/GjRvJy8s7qhLLy8sZPXo0+fn5rFy5kqKiIn75y18ydepUnn32Werq6hg3bhyTJk3ixRdfpKamhhUrVmAYBmBd3HjQoEHMmjULu93OmjVrcDqdR1VTZxXSQCSWwB3v1UMkItLppKSkMGbMGObOnRsIRP/+979JT0/nxz/+MTabjZNPPjnQ/g9/+AOvvfYab7zxBlOnTj2qbc+dO5eqqiqef/554uKs8PbEE09w/vnn8+CDD+J0OikpKeG8887j+OOPB6zhJn7bt2/nlltuoW/fvgD06tXrqOrpzBSIwkD9oGoFIhGRIM5Yq6cmVNtupoKCAiZNmsRf//pXXC4Xc+bMYcKECdhsNsrKyrj77rt566232L17N3V1dVRWVrJ9+/ajLnHDhg2cfPLJgTAEMHz4cLxeLxs3bmTEiBFcccUVjB49mp/85CeMGjWKiy++mOzsbMAaqvLLX/6Sf/7zn4waNYqf/exngeAUacJ2llkkqR9UrVNmIiJBDMM6bRWKh++0UnOcf/75mKbJW2+9xY4dO/joo48oKCgA4Oabb+a1117jgQce4KOPPmLNmjUMHDiQmpqa9jpqQWbPns2yZcsYNmwYL7/8Mr179+bTTz8F4O677+arr75i7NixfPDBB/Tv35/XXnutQ+oKNwpEYUA3eBUR6dyio6O56KKLmDNnDi+++CJ9+vTh1FNPBWDp0qVcccUVXHjhhQwcOJCsrCy+/fbbNtluv379WLt2LeXl5YFlS5cuxWaz0adPn8CyQYMGcfvtt/PJJ59w4oknBo297d27NzfeeCPvvfceF110EbNnz26T2jobBaIwoEHVIiKdX0FBAW+99RbPPPNMoHcIrHE5r776KmvWrGHt2rVccsklh8xIO5ptRkdHM3HiRL788ksWLVrE9ddfz2WXXUZmZiZbt27l9ttvZ9myZWzbto333nuPzZs3069fPyorK5k6dSoffvgh27ZtY+nSpaxcuTJojFEk0RiiMKAeIhGRzu+ss84iNTWVjRs3cskllwSWP/roo1x11VUMGzaM9PR0fvvb37bZTcNjY2N59913ueGGGzjttNOIjY1l/PjxPProo4H1X3/9Nc899xz79+8nOzubKVOm8Ktf/Yq6ujr279/P5Zdfzp49e0hPT+eiiy7innvuaZPaOhvDPNK8dwGsK2QnJSVRUlLSLrfx+GjzXi77xwr6ZiUwf9qINn9/EZHOoKqqiq1bt9KzZ8+g682JHMmRvjct+futU2ZhICFwYUadMhMREQkFBaIwoOsQiYgIWHdfiI+Pb/IxYMCAUJd3TNMYojDgH1RdVl2H12tiszV/qqeIiBw7fvrTnwZuTt5YpF5BuqMoEIWBBF8PkWlCaXUdSTH60ouIRKKEhAQSEhJCXUZE0imzMOBy2Il2Wh+FrlYtIiLS8RSIwkSCpt6LiIiEjAJRmAgMrNbFGUVERDqcAlGY8A+sLlUPkYiISIdTIAoT9VerVg+RiIhIR1MgChP19zNTD5GISGdz5plnMm3atFCXwd13380pp5wS6jI6JQWiMJGgizOKiMhRuvnmm1m4cGGoy2iWK664gnHjxoW6jAAFojAROGWmQdUiItJITU1Ns9rFx8eTlpbWztUcWW1t5/yHvQJRmEiMsXqINKhaRKSeaZpU1FaE5NHae59XV1dz880307VrV+Li4hg6dCgffvhhYP3+/fv5xS9+QdeuXYmNjWXgwIG8+OKLQe9x5plnMnXqVKZNm0Z6ejqjR4/mww8/xDAMFi5cyJAhQ4iNjWXYsGFs3Lgx8LrGp8z8vTCPPPII2dnZpKWlMWXKlKDQsnv3bsaOHUtMTAw9e/Zk7ty59OjRg5kzZzZrfw3DYNasWfz0pz8lLi6O+++/H4/Hw9VXX03Pnj2JiYmhT58+/OUvfwmq87nnnuO///0vhmFgGEbgGO3YsYOLL76Y5ORkUlNTueCCC/j222+bffxbS1eqDhOJug6RiMghKusqGTq36VtZtLfllywn1hnb4tdNnTqV9evX89JLL5GTk8Nrr73GOeecw7p16+jVqxdVVVUMHjyY3/72tyQmJvLWW29x2WWXcfzxx3P66acH3ue5557j2muvZenSpYAVXADuuOMO/vSnP9GlSxeuueYarrrqqkCbpixatIjs7GwWLVrEli1b+PnPf84pp5zCpEmTALj88svZt28fH374IU6nk5tuuomioqIW7fPdd9/NH//4R2bOnInD4cDr9dKtWzdeeeUV0tLS+OSTT5g8eTLZ2dlcfPHF3HzzzWzYsAG3283s2bMBSE1Npba2ltGjR5Ofn89HH32Ew+Hgvvvu45xzzuGLL74gKiqqRXW1hAJRmKgfVK1TZiIindX27duZPXs227dvJycnB7DG9cyfP5/Zs2fzwAMP0LVrV26++ebAa66//nreffdd/vWvfwUFol69evHQQw8FfvcHovvvv58f/ehHANx2222MHTuWqqoqoqOjm6wpJSWFJ554ArvdTt++fRk7diwLFy5k0qRJfP3117z//vusXLmSIUOGAPB///d/9OrVq0X7fckll3DllVcGLbvnnnsCP/fs2ZNly5bxr3/9i4svvpj4+HhiYmKorq4mKysr0O6FF17A6/Xyf//3fxiGdV/P2bNnk5yczIcffsjZZ5/dorpaQoEoHJgmaYabk40tnFyyBlZvgv7jIDox1JWJiIRUjCOG5ZcsD9m2W2rdunV4PB569+4dtLy6ujowtsfj8fDAAw/wr3/9i507d1JTU0N1dTWxscG9UYMHD25yGyeddFLg5+zsbACKiorIy8trsv2AAQOw2+1Br1m3bh0AGzduxOFwcOqppwbWn3DCCaSkpDR3lwECYaqhJ598kmeeeYbt27dTWVlJTU3N986AW7t2LVu2bDnkfm5VVVX873//a1FNLaVAFEoHv4UXL4HibQyvKeO/LqAceAMo3QM/uiW09YmIhJhhGK06bRUqZWVl2O12Vq1aFRRCwBrwDPDwww/zl7/8hZkzZzJw4EDi4uKYNm3aIQOn4+LimtxGw7ve+3tRvF7vYWtq2N7/miO1b43Gtb700kvcfPPN/OlPfyI/P5+EhAQefvhhli8/crgtKytj8ODBzJkz55B1Xbp0adOaG1MgCqXoZCj6KvDrbjMVmwGZHICSHaGrS0REWmXQoEF4PB6Kior44Q9/2GSbpUuXcsEFF3DppZcCVpjZtGkT/fv378hSAejTpw91dXV8/vnngR6pLVu2cPDgwaN636VLlzJs2DCuu+66wLLGPTxRUVF4PJ6gZaeeeiovv/wyGRkZJCZ27FkSzTILpZhkuPQ/MPUzin69jfzqJ5hVe761rqokpKWJiEjL9e7dm4KCAi6//HJeffVVtm7dyooVK5gxYwZvvfUWYI0NWrBgAZ988gkbNmzgV7/6FXv27AlJvX379mXUqFFMnjyZFStW8PnnnzN58mRiYmICvU+t0atXLz777DPeffddNm3axF133cXKlSuD2vTo0YMvvviCjRs3sm/fPmpraykoKCA9PZ0LLriAjz76iK1bt/Lhhx/y61//mu++++5od/eIFIhC7YRRkN6LRN/50hLT1zWsQCQi0inNnj2byy+/nN/85jf06dOHcePGsXLlysAYnzvvvJNTTz2V0aNHc+aZZ5KVlRXSCxQ+//zzZGZmMmLECC688EImTZpEQkLCYQdpN8evfvUrLrroIn7+858zdOhQ9u/fH9RbBDBp0iT69OnDkCFD6NKlC0uXLiU2NpYlS5aQl5fHRRddRL9+/bj66qupqqpq9x4jw2zthRYiiNvtJikpiZKSknb7QEzTpM+d8/mhuZJ/RP0Jck6FyYvaZVsiIuGoqqqKrVu30rNnz6P6YyxH57vvviM3N5f333+fkSNHhrqc73Wk701L/n5rDFGYMAyDhGgH7grfwDT1EImISAf44IMPKCsrY+DAgezevZtbb72VHj16MGLEiFCX1qF0yiyMJMY4caNTZiIi0nFqa2v53e9+x4ABA7jwwgvp0qVL4CKNc+bMIT4+vsnHgAEDQl16m1IPURhJjHZQZDboITJNOIpBbSIiIt9n9OjRjB49usl1P/3pTxk6tOkrhTeezt/ZKRCFkcQYJ1v8PUTeWqithKjOc/0NERE5tiQkJBxykcRjlU6ZhZHEaCflROP1fyw6bSYiEaitLxoox7a2mhumHqIwkhDtAAyqHQnE1JVYgSgxO9RliYh0iKioKGw2G7t27aJLly5ERUUd1bVw5NhnmiZ79+7FMIyjPoWnQBRG/Dd4rbLH1wciEZEIYbPZ6NmzJ7t372bXrl2hLkc6CcMw6Nat2yG3SmkpBaIwkhhtfRzlRhwpoEAkIhEnKiqKvLw86urqDrmtg0hTnE7nUYchUCAKK/4eojJD1yISkcjlP/1xrM1ikvCmQdVhJDHa+j+/G38gKg5dMSIiIhFEgSiMJMZYHXYl3hhrgXqIREREOoQCURhJ8PUQHfAoEImIiHQkBaIw4j9ltl+BSEREpEMpEIUR/ymzfXW+u/UqEImIiHQIBaIw4u8hOujRDV5FREQ6kgJRGImNsmO3GZSgafciIiIdSYEojBiGQUK0A7fZih4i927Yuap9ChMRETnGKRCFmcRoZ4PrELUgEL10Cfx9JBzc1j6FiYiIHMMUiMJMYkyjHqLm3sX3wP8AE0q+a7faREREjlUKRGEmqIfIWwu1ld//Iq+nvjeptqL9ihMRETlGKRCFmcRoJxW48Bq+G9U157RZwzY15e1TmIiIyDFMgSjMJEQ7AINqe7y1oDmBqPJg/c/qIRIREWkxBaIwk+S7431liwJRcf3P6iESERFpMQWiMHN8hhWEir0tmHqvHiIREZGjokAUZk7ulgxAUU0Lbt/RMBCph0hERKTFwjoQeTwe7rrrLnr27ElMTAzHH388f/jDHzAbTEU3TZPp06eTnZ1NTEwMo0aNYvPmzUHvc+DAAQoKCkhMTCQ5OZmrr76asrKyjt6dZumdGU+008YBr/8Gr8Xf/yIFIhERkaMS1oHowQcfZNasWTzxxBNs2LCBBx98kIceeojHH3880Oahhx7iscce46mnnmL58uXExcUxevRoqqqqAm0KCgr46quvWLBgAfPmzWPJkiVMnjw5FLv0vRx2GyfmJLXsatUNQ5NOmYmIiLSYI9QFHMknn3zCBRdcwNixYwHo0aMHL774IitWrACs3qGZM2dy5513csEFFwDw/PPPk5mZyeuvv86ECRPYsGED8+fPZ+XKlQwZMgSAxx9/nHPPPZdHHnmEnJyc0OzcEZycm4x7ZwuuVh3UQ6RAJCIi0lJh3UM0bNgwFi5cyKZNmwBYu3YtH3/8MWPGjAFg69atFBYWMmrUqMBrkpKSGDp0KMuWLQNg2bJlJCcnB8IQwKhRo7DZbCxfvrzJ7VZXV+N2u4MeHenk3OSW9RAFDarWKTMREZGWCuseottuuw23203fvn2x2+14PB7uv/9+CgoKACgsLAQgMzMz6HWZmZmBdYWFhWRkZAStdzgcpKamBto0NmPGDO6555623p1mO7lbEp9hBSJPZQn273uBeohERESOSlj3EP3rX/9izpw5zJ07l9WrV/Pcc8/xyCOP8Nxzz7Xrdm+//XZKSkoCjx07drTr9hrLS42lLioRgAr3/u9/QcPrEGkMkYiISIuFdQ/RLbfcwm233caECRMAGDhwINu2bWPGjBlMnDiRrKwsAPbs2UN2dnbgdXv27OGUU04BICsri6KioqD3raur48CBA4HXN+ZyuXC5XO2wR81jGAbp6RmwF6pLD5DwfS/QLDMREZGjEtY9RBUVFdhswSXa7Xa8Xi8APXv2JCsri4ULFwbWu91uli9fTn5+PgD5+fkUFxezatWqQJsPPvgAr9fL0KFDO2AvWifHdxrQ1IUZRURE2l1Y9xCdf/753H///eTl5TFgwAA+//xzHn30Ua666irA6kmZNm0a9913H7169aJnz57cdddd5OTkMG7cOAD69evHOeecw6RJk3jqqaeora1l6tSpTJgwISxnmPn16JoDX4KjtvTIDU1TY4hERESOUlgHoscff5y77rqL6667jqKiInJycvjVr37F9OnTA21uvfVWysvLmTx5MsXFxZxxxhnMnz+f6OjoQJs5c+YwdepURo4cic1mY/z48Tz22GOh2KVm69W9GwBx3jJKK2tIiIlqumFtBXhrG/yuU2YiIiItZZgNL/ssTXK73SQlJVFSUkJiYmLHbLS6DGZ0BeDTX3zJD/rkNt2u5Dv484D6321OmL6vAwoUEREJby35+x3WY4giWlQcHt/Hs/HbnYdv5z9dZvcNAvfWgqf28O1FRETkEApE4cowqHFaafbb75oRiBIbjIfSTDMREZEWUSAKY0Z0EgA7D3MBSaD+GkTxGWD4LuGomWYiIiItokAUxpxxyQDUlB+kyF3VdCN/D1FMKkT57n+mmWYiIiItokAUxuwxyQAkUsHa7w5zPaJAIEoGp+/+Z5ppJiIi0iIKROHMd8os0ahg7Y7iptsEAlEKRPkCkXqIREREWkSBKJz5AxHlrP2uuOk2Vb7lMSng9J0yUw+RiIhIiygQhbNGPURNXjJKPUQiIiJHTYEonEUnA5Biq8BdVcemPWWHtvEHoujkBmOIFIhERERaQoEonPl6iHrE1QHw0ea9h7YJ6iHyzzLTKTMREZGWUCAKZ75A1DWmBoAlm5u4JYf/OkQxKeohEhERaSUFonDmC0TpjkoAln+zn6paT3CbQCBK1hgiERGRVlIgCme+QOSqKyMrMZrqOi8rvz1Qv95TCzWl1s+aZSYiItJqCkThzBeIjKoSftgrHYAlmxqMI/L3DvnbqodIRESkVRSIwpkvENEgEH3UcBxRYIZZEtjsGkMkIiLSSgpE4cwfiLy1nNEjDsOArwtL2eO/r5n/ooy+6fmaZSYiItI6CkThLCoucAf7VFslA7taASnQS9Rwyj2oh0hERKSVFIjCmWEEnTYb0asL0GAcUeNApDFEIiIiraJAFO4aBqLeViD6eMs+vF6ziR4izTITERFpDQWicNcgEA3KSybe5eBAeQ1f7XIHX4MI1EMkIiLSSgpE4a5BIHLabeQfnwbAks17j9BDpEAkIiLSEgpE4S4QiIoBGNHwekSHHUOkU2YiIiItoUAU7hr0EAGBcUSrth2krtx31WrNMhMRETkqCkThrlEg6p4WR/e0WOq8JmUlvun3ja9DVFcF3kb3PBMREZHDUiAKd/6w4wtEQOCq1XVl+60FjXuIQL1EIiIiLaBAFO4a9RAB/OA4a2C1s8a3LBCIYgDD+lkzzURERJpNgSjcNRGIrCtWm8R5y6wF/kBkGA3GEWlgtYiISHMpEIW7JgJRXmos2dG1OAyvtcB/HSLQtYhERERaQYEo3DURiAzD4LRM69RYnc3lO1Xmo5lmIiIiLaZAFO6aCEQAp6SbAFTYE4Lb6473IiIiLaZAFO4aBiLTDCzul2xNqz/ojQturx4iERGRFlMgCnf+QOSthdrKwOLjE+oAKKqLodbjrW+vMUQiIiItpkAU7qLiwO6yfi7eHljcxW4FnoPeODbvKatvrzvei4iItJgCUbgzDOhxhvXz5nfrF1dZ9zErNuP5cmeD8UXqIRIREWkxBaLOoM8Y63njO/XLfDd2LSGOdQ0Dka5DJCIi0mIKRJ2BPxDtWA7lvvuXVRYDVg9RUCAKzDJTD5GIiEhzKRB1BkndIOskML2w+T1rWYMeog273dT5B1ZrlpmIiEiLKRB1Fn3OtZ43vm09+3qIqhxJVNd52VzkG1gdGEOkU2YiIiLNpUDUWfhPm235AGqrAj1EqWldAOpPmwVmmamHSEREpLkUiDqL7JMhsas1WHrrEqgqBiArKxugfqaZZpmJiIi0mAJRZ2EYDWabvR3oIcrt2hVoqodIp8xERESaS4GoM/EHoq/nBU6J9eqeC1A/sFo9RCIiIi2mQNSZ9PghRMVD+V7fAoO87CziXQ6qar1s2VumWWYiIiKtoEDUmThccMLI+t9jkrHZ7QzISQRg3Xclutu9iIhIKygQdTb+6fcAMSkADOxq3QD2y50l6iESERFpBQWizqbX2WD4PrboZAAGdrMC0bqdJRpDJCIi0goKRJ1NbCrk5Vs/+3qITvT1EK3f7abOHmOtq60A0wxFhSIiIp2OAlFnNOBC6zn1OAB6psUFBlZvdfsbmVBbGZLyREREOhtHqAuQVhhyNSRkQ/dhANhsBsd3iWPtdyX8r9hLL3+72or6U2giIiJyWOoh6oxsNuh3nnX6zCcvzZpdtv1gFTiirYWaaSYiItIsCkTHiO6pVk/Qtv0VmmkmIiLSQgpEx4i8NCsEbT9Q0eBaRApEIiIizaFAdIxouodIp8xERESaI+wD0c6dO7n00ktJS0sjJiaGgQMH8tlnnwXWm6bJ9OnTyc7OJiYmhlGjRrF58+ag9zhw4AAFBQUkJiaSnJzM1VdfTVlZWUfvSrvq7htDtLO4Eq9T1yISERFpibAORAcPHmT48OE4nU7eeecd1q9fz5/+9CdSUlICbR566CEee+wxnnrqKZYvX05cXByjR4+mqqoq0KagoICvvvqKBQsWMG/ePJYsWcLkyZNDsUvtJiPBhcthw+M1qbH5BlWrh0hERKRZwnra/YMPPkhubi6zZ88OLOvZs2fgZ9M0mTlzJnfeeScXXHABAM8//zyZmZm8/vrrTJgwgQ0bNjB//nxWrlzJkCFDAHj88cc599xzeeSRR8jJyenYnWonNptBXmosm4vKKDddRIN6iERERJoprHuI3njjDYYMGcLPfvYzMjIyGDRoEH//+98D67du3UphYSGjRo0KLEtKSmLo0KEsW7YMgGXLlpGcnBwIQwCjRo3CZrOxfPnyJrdbXV2N2+0OenQG/tNmpZ4oa4FmmYmIiDRLWAeib775hlmzZtGrVy/effddrr32Wn7961/z3HPPAVBYWAhAZmZm0OsyMzMD6woLC8nIyAha73A4SE1NDbRpbMaMGSQlJQUeubm5bb1r7aK7b6ZZSZ3TWlBzbI2TEhERaS9hHYi8Xi+nnnoqDzzwAIMGDWLy5MlMmjSJp556ql23e/vtt1NSUhJ47Nixo12311b8gWh/re9MqE6ZiYiINEtYB6Ls7Gz69+8ftKxfv35s374dgKysLAD27NkT1GbPnj2BdVlZWRQVFQWtr6ur48CBA4E2jblcLhITE4MenUGeb+r9vipfINIpMxERkWZpVSBavXo169atC/z+3//+l3HjxvG73/2OmpqaNitu+PDhbNy4MWjZpk2b6N69O2ANsM7KymLhwoWB9W63m+XLl5Ofb90RPj8/n+LiYlatWhVo88EHH+D1ehk6dGib1RoO/GOI9lT5PlbdukNERKRZWhWIfvWrX7Fp0ybAGuczYcIEYmNjeeWVV7j11lvbrLgbb7yRTz/9lAceeIAtW7Ywd+5cnn76aaZMmQKAYRhMmzaN++67jzfeeIN169Zx+eWXk5OTw7hx4wCrR+mcc85h0qRJrFixgqVLlzJ16lQmTJhwzMww8+uaHIPNgBINqhYREWmRVgWiTZs2ccoppwDwyiuvMGLECObOncuzzz7Lf/7znzYr7rTTTuO1117jxRdf5MQTT+QPf/gDM2fOpKCgINDm1ltv5frrr2fy5MmcdtpplJWVMX/+fKKjowNt5syZQ9++fRk5ciTnnnsuZ5xxBk8//XSb1Rkuohw2cpJjqMRlLdAYIhERkWZp1XWITNPE6/UC8P7773PeeecBkJuby759+9quOuC8884LvH9TDMPg3nvv5d577z1sm9TUVObOndumdYWr7mmxVJT4ApEuzCgiItIsreohGjJkCPfddx///Oc/Wbx4MWPHjgWs6wI1ngIvHSsvNY4K9RCJiIi0SKsC0cyZM1m9ejVTp07ljjvu4IQTTgDg3//+N8OGDWvTAqVluqfF1p8y0xgiERGRZmnVKbOTTjopaJaZ38MPP4zdbj/qoqT1uqfG8r7p7yHSKTMREZHmaFUP0cqVK5u87cXatWtZu3btURclrZeXFksl/pu7qodIRESkOVoViKZMmdLk1Zt37twZmBIvodE9rX4MkakeIhERkWZpVSBav349p5566iHLBw0axPr164+6KGm9eJcDV0y89UttBZhmaAsSERHpBFoViFwu1yG3ywDYvXs3DkerhiVJG0pPTQHAML1QVx3iakRERMJfqwLR2WefHbgBql9xcTG/+93v+MlPftJmxUnrZKan1f+icUQiIiLfq1XdOY888ggjRoyge/fuDBo0CIA1a9aQmZnJP//5zzYtUFquW1oiNaadKMNjzTSLTQ11SSIiImGtVYGoa9eufPHFF8yZM4e1a9cSExPDlVdeyS9+8QucTmdb1ygt5L8WURQV6iESERFphlYP+ImLi2Py5MltWYu0ke5psVQQTRIVuhaRiIhIMzQ7EL3xxhuMGTMGp9PJG2+8ccS2P/3pT4+6MGm9vNQ43KYLDKipKiMq1AWJiIiEuWYHonHjxlFYWEhGRgbjxo07bDvDMPB4PG1Rm7RSenwUew3rWkT7Dxwk+/gQFyQiIhLmmh2I/He3b/yzhB/DMPA6YsED+w8Wkx3qgkRERMJci6fd19bWMnLkSDZv3twe9UgbMaLiACguORjiSkRERMJfiwOR0+nkiy++aI9apA3Zo61A5Ha7Q1yJiIhI+GvVhRkvvfRS/vGPf7R1LdKGony37ygrUyASERH5Pq2adl9XV8czzzzD+++/z+DBg4mLiwta/+ijj7ZJcdJ60bGJAFRXlIa4EhERkfDXqkD05ZdfBm7uumnTpjYtSNpGbHwCAHVVZZimiWEYIa5IREQkfLUqEC1atKit65A2Fhdv9RA5PZW4K+tIitUVxEVERA6nVWOIrrrqKkpLDz0VU15ezlVXXXXURcnRc0ZbY4hijGq+K9btO0RERI6kVYHoueeeo7Ky8pDllZWVPP/880ddlLQB37T7WKrZefDQz0pERETqteiUmdvtxjRNTNOktLSU6OjowDqPx8Pbb79NRkZGmxcpreCMBaxAtLVYgUhERORIWhSIkpOTMQwDwzDo3bv3IesNw+Cee+5ps+LkKPh7iIwqdioQiYiIHFGLAtGiRYswTZOzzjqL//znP6SmpgbWRUVF0b17d3Jyctq8SGmFWOuzSaVUgUhEROR7tCgQ/ehHPwJg69at5OXlaSp3OItNByDVKNUYIhERke/RqkHV3bt35+OPP+bSSy9l2LBh7Ny5E4B//vOffPzxx21aoLRSnBWIUowyCg+Wh7gYERGR8NaqQPSf//yH0aNHExMTw+rVq6murgagpKSEBx54oE0LlFaKqT+d6SnfT1WtJ4TFiIiIhLdWBaL77ruPp556ir///e84nfUX/Bs+fDirV69us+LkKNgdmDEpAKQabnZpHJGIiMhhtSoQbdy4kREjRhyyPCkpieLi4qOtSdqI4RtHlGa4NbBaRETkCFoViLKystiyZcshyz/++GOOO+64oy5K2ohvHFEqpeohEhEROYJWBaJJkyZxww03sHz5cgzDYNeuXcyZM4ebb76Za6+9tq1rlNaKTQOsU2aaaSYiInJ4rbq562233YbX62XkyJFUVFQwYsQIXC4XN998M9dff31b1yitFVd/ymy7eohEREQOq1WByDAM7rjjDm655Ra2bNlCWVkZ/fv3Jz4+vq3rk6MRW3/K7FMFIhERkcNqUSBq7p3sn3nmmVYVI23MP4ZIg6pFRESOqEWB6Nlnn6V79+4MGjQI0zTbqyZpK/5ZZpSyu7gKj9fEbtPVxUVERBprUSC69tprefHFF9m6dStXXnkll156adD9zCTMxFmDqtMMN3Vek6LSKrKTYkJclIiISPhp0SyzJ598kt27d3Prrbfy5ptvkpuby8UXX8y7776rHqNwFNcFgHRbKYCm3ouIiBxGi6fdu1wufvGLX7BgwQLWr1/PgAEDuO666+jRowdlZWXtUaO0lu+UWRKlGHj5TlPvRUREmtSq6xAFXmyzYRgGpmni8eheWWHHdx0iO16SKNfAahERkcNocSCqrq7mxRdf5Cc/+Qm9e/dm3bp1PPHEE2zfvl3T7sONIwpcSYDv9h3qIRIREWlSiwZVX3fddbz00kvk5uZy1VVX8eKLL5Kent5etUlbiEuD6hLdvkNEROQIWhSInnrqKfLy8jjuuONYvHgxixcvbrLdq6++2ibFSRuITYcD35BquNmqQCQiItKkFgWiyy+/HMPQdWw6lcDtO0r5+GAlpmnqMxQREWmkxRdmlE7Gf4NX3JTXeHBX1pEU6wxxUSIiIuHlqGaZSSfg6yHqGlUOwHfFFaGsRkREJCwpEB3rfNciyvEFIs00ExEROZQC0bHO10OUYbMumqlrEYmIiBxKgehY5+shSsEN6PYdIiIiTVEgOtb5bvCa4C0G1EMkIiLSFAWiY52vhyimphgwNYZIRESkCQpExzrfGCKbWUsClewsrgpxQSIiIuFHgehY54wBZxwAqYabfWXVVNXqRrwiIiINdapA9Mc//hHDMJg2bVpgWVVVFVOmTCEtLY34+HjGjx/Pnj17gl63fft2xo4dS2xsLBkZGdxyyy3U1dV1cPUh5BtH1NVpTb0PDKz2euDtW+CLV0JVmYiISFjoNIFo5cqV/O1vf+Okk04KWn7jjTfy5ptv8sorr7B48WJ27drFRRddFFjv8XgYO3YsNTU1fPLJJzz33HM8++yzTJ8+vaN3IXR844hOiLNOlwUGVm9dAiuehoX3hKoyERGRsNApAlFZWRkFBQX8/e9/JyUlJbC8pKSEf/zjHzz66KOcddZZDB48mNmzZ/PJJ5/w6aefAvDee++xfv16XnjhBU455RTGjBnDH/7wB5588klqampCtUsdyzeOqEeMFYQCPUSF66zniv2hqEpERCRsdIpANGXKFMaOHcuoUaOClq9atYra2tqg5X379iUvL49ly5YBsGzZMgYOHEhmZmagzejRo3G73Xz11VdNbq+6uhq32x306NQaX63aP7B6z5fWc20F1FWHojIREZGw0KKbu4bCSy+9xOrVq1m5cuUh6woLC4mKiiI5OTloeWZmJoWFhYE2DcOQf71/XVNmzJjBPfccQ6eRfGOIshzW1arre4i+rG9TWQwJmYiIiESisO4h2rFjBzfccANz5swhOjq6w7Z7++23U1JSEnjs2LGjw7bdLnw9RKmUAr77mdVVw76N9W0qD4aiMhERkbAQ1oFo1apVFBUVceqpp+JwOHA4HCxevJjHHnsMh8NBZmYmNTU1FBcXB71uz549ZGVlAZCVlXXIrDP/7/42jblcLhITE4MenZpvDFGiWQLArpJK2LsRvA1m2lUVh6AwERGR8BDWgWjkyJGsW7eONWvWBB5DhgyhoKAg8LPT6WThwoWB12zcuJHt27eTn58PQH5+PuvWraOoqCjQZsGCBSQmJtK/f/8O36eQ8PUQxdZavUC7i6vw+gdU+6mHSEREIlhYjyFKSEjgxBNPDFoWFxdHWlpaYPnVV1/NTTfdRGpqKomJiVx//fXk5+fzgx/8AICzzz6b/v37c9lll/HQQw9RWFjInXfeyZQpU3C5XB2+TyHh6yFyVh/AZkCNx0vVjrXENmyjQCQiIhEsrANRc/z5z3/GZrMxfvx4qqurGT16NH/9618D6+12O/PmzePaa68lPz+fuLg4Jk6cyL333hvCqjtYrDWo2ijfT1ZiNLtKqvDs9vUQGXYwPdagahERkQhlmKZphrqIcOd2u0lKSqKkpKRzjieqLoUZ3QAoyHiNpdsr2JR4HVE1JdB1COz8DEbcCmfdEeJCRURE2k5L/n6H9RgiaSNR8WC3Tg/2jq8iiwNWGDLskGedWtQpMxERiWQKRJHAMOqvVh1bRT/bdmt5em9IyLZ+1iwzERGJYApEkcI3jqibq4J+xjZrWdaJEOO7FYp6iEREJIIpEEUKXw9RtqOU/v4eoswTISbZ+lmBSEREIlinn2UmzeS7FlG6UYarYQ+R0zf5XrPMREQkgikQRQpfD1FyTSFphnUPt4qUfsR6fDeuVQ+RiIhEMJ0yixS+MURRO5ZiN0z2mons8iRCdLK1vqoYvN6QlSciIhJKCkSRwtdDxN4NAGzwdmdncVX9GCLTCzWloalNREQkxBSIIoVvDJHfBjPPuuu9MwYcMdZCnTYTEZEIpUAUKeKCA9F6b3d2FVdav2immYiIRDgFokgR1yXo1w1mw0DkvxZRccfWJCIiEiY0yyxS+AZVA3hsTr4xs0k+JBCph0hERCKTeogiRXQS2JwAVCf3pg5HfQ+Rf6aZApGIiEQoBaJIYRj1vURZJwJQWFKFx2vW9xDpfmYiIhKhFIgiiW9gdXS3k3HYDOq8JntLqzWoWkREIp4CUSQ57kxwxmLrfTZZSdEA7CyuUCASEZGIp0AUSUbfD7/dBum9yEm2rj1kXZxRs8xERCSyKRBFGkcUAF19gWhXcaUCkYiIRDwFogiVk+w7ZXawUtPuRUQk4ikQRaiuybGAr4eo4Q1eRUREIpACUYQK9BAVq4dIREREgShCNTmGqLYC6qpDWJWIiEhoKBBFKP8sM3dVHaXEAIa1QgOrRUQkAikQRag4l4PkWOtWHrtKanQtIhERiWgKRBEsJ6mpqfcKRCIiEnkUiCKY/7TZd5ppJiIiEU6BKIJ1S1EPkYiICCgQRTT/1HsFIhERiXQKRBEscD+zg5UNBlUXh6weERGRUFEgimDdUqyrVX+7vxzTP4ZIPUQiIhKBFIgiWN+sBJx2g31lNRQTby3UoGoREYlACkQRLNppZ0BOEgBby6xrEqmHSEREIpECUYQb3N0aTL2h2G4tUCASEZEIpEAU4fyB6PN9unWHiIhELgWiCOcPROv2+wOReohERCTyKBBFuMzEaLomx3DAG2ctqCoGrzekNYmIiHQ0BSJhcPcU3PgCkemFmtLQFiQiItLBFIiEwd1TqCaKasNlLdBpMxERiTAKRBIYR1Rs+nqJFIhERCTCKBAJfbMSiHHa68cRaaaZiIhEGAUiwWG3cUpucv04IvUQiYhIhFEgEsA6bVZs+m7foUAkIiIRRoFIgEaBSPczExGRCKNAJAAMykumxHfKrNK9P8TViIiIdCwFIgEgOTYKe6w12+zgvj0hrkZERKRjKRBJQEp6JgBlxftCXImIiEjHUiCSgKzMLABqy3XKTEREIosCkQR079YVAEd1CbUe3c9MREQihwKRBGRn5gCQQBkbdrtDXI2IiEjHUSCSAFtsMgDJlPPZt7oWkYiIRA4FIqkXY80yizWqWbO1MMTFiIiIdBwFIqnnSsQ0rK/Exm+/wzTNEBckIiLSMRSIpJ7NBtFJAHgqDvDt/ooQFyQiItIxwjoQzZgxg9NOO42EhAQyMjIYN24cGzduDGpTVVXFlClTSEtLIz4+nvHjx7NnT/CFBbdv387YsWOJjY0lIyODW265hbq6uo7clU7D8J02S6aMlVsPhLgaERGRjhHWgWjx4sVMmTKFTz/9lAULFlBbW8vZZ59NeXl5oM2NN97Im2++ySuvvMLixYvZtWsXF110UWC9x+Nh7Nix1NTU8Mknn/Dcc8/x7LPPMn369FDsUvjzBaIko5wV3yoQiYhIZDDMTjRQZO/evWRkZLB48WJGjBhBSUkJXbp0Ye7cufy///f/APj666/p168fy5Yt4wc/+AHvvPMO5513Hrt27SIz07oS81NPPcVvf/tb9u7dS1RU1Pdu1+12k5SURElJCYmJie26jyH3z4vgfwv5Tc01fJZyDotv+XGoKxIREWmVlvz9DuseosZKSkoASE1NBWDVqlXU1tYyatSoQJu+ffuSl5fHsmXLAFi2bBkDBw4MhCGA0aNH43a7+eqrr5rcTnV1NW63O+gRMeKt49TDVsi2/RUUuatCXJCIiEj76zSByOv1Mm3aNIYPH86JJ54IQGFhIVFRUSQnJwe1zczMpLCwMNCmYRjyr/eva8qMGTNISkoKPHJzc9t4b8JYj+EA/MS1AUCnzUREJCJ0mkA0ZcoUvvzyS1566aV239btt99OSUlJ4LFjx45232bYOM46Rdbbs5kkDawWEZEI0SkC0dSpU5k3bx6LFi2iW7dugeVZWVnU1NRQXFwc1H7Pnj1kZWUF2jSedeb/3d+mMZfLRWJiYtAjYiR1hS59seFlmO0rVuiK1SIiEgHCOhCZpsnUqVN57bXX+OCDD+jZs2fQ+sGDB+N0Olm4cGFg2caNG9m+fTv5+fkA5Ofns27dOoqKigJtFixYQGJiIv379++YHelsjj8LgB/avuDrQjcllbUhLkhERKR9hXUgmjJlCi+88AJz584lISGBwsJCCgsLqaysBCApKYmrr76am266iUWLFrFq1SquvPJK8vPz+cEPfgDA2WefTf/+/bnssstYu3Yt7777LnfeeSdTpkzB5XKFcvfCly8QneX8EtM0Wb1NvUQiInJsC+tANGvWLEpKSjjzzDPJzs4OPF5++eVAmz//+c+cd955jB8/nhEjRpCVlcWrr74aWG+325k3bx52u538/HwuvfRSLr/8cu69995Q7FLn0H0Y2KPIMvfS0yjUwGoRETnmdarrEIVKRF2HyO+582HrEqbXTmR9twn8+9phoa5IRESkRY7Z6xBJBwqMI1rHF9+VUFXrCXFBIiIi7UeBSJrmC0TD7OsxPTV88V1JiAsSERFpPwpE0rTMgRCbThxVDDI2s1LjiERE5BimQCRNs9ngeOsijT+0r2OFLtAoIiLHMAUiObwG44hWbzuI16vx9yIicmxSIJLD893G4yTjG2zVxezWjV5FROQYpUAkh5eYDRn9sRkmw21fsnlPaagrEhERaRcKRHJkDU6bbSkqC3ExIiIi7UOBSI7MN7B6hP0LtqiHSEREjlEKRHJkecPwGg66GvspLtwa6mpERETahQKRHFlULNXp/QFI2vc5utOLiIgcixSI5Hs5e/wAgL51G9hXVhPiakRERNqeApF8L0d3KxANtm1ic5HGEYmIyLFHgUi+X7fTAehvbOPbXUUhLkZERKTtKRDJ90vqhtvZBYfhpWrbqlBXIyIi0uYUiOT7GQYl6acCELtHgUhERI49CkTSLLa8oQB0LfsixJWIiIi0PQUiaZaUPsMBGODdSEm5ZpqJiMixRYFImiU271SqcZJqlLHjf+olEhGRY4sCkTSPI4pvo/oAUL7lkxAXIyIi0rYUiKTZ9qWcAoBz12ehLURERKSNKRBJs3m6DgEgo2RtiCsRERFpWwpE0mwJvYYBkFO7DSqLQ1uMiIhIG1IgkmbrkdeTb72Z2DCp+nZFqMsRERFpMwpE0mwpcVGst1sDq0s2fRziakRERNqOApG0yK6Ek6wfdqiHSEREjh0KRNIiVdmDAUg+sBa8nhBXIyIi0jYUiKRFEnJPosyMxuWtgKINoS5HRESkTSgQSYuckJXMGu/x1i+fvwCeutAWJCIi0gYUiKRFTsiI5z2vdT0ils+Cp38E23TlahER6dwUiKRFMhJcvO4cw+9qr8bjSoI9X8LsMfDqZCgtDHV5IiIiraJAJC1iGAbHZyQy1zOS90e+A6dOBAz44mWYeZIVjLZ9AqYZ6lJFRESaTYFIWqxXRjwAr22swnveX2DSQug6BDzVVjCaPQaePB0+eRx2fQ7VZSGuWERE5MgM09Q/5b+P2+0mKSmJkpISEhMTQ11OyC3/Zj+X/N9yPF6TK4b14Pfn98cA2LkaVj8L6/4DteXBL0rsCum9oNtpMOx6iE4KQeUiIhJJWvL3W4GoGRSIDvXa599x48vWTV5vHNWbG0b1ql9Z5YYv/w1fvmpNza/YF/zihGwY+yfoO7YDKxYRkUijQNTGFIia9uzSrdz95noA7j6/P1cM79l0w4oDsH8LFK2HpY/Bgf9Zy/v9FM59GBKyOqhiERGJJC35+60xRNJqVwzvyTRfz9Ddb67n36u+a7phbCrkng6Dr4Brl8IZN4Fhhw1vwBOnw+KH4OC3HVa3iIhIY+ohagb1EB2eaZrc8+Z6nv3kWwCG9kzl1yN7Mez4NAzDOPwLC9fBG9dbg679cn8AJ10MAy60QpSIiMhR0CmzNqZAdGRer8kf53/N7KVbqfVYX6dBeclcf9YJ/LhPxuGDkdcD616BtS/CN4sB31fRsEHmidB9GOTlW8/xGR2zMyIicsxQIGpjCkTNs6u4kqeXfMOLK7ZTXecFIDc1hnGndGXcoK4c3yX+8C9274Iv/2NN2y9cd+j66GSITbMecekQnwk9fwjHnwUxKe2zQyIi0qkpELUxBaKW2Vtazf99/A1zPt1OWXX9vc5O6pbET0/O4cd9MzguPe7wPUfu3bD9E9i2DLYvgz1fEeg9asywW+OTev3ECkeZA8HuaPudEhGRTkeBqI0pELVOZY2HBRv28PrnO1m8aS8eb/1XLTc1hjN7Z/Cj3l34wfFpxLuOEGKq3FC6Gyr2W4/yfdastS0LYe+G4LZR8da1jvyn27IGQkxy++ygiIiENQWiNqZAdPT2lVUzb+0uFmzYw8qtB6nxeAPrHDaDU3KTGXZCOsOPT2NQXgpRjmZOgCzeDpsXwJb3YdtSqCo5tE1iV8joD5n9Ibk7uBKs4BQV53uOBWcMOBs82+xttOciIhIqCkRtTIGobZVX1/HpN/v5cONeFm/ay/YDFUHro502BnZN4pTcZAblpXBKbjLZSdFHnrUG4PVa1zravsy6n9p3K6FkR8sLtDkgqZsVnlK6Q3IeOGLA9ILpsZ6j4qHHDyGjHzRVl2lag8Z1+k5EJGQUiNqYAlH72nGggqVb9rH0f/tZ9r997CurOaRNalwUfTIT6JudQN+sBPpkJdIrI564I51qA6vHqGiDNQ6paD2UFkJ1KdSUQ02Z9VxbAbWV1nNLJeRYY5eO/7EVlAq/gMIvrYHhlQeg+3DrApT9zoPEnJa/v4iItJoCURtTIOo4pmnyv73lrNlRzJodB/l8ezFfF5YGjT9qqFtKDL0zE+idmcBxXeLITYklLy2WrMRo7Lbv6VE6dONQV2WNUSreDsXb4OA2q5fJW2ddDsCwWT1C7t3WKbq6qua/f7fTrICUnAtJeVYvVGKOdYrO7my6p0lERFpNgaiNKRCFVmWNh81FpXxdWMpG3+PrwlL2lVUf9jVOu0FOcgy5KbHkpsaQmxrr+zmWrskxpMdHff8puO9TW2XNhtuyEL79CBzRkHUSZJ1oDeZ2JcGm+bDhTdixnMPOlPOzu8AeZY1pik62BoNHJ1uXFYhNhZhU6zk2zbo5riMaHK765/gMa3yUiIgACkRtToEoPB0sr2HTnlLfo4xv95fz3cFKvjtYEbhA5OFEO23kJMfQNTmGLvEukmOjSIl1khIXRVpcFBmJLjISoumS4CLa2QYDrEsLYePbUPS11eNUsgOKd0BV8dG/d0OuJKvnKakrxKZbY568ddbDUwd1ldZpwuoy65Sh1wOJ2b7eqq6QlAvRDb/jhjWmKi7duilvQpYVxtSbJSKdgAJRG1Mg6lw8XpM97iq2H6hgx4EKdhys5LsDFew4WMF3ByspdFfRkm99YrSD1LioQGiynqNIjbMCVGpslPUcZy1PiXXisDdzllxtpXXazVMLddXgqbGCSmWxFZb8zxUHrEsOVB60nqtKrPZ11dbrayuhtrzlB6s1HDFW75XdCTan9exwQUpPyBzQYEZfD7DpdokiEjoKRG1MgejYUlPnZXdJJTsPVvJdcSUHy2s4UFFDcXktBypq2F9WTVGp9aip837/GzYhOdZJamwUiTFOkmKcvmcHcS4HLocdl8OGy2Ej2mkn1dcrlRYfRVqci/hoBw6b0fJTetWlULIT3N9Zz5UHrN4d/8OwWeOVXA0uOWDYrKuEu3dCyXdWz1VNBWASSI2eGijfa/VytbRHy+YLS3andUrQ5rAuaWCzWz9j+HqxfA/TY9XkX29zWBffNL3Bs/z8PVcN38vmsLZns1vbAytoej3grbV6yTCCx4IZdmsmoD/Y+d/TsNfXgeHbpv+Y+GYQeuus5V6Ptcz/HnanderT8IVBw7DeA+q3i1G//Yb7YNiDtxPEqH8//+sMuy90+o+jt8HxrLV6Bb211nEwvcEh1u60tuOpqX94PdZ3JCqu/jtis/t6GGt9x9HToH5bg8+rwbG3OaztNTz+pun7LkRZD0eU7zj73sf/njT63huNPjP/5+Gtq//O+L8Pdmd9LU3+/6fxe9safN6+7Xt97+3vXcVocKztwXU0/HyD9qPBcTFsvuPhgboa6x8w/n/82KPAGV1/2tvmqN8nr8c6Zv73PaSGBg//d+VIf86DjmOj4x303Ph1/u9Y59SSv9+aEywRJ8pho3taHN3T4o7YzjRN3JV1FJVWcbCiluKKGooraimurOFAufX7/vIaK1D5Q1VFLYDVzvdzazntBg6bDafdICHaClWJ0Q4SY5zEuxxE2W04HQZOu40ouw2X006M00mM83hionoTHW8nLspBrMtObJSDuCg7sS4H8VEO4lz25vdiNVRb6Zup57b+2HpqrD92NeWwbxPsWQ9FX8HeTeCp9q07uuMgImGgYRhrHCyhiZDY5JscGiAbBrX4DLjm4/apvxkUiEQOwzAMkmKdJMU6m/2aOo+X4sraQEgqqazFXVVHSWUtJZW1VNbUUV3nparWQ3Wdl4oaDwfLrWC1v6wad1X9rU5qPSa1Hg+VteCuqmNncWWb7l+Uw0ZslP2Q/7S5HHbiXHbio50kuBzERtlxOmw4bQYOuw2HzcBpt+OwO3DaY3HYDKKddgbknMppg1NJjHZaYanyQIPeB98pwUCvSl39z4a9Qc+M71+73gZjn7yeQ//FbZoNxkc1HCdV2+C9zfreCv8zNOht8taPrfI26knx9/z4f27ci+H/V7O/V8cw6rfv32fTG9zTY/r+p+HyQG9AXX3PRON/tde/uInX+Z5NrHoa9hwF7bvTqt9bF/yZGDarp8bfa2PYrB4M/xizmjKr3kDvm6P+oqX+/fD33AWOv69HyF9L4NgbVkiua9Qj5e8R8/fCBfaT+nUNj5tp1veq+bcB9T1Y/l6xxprqPWnY6+j1bb9hr52/xy5wvL2H9hY29Rz0HfMdG5vd10Pmqj/mnlpfj1FV/f8/Gn6Ghq3B8W3wmX/fBI32YHrA42nfbRih7YlSIBJpQw67jfR4F+nxrla9vqbOS0VNHbUekzqvlzqPSXWdl7LqOty+UOWuqqW8us4XmLzUerzU1HmpqvVSWeuhstZDVY2HihoPFbUeKqrrqKjxUF5TR0W1J3CV8Jo672FOCba+R8dmwIldk8g/Lo2B3ZJIiHYR74olzmWdLnTabdhthvUwDCtTGAY2w8AwCDwbWIHUeuboZwSKHGv8wcvrafoUntWovm1QqDxcsDtkI8GnYQOnrJuopfG2mmzTRC0Nfw7xHQIiKhA9+eSTPPzwwxQWFnLyySfz+OOPc/rpp4e6LJGAKIeNKEdUu27DH7rKazxU1lg9UoH/VgHVtVYAK6uuo9z3XOfxUuc1qfWYeLxeajxmYFlNnZfSqjpWbTvAt/sr+OK7Er74rolbqBwlmy8Y2QwwsFJTIDBhBNb7A5XNZhwSrKBh4LJe11TWsvkW+oeVGBwa1GgquFH/Or9A+ybez/c2EPQeh77OZhy6v4dup9H7Nt4u9cGy4XJ/FY2PS8N6Gws+/k2/56HHymi0f/XbCXpv/zEK+twO3X7Q52EErwve50Y1GsHv0RRbE/U2LrKp71BzAnzj71PjY3Gk7079PtavP9w6jMaff/Bxafy6+tcHf7aHtrU12N+maw6qo9HrD/nuN+By2jgr49CaOkrEBKKXX36Zm266iaeeeoqhQ4cyc+ZMRo8ezcaNG8nICOEnINLB/KErObbt33t3SSXL/refZf/bz9Z95VaoqqmjvNoTCFaHucbm9/KagGliddprLojIsSYjwcWKOzJDtv2ImWU2dOhQTjvtNJ544gkAvF4vubm5XH/99dx2221HfG17zTLzeD3sqdjTZu8n0hmYponXBK/XxItp3fbNNPGaptVzjq9X39/WepXVe+9r61uCaZpBw028pvWeXtO3rv6lgeEnJmbTZwcC9dW/1htoazaoyfqf+jrN4GFCNOxxM4OWBTbbcL0ZvL9mYL0Z9DqT4Nr97TnCewYdp6A2wS8zG722vgQzqF1gUYP9b/x+NKgrcLyDd+mIn4H/MzWp/6yDG9S/l/8zalhqw7rqGwcfr6DPImjbjY9B00U2bBf8mZuHP2PUYLuB702Tbeq/301+XmaDVzZ6n6CzUg3rb3gMgrbW1H7Vb6PJw282bm82uTx4vw5t05TE6Ciem3j2kRu1kGaZNVJTU8OqVau4/fbbA8tsNhujRo1i2bJlh7Svrq6murr+Kshut7td6jpYfZDR/xndLu8tIiLSIkaj5w7WJaYL0LaBqCUiIhDt27cPj8dDZmZwV1xmZiZff/31Ie1nzJjBPffc0yG1ueytG3wrIiJyLImyt+/4ye8TEYGopW6//XZuuummwO9ut5vc3Nw23056TDqfXfpZm7+viIiItExEBKL09HTsdjt79gSP19mzZw9ZWVmHtHe5XLhc6rkRERGJFJ33etwtEBUVxeDBg1m4cGFgmdfrZeHCheTn54ewMhEREQkHEdFDBHDTTTcxceJEhgwZwumnn87MmTMpLy/nyiuvDHVpIiIiEmIRE4h+/vOfs3fvXqZPn05hYSGnnHIK8+fPP2SgtYiIiESeiLkO0dHQ3e5FREQ6n5b8/Y6IMUQiIiIiR6JAJCIiIhFPgUhEREQingKRiIiIRDwFIhEREYl4CkQiIiIS8RSIREREJOIpEImIiEjEUyASERGRiBcxt+44Gv6Lebvd7hBXIiIiIs3l/7vdnJtyKBA1Q2lpKQC5ubkhrkRERERaqrS0lKSkpCO20b3MmsHr9bJr1y4SEhIwDKNN39vtdpObm8uOHTt0n7R2pmPdcXSsO46OdcfRse44bXWsTdOktLSUnJwcbLYjjxJSD1Ez2Gw2unXr1q7bSExM1P/BOoiOdcfRse44OtYdR8e647TFsf6+niE/DaoWERGRiKdAJCIiIhFPgSjEXC4Xv//973G5XKEu5ZinY91xdKw7jo51x9Gx7jihONYaVC0iIiIRTz1EIiIiEvEUiERERCTiKRCJiIhIxFMgEhERkYinQBRCTz75JD169CA6OpqhQ4eyYsWKUJfU6c2YMYPTTjuNhIQEMjIyGDduHBs3bgxqU1VVxZQpU0hLSyM+Pp7x48ezZ8+eEFV87PjjH/+IYRhMmzYtsEzHuu3s3LmTSy+9lLS0NGJiYhg4cCCfffZZYL1pmkyfPp3s7GxiYmIYNWoUmzdvDmHFnZfH4+Guu+6iZ8+exMTEcPzxx/OHP/wh6H5YOt6ts2TJEs4//3xycnIwDIPXX389aH1zjuuBAwcoKCggMTGR5ORkrr76asrKyo66NgWiEHn55Ze56aab+P3vf8/q1as5+eSTGT16NEVFRaEurVNbvHgxU6ZM4dNPP2XBggXU1tZy9tlnU15eHmhz44038uabb/LKK6+wePFidu3axUUXXRTCqju/lStX8re//Y2TTjopaLmOdds4ePAgw4cPx+l08s4777B+/Xr+9Kc/kZKSEmjz0EMP8dhjj/HUU0+xfPly4uLiGD16NFVVVSGsvHN68MEHmTVrFk888QQbNmzgwQcf5KGHHuLxxx8PtNHxbp3y8nJOPvlknnzyySbXN+e4FhQU8NVXX7FgwQLmzZvHkiVLmDx58tEXZ0pInH766eaUKVMCv3s8HjMnJ8ecMWNGCKs69hQVFZmAuXjxYtM0TbO4uNh0Op3mK6+8EmizYcMGEzCXLVsWqjI7tdLSUrNXr17mggULzB/96EfmDTfcYJqmjnVb+u1vf2ueccYZh13v9XrNrKws8+GHHw4sKy4uNl0ul/niiy92RInHlLFjx5pXXXVV0LKLLrrILCgoME1Tx7utAOZrr70W+L05x3X9+vUmYK5cuTLQ5p133jENwzB37tx5VPWohygEampqWLVqFaNGjQoss9lsjBo1imXLloWwsmNPSUkJAKmpqQCsWrWK2traoGPft29f8vLydOxbacqUKYwdOzbomIKOdVt64403GDJkCD/72c/IyMhg0KBB/P3vfw+s37p1K4WFhUHHOikpiaFDh+pYt8KwYcNYuHAhmzZtAmDt2rV8/PHHjBkzBtDxbi/NOa7Lli0jOTmZIUOGBNqMGjUKm83G8uXLj2r7urlrCOzbtw+Px0NmZmbQ8szMTL7++usQVXXs8Xq9TJs2jeHDh3PiiScCUFhYSFRUFMnJyUFtMzMzKSwsDEGVndtLL73E6tWrWbly5SHrdKzbzjfffMOsWbO46aab+N3vfsfKlSv59a9/TVRUFBMnTgwcz6b+m6Jj3XK33XYbbrebvn37Yrfb8Xg83H///RQUFADoeLeT5hzXwsJCMjIygtY7HA5SU1OP+tgrEMkxa8qUKXz55Zd8/PHHoS7lmLRjxw5uuOEGFixYQHR0dKjLOaZ5vV6GDBnCAw88AMCgQYP48ssveeqpp5g4cWKIqzv2/Otf/2LOnDnMnTuXAQMGsGbNGqZNm0ZOTo6O9zFMp8xCID09Hbvdfshsmz179pCVlRWiqo4tU6dOZd68eSxatIhu3boFlmdlZVFTU0NxcXFQex37llu1ahVFRUWceuqpOBwOHA4Hixcv5rHHHsPhcJCZmalj3Uays7Pp379/0LJ+/fqxfft2gMDx1H9T2sYtt9zCbbfdxoQJExg4cCCXXXYZN954IzNmzAB0vNtLc45rVlbWIZOP6urqOHDgwFEfewWiEIiKimLw4MEsXLgwsMzr9bJw4ULy8/NDWFnnZ5omU6dO5bXXXuODDz6gZ8+eQesHDx6M0+kMOvYbN25k+/btOvYtNHLkSNatW8eaNWsCjyFDhlBQUBD4Wce6bQwfPvyQy0ds2rSJ7t27A9CzZ0+ysrKCjrXb7Wb58uU61q1QUVGBzRb859Fut+P1egEd7/bSnOOan59PcXExq1atCrT54IMP8Hq9DB069OgKOKoh2dJqL730kulyucxnn33WXL9+vTl58mQzOTnZLCwsDHVpndq1115rJiUlmR9++KG5e/fuwKOioiLQ5pprrjHz8vLMDz74wPzss8/M/Px8Mz8/P4RVHzsazjIzTR3rtrJixQrT4XCY999/v7l582Zzzpw5ZmxsrPnCCy8E2vzxj380k5OTzf/+97/mF198YV5wwQVmz549zcrKyhBW3jlNnDjR7Nq1qzlv3jxz69at5quvvmqmp6ebt956a6CNjnfrlJaWmp9//rn5+eefm4D56KOPmp9//rm5bds20zSbd1zPOeccc9CgQeby5cvNjz/+2OzVq5f5i1/84qhrUyAKoccff9zMy8szo6KizNNPP9389NNPQ11Spwc0+Zg9e3agTWVlpXndddeZKSkpZmxsrHnhhReau3fvDl3Rx5DGgUjHuu28+eab5oknnmi6XC6zb9++5tNPPx203uv1mnfddZeZmZlpulwuc+TIkebGjRtDVG3n5na7zRtuuMHMy8szo6OjzeOOO8684447zOrq6kAbHe/WWbRoUZP/jZ44caJpms07rvv37zd/8YtfmPHx8WZiYqJ55ZVXmqWlpUddm2GaDS69KSIiIhKBNIZIREREIp4CkYiIiEQ8BSIRERGJeApEIiIiEvEUiERERCTiKRCJiIhIxFMgEhERkYinQCQiIiIRT4FIRKSZDMPg9ddfD3UZItIOFIhEpFO44oorMAzjkMc555wT6tJE5BjgCHUBIiLNdc455zB79uygZS6XK0TViMixRD1EItJpuFwusrKygh4pKSmAdTpr1qxZjBkzhpiYGI477jj+/e9/B71+3bp1nHXWWcTExJCWlsbkyZMpKysLavPMM88wYMAAXC4X2dnZTJ06NWj9vn37uPDCC4mNjaVXr1688cYbgXUHDx6koKCALl26EBMTQ69evQ4JcCISnhSIROSYcddddzF+/HjWrl1LQUEBEyZMYMOGDQCUl5czevRoUlJSWLlyJa+88grvv/9+UOCZNWsWU6ZMYfLkyaxbt4433niDE044IWgb99xzDxdffDFffPEF5557LgUFBRw4cCCw/fXr1/POO++wYcMGZs2aRXp6escdABFpPVNEpBOYOHGiabfbzbi4uKDH/fffb5qmaQLmNddcE/SaoUOHmtdee61pmqb59NNPmykpKWZZWVlg/VtvvWXabDazsLDQNE3TzMnJMe+4447D1gCYd955Z+D3srIyEzDfeecd0zRN8/zzzzevvPLKttlhEelQGkMkIp3Gj3/8Y2bNmhW0LDU1NfBzfn5+0Lr8/HzWrFkDwIYNGzj55JOJi4sLrB8+fDher5eNGzdiGAa7du1i5MiRR6zhpJNOCvwcFxdHYmIiRUVFAFx77bWMHz+e1atXc/bZZzNu3DiGDRvWqn0VkY6lQCQinUZcXNwhp7DaSkxMTLPaOZ3OoN8Nw8Dr9QIwZswYtm3bxttvv82CBQsYOXIkU6ZM4ZFHHmnzekWkbWkMkYgcMz799NNDfu/Xrx8A/fr1Y+3atZSXlwfWL126FJvNRp8+fUhISKBHjx4sXLjwqGro0qULEydO5IUXXmDmzJk8/fTTR/V+ItIx1EMkIp1GdXU1hYWFQcscDkdg4PIrr7zCkCFDOOOMM5gzZw4rVqzgH//4BwAFBQX8/ve/Z+LEidx9993s3buX66+/nssuu4zMzEwA7r77bq655hoyMjIYM2YMpaWlLF26lOuvv75Z9U2fPp3BgwczYMAAqqurmTdvXiCQiUh4UyASkU5j/vz5ZGdnBy3r06cPX3/9NWDNAHvppZe47rrryM7O5sUXX6R///4AxMbG8u6773LDDTdw2mmnERsby/jx43n00UcD7zVx4kSqqqr485//zM0330x6ejr/7//9v2bXFxUVxe233863335LTEwMP/zhD3nppZfaYM9FpL0ZpmmaoS5CRORoGYbBa6+9xrhx40Jdioh0QhpDJCIiIhFPgUhEREQinsYQicgxQWf/ReRoqIdIREREIp4CkYiIiEQ8BSIRERGJeApEIiIiEvEUiERERCTiKRCJiIhIxFMgEhERkYinQCQiIiIR7/8DjpSOODfeJyEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ftype = 'json'\n",
    "cnn_model_history_name = '{}_{}_{}.{}'.format(dataset_name, modeltype, 'history', ftype) \n",
    "cnn_model_history_path = os.path.join(cnn_model_files_dir, cnn_model_history_name)\n",
    "with open(cnn_model_history_path, \"w\") as file: \n",
    "    json.dump({'history': history.history}, file, indent=4)\n",
    "nprint('CNN model history path', cnn_model_history_path)\n",
    "display_training_performance(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bde3bd-05e1-44a4-a7fa-fc2afc0603d1",
   "metadata": {},
   "source": [
    "<h2>Creation of a .zip file for uploading to Google Drive</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9877b05e-6ed3-441d-94f4-48fee7d60d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftype = 'zip'\n",
    "shutil.make_archive(cnn_model_files_dir, ftype, cnn_model_files_dir)\n",
    "shutil.rmtree(cnn_model_files_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ee8384-469d-4c54-bd5b-f146f34e8b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
